<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>深度学习6.3-YOLOv3实现AI识虫（下） | 小漁头|小戴</title><meta name="author" content="小漁头&amp;小戴"><meta name="copyright" content="小漁头&amp;小戴"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="本文是深度学习的第十五篇，本文介绍基于YOLOv3的AI识虫实验和单阶段目标检测模型YOLOv3。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习6.3-YOLOv3实现AI识虫（下）">
<meta property="og:url" content="http://blog.dai2yutou.space/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.3-YOLOv3%E5%AE%9E%E7%8E%B0AI%E8%AF%86%E8%99%AB%EF%BC%88%E4%B8%8B%EF%BC%89/index.html">
<meta property="og:site_name" content="小漁头|小戴">
<meta property="og:description" content="本文是深度学习的第十五篇，本文介绍基于YOLOv3的AI识虫实验和单阶段目标检测模型YOLOv3。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picbed.dai2yutou.space/web_img/19.png">
<meta property="article:published_time" content="2023-01-03T13:05:55.000Z">
<meta property="article:modified_time" content="2023-03-30T12:13:05.781Z">
<meta property="article:author" content="小漁头&amp;小戴">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="paddle">
<meta property="article:tag" content="深度学习高级_计算机视觉之目标检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picbed.dai2yutou.space/web_img/19.png"><link rel="shortcut icon" href="/img/basketball.png"><link rel="canonical" href="http://blog.dai2yutou.space/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.3-YOLOv3%E5%AE%9E%E7%8E%B0AI%E8%AF%86%E8%99%AB%EF%BC%88%E4%B8%8B%EF%BC%89/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 小漁头&小戴","link":"链接: ","source":"来源: 小漁头|小戴","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习6.3-YOLOv3实现AI识虫（下）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-30 20:13:05'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/css.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/at.alicdn.com/t/c/font_3829236_a49e40pee5.css"><link rel="stylesheet" href="/css/font-awesome.css"><link rel="stylesheet" href="/css/progress_bar.css"><link rel="stylesheet" href="/css/nav_menu.css"><link rel="stylesheet" href="/css/color.css"><link rel="apple-touch-icon" href="/img/apple-touch-icon.jpg"><meta name="apple-mobile-web-app-title" content="小漁头🏀"><link rel="bookmark" href="/img/apple-touch-icon.jpg"><link rel="apple-touch-icon-precomposed" sizes="180x180" href="/img/apple-touch-icon.jpg" ><link rel="stylesheet" href="/css/card_author.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (ture) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">61</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">36</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picbed.dai2yutou.space/web_img/19.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">小漁头|小戴</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习6.3-YOLOv3实现AI识虫（下）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-03T13:05:55.000Z" title="发表于 2023-01-03 21:05:55">2023-01-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-30T12:13:05.781Z" title="更新于 2023-03-30 20:13:05">2023-03-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">20.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>87分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习6.3-YOLOv3实现AI识虫（下）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="一、基于YOLOv3的AI识虫实验"><a href="#一、基于YOLOv3的AI识虫实验" class="headerlink" title="一、基于YOLOv3的AI识虫实验"></a>一、基于YOLOv3的AI识虫实验</h1><p>基于YOLOv3的AI识虫实验流程如下图所示，包含如下9个步骤：</p>
<p><strong>1.数据处理</strong>：根据网络接收的数据格式，完成相应的预处理操作，保证模型正常读取，同时，对于训练数据，使用数据增广策略来提升模型泛化性能；</p>
<p><strong>2.模型构建</strong>：设计深度神经网络结构（模型的假设空间）；</p>
<p><strong>3.模型后处理</strong>：通过模型预测得到的概率图，经过一系列后处理操作得到真实的输出值；</p>
<p><strong>4.损失函数定义</strong>：根据预测值和真实值构建损失函数，神经网络通过最小化损失函数使得网络的输出值更接近真实值；</p>
<p><strong>5.训练配置</strong>：实例化模型，加载模型参数，指定模型采用的寻解算法（优化器）；</p>
<p><strong>6.模型训练</strong>：执行多轮训练不断调整参数，以达到较好的效果；</p>
<p><strong>7.模型保存</strong>：将模型参数保存到指定位置，便于后续推理或继续训练使用；</p>
<p><strong>8.模型评估</strong>：对训练好的模型进行评估测试，观察准确率和Loss；</p>
<p><strong>9.模型推理及可视化</strong>：使用一张真实图片来验证模型识别的效果，并可视化推理结果。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/fc58e8f1fa1943448d5077d7bff25afa94c4d41925274f3985592cc935f253c9" width = "900"></center>

<blockquote>
<p>上述不是文本检测是目标检测，打错了！！！</p>
</blockquote>
<p><br></br></p>
<hr>
<blockquote>
<p><strong>说明：</strong></p>
<p>不同的深度学习任务，使用深度学习框架的代码结构基本相似。大家掌握了一个任务的实现方法，便很容易在此基础上举一反三。使用深度学习框架可以屏蔽底层实现，用户只需关注模型的逻辑结构。同时，简化了计算，降低了深度学习入门门槛。</p>
</blockquote>
<hr>
<h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p>本实验支持在飞桨实训平台或本地环境操作，建议您使用飞桨实训平台。</p>
<ul>
<li><strong>飞桨实训平台</strong>：实训平台集成了实验必须的大部分相关环境，代码可在线运行，同时还提供了免费算力，即使实践复杂模型也无算力之忧。</li>
<li><strong>本地环境</strong>：如果您选择在本地环境上操作，需要安装Python3.X、飞桨开源框架2.X 等实验必须的环境，具体请参见<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html">《飞桨开始使用-安装》</a>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压数据脚本，将文件解压到work目录下</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;开始解压......&#x27;</span>)</span><br><span class="line">!unzip  -o -q -d  /home/aistudio/work /home/aistudio/data/data170339/insects.<span class="built_in">zip</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;解压完成&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageEnhance</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">INSECT_NAMES = [<span class="string">&#x27;Boerner&#x27;</span>, <span class="string">&#x27;Leconte&#x27;</span>, <span class="string">&#x27;Linnaeus&#x27;</span>, </span><br><span class="line">                <span class="string">&#x27;acuminatus&#x27;</span>, <span class="string">&#x27;armandi&#x27;</span>, <span class="string">&#x27;coleoptera&#x27;</span>, <span class="string">&#x27;linnaeus&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_insect_names</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    return a dict, as following,</span></span><br><span class="line"><span class="string">        &#123;&#x27;Boerner&#x27;: 0,</span></span><br><span class="line"><span class="string">         &#x27;Leconte&#x27;: 1,</span></span><br><span class="line"><span class="string">         &#x27;Linnaeus&#x27;: 2, </span></span><br><span class="line"><span class="string">         &#x27;acuminatus&#x27;: 3,</span></span><br><span class="line"><span class="string">         &#x27;armandi&#x27;: 4,</span></span><br><span class="line"><span class="string">         &#x27;coleoptera&#x27;: 5,</span></span><br><span class="line"><span class="string">         &#x27;linnaeus&#x27;: 6</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    It can map the insect name into an integer label.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    insect_category2id = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(INSECT_NAMES):</span><br><span class="line">        insect_category2id[item] = i <span class="comment"># 构建键值对</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> insect_category2id</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_annotations</span>(<span class="params">cname2cid, datadir</span>):</span><br><span class="line">    filenames = os.listdir(os.path.join(datadir, <span class="string">&#x27;annotations&#x27;</span>, <span class="string">&#x27;xmls&#x27;</span>))</span><br><span class="line">    records = []</span><br><span class="line">    ct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> filenames:</span><br><span class="line">        fid = fname.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] <span class="comment"># 序号</span></span><br><span class="line">        fpath = os.path.join(datadir, <span class="string">&#x27;annotations&#x27;</span>, <span class="string">&#x27;xmls&#x27;</span>, fname) <span class="comment"># 路径</span></span><br><span class="line">        img_file = os.path.join(datadir, <span class="string">&#x27;images&#x27;</span>, fid + <span class="string">&#x27;.jpeg&#x27;</span>) <span class="comment"># 序号--&gt;图片</span></span><br><span class="line">        tree = ET.parse(fpath) <span class="comment"># 读取xml文件</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> tree.find(<span class="string">&#x27;id&#x27;</span>) <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            im_id = np.array([ct])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_id = np.array([<span class="built_in">int</span>(tree.find(<span class="string">&#x27;id&#x27;</span>).text)])</span><br><span class="line"></span><br><span class="line">        objs = tree.findall(<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">        im_w = <span class="built_in">float</span>(tree.find(<span class="string">&#x27;size&#x27;</span>).find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">        im_h = <span class="built_in">float</span>(tree.find(<span class="string">&#x27;size&#x27;</span>).find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line">        gt_bbox = np.zeros((<span class="built_in">len</span>(objs), <span class="number">4</span>), dtype=np.float32)</span><br><span class="line">        gt_class = np.zeros((<span class="built_in">len</span>(objs), ), dtype=np.int32)</span><br><span class="line">        is_crowd = np.zeros((<span class="built_in">len</span>(objs), ), dtype=np.int32)</span><br><span class="line">        difficult = np.zeros((<span class="built_in">len</span>(objs), ), dtype=np.int32)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, obj <span class="keyword">in</span> <span class="built_in">enumerate</span>(objs):</span><br><span class="line">            cname = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">            gt_class[i] = cname2cid[cname]</span><br><span class="line">            _difficult = <span class="built_in">int</span>(obj.find(<span class="string">&#x27;difficult&#x27;</span>).text)</span><br><span class="line">            x1 = <span class="built_in">float</span>(obj.find(<span class="string">&#x27;bndbox&#x27;</span>).find(<span class="string">&#x27;xmin&#x27;</span>).text)</span><br><span class="line">            y1 = <span class="built_in">float</span>(obj.find(<span class="string">&#x27;bndbox&#x27;</span>).find(<span class="string">&#x27;ymin&#x27;</span>).text)</span><br><span class="line">            x2 = <span class="built_in">float</span>(obj.find(<span class="string">&#x27;bndbox&#x27;</span>).find(<span class="string">&#x27;xmax&#x27;</span>).text)</span><br><span class="line">            y2 = <span class="built_in">float</span>(obj.find(<span class="string">&#x27;bndbox&#x27;</span>).find(<span class="string">&#x27;ymax&#x27;</span>).text)</span><br><span class="line">            x1 = <span class="built_in">max</span>(<span class="number">0</span>, x1)</span><br><span class="line">            y1 = <span class="built_in">max</span>(<span class="number">0</span>, y1)</span><br><span class="line">            x2 = <span class="built_in">min</span>(im_w - <span class="number">1</span>, x2)</span><br><span class="line">            y2 = <span class="built_in">min</span>(im_h - <span class="number">1</span>, y2)</span><br><span class="line">            <span class="comment"># 这里将原二点表示转换为xywh格式，使用xywh格式来表示目标物体真实框</span></span><br><span class="line">            gt_bbox[i] = [(x1+x2)/<span class="number">2.0</span> , (y1+y2)/<span class="number">2.0</span>, x2-x1+<span class="number">1.</span>, y2-y1+<span class="number">1.</span>]</span><br><span class="line">            is_crowd[i] = <span class="number">0</span></span><br><span class="line">            difficult[i] = _difficult</span><br><span class="line"></span><br><span class="line">        voc_rec = &#123;</span><br><span class="line">            <span class="string">&#x27;im_file&#x27;</span>: img_file,</span><br><span class="line">            <span class="string">&#x27;im_id&#x27;</span>: im_id,</span><br><span class="line">            <span class="string">&#x27;h&#x27;</span>: im_h,</span><br><span class="line">            <span class="string">&#x27;w&#x27;</span>: im_w,</span><br><span class="line">            <span class="string">&#x27;is_crowd&#x27;</span>: is_crowd,</span><br><span class="line">            <span class="string">&#x27;gt_class&#x27;</span>: gt_class,</span><br><span class="line">            <span class="string">&#x27;gt_bbox&#x27;</span>: gt_bbox,</span><br><span class="line">            <span class="string">&#x27;gt_poly&#x27;</span>: [],</span><br><span class="line">            <span class="string">&#x27;difficult&#x27;</span>: difficult</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(objs) != <span class="number">0</span>:</span><br><span class="line">            records.append(voc_rec)</span><br><span class="line">        ct += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> records</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_bbox</span>(<span class="params">gt_bbox, gt_class</span>):</span><br><span class="line">    <span class="comment"># 对于一般的检测任务来说，一张图片上往往会有多个目标物体</span></span><br><span class="line">    <span class="comment"># 设置参数MAX_NUM = 50， 即一张图片最多取50个真实框；</span></span><br><span class="line">    <span class="comment"># 如果真实框的数目少于50个，则将不足部分的gt_bbox, gt_class和gt_score的各项数值全设置为0</span></span><br><span class="line">    MAX_NUM = <span class="number">50</span></span><br><span class="line">    gt_bbox2 = np.zeros((MAX_NUM, <span class="number">4</span>))</span><br><span class="line">    gt_class2 = np.zeros((MAX_NUM,))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(gt_bbox)):</span><br><span class="line">        gt_bbox2[i, :] = gt_bbox[i, :]</span><br><span class="line">        gt_class2[i] = gt_class[i]</span><br><span class="line">        <span class="keyword">if</span> i &gt;= MAX_NUM:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> gt_bbox2, gt_class2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_img_data_from_file</span>(<span class="params">record</span>):</span><br><span class="line">    im_file = record[<span class="string">&#x27;im_file&#x27;</span>]</span><br><span class="line">    h = record[<span class="string">&#x27;h&#x27;</span>]</span><br><span class="line">    w = record[<span class="string">&#x27;w&#x27;</span>]</span><br><span class="line">    is_crowd = record[<span class="string">&#x27;is_crowd&#x27;</span>]</span><br><span class="line">    gt_class = record[<span class="string">&#x27;gt_class&#x27;</span>]</span><br><span class="line">    gt_bbox = record[<span class="string">&#x27;gt_bbox&#x27;</span>]</span><br><span class="line">    difficult = record[<span class="string">&#x27;difficult&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    img = cv2.imread(im_file)</span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 机器校验</span></span><br><span class="line">    <span class="keyword">assert</span> img.shape[<span class="number">0</span>] == <span class="built_in">int</span>(h), \</span><br><span class="line">             <span class="string">&quot;image height of &#123;&#125; inconsistent in record(&#123;&#125;) and img file(&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">               im_file, h, img.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> img.shape[<span class="number">1</span>] == <span class="built_in">int</span>(w), \</span><br><span class="line">             <span class="string">&quot;image width of &#123;&#125; inconsistent in record(&#123;&#125;) and img file(&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">               im_file, w, img.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    gt_boxes, gt_labels = get_bbox(gt_bbox, gt_class)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gt_bbox 用相对值</span></span><br><span class="line">    gt_boxes[:, <span class="number">0</span>] = gt_boxes[:, <span class="number">0</span>] / <span class="built_in">float</span>(w)</span><br><span class="line">    gt_boxes[:, <span class="number">1</span>] = gt_boxes[:, <span class="number">1</span>] / <span class="built_in">float</span>(h)</span><br><span class="line">    gt_boxes[:, <span class="number">2</span>] = gt_boxes[:, <span class="number">2</span>] / <span class="built_in">float</span>(w)</span><br><span class="line">    gt_boxes[:, <span class="number">3</span>] = gt_boxes[:, <span class="number">3</span>] / <span class="built_in">float</span>(h)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> img, gt_boxes, gt_labels, (h, w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义可视化函数，用于对比原图和图像增强的效果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">srcimg, img_enhance</span>):</span><br><span class="line">    plt.figure(num=<span class="number">2</span>, figsize=(<span class="number">6</span>,<span class="number">12</span>))</span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Src Image&#x27;</span>, color=<span class="string">&#x27;#0000FF&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>) <span class="comment"># 不显示坐标轴</span></span><br><span class="line">    plt.imshow(srcimg) <span class="comment"># 显示原图片</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对原图做随机改变亮暗、对比度和颜色等数据增强</span></span><br><span class="line">    srcimg_gtbox = records[<span class="number">0</span>][<span class="string">&#x27;gt_bbox&#x27;</span>]</span><br><span class="line">    srcimg_label = records[<span class="number">0</span>][<span class="string">&#x27;gt_class&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Enhance Image&#x27;</span>, color=<span class="string">&#x27;#0000FF&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>) <span class="comment"># 不显示坐标轴</span></span><br><span class="line">    plt.imshow(img_enhance/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机改变亮暗、对比度和颜色等</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_distort</span>(<span class="params">img</span>):</span><br><span class="line">    <span class="comment"># 随机改变亮度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">random_brightness</span>(<span class="params">img, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span></span>):</span><br><span class="line">        e = np.random.uniform(lower, upper)</span><br><span class="line">        <span class="keyword">return</span> ImageEnhance.Brightness(img).enhance(e)</span><br><span class="line">    <span class="comment"># 随机改变对比度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">random_contrast</span>(<span class="params">img, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span></span>):</span><br><span class="line">        e = np.random.uniform(lower, upper)</span><br><span class="line">        <span class="keyword">return</span> ImageEnhance.Contrast(img).enhance(e)</span><br><span class="line">    <span class="comment"># 随机改变颜色</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">random_color</span>(<span class="params">img, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span></span>):</span><br><span class="line">        e = np.random.uniform(lower, upper)</span><br><span class="line">        <span class="keyword">return</span> ImageEnhance.Color(img).enhance(e)</span><br><span class="line"></span><br><span class="line">    ops = [random_brightness, random_contrast, random_color]</span><br><span class="line">    np.random.shuffle(ops)</span><br><span class="line"></span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    img = ops[<span class="number">0</span>](img)</span><br><span class="line">    img = ops[<span class="number">1</span>](img)</span><br><span class="line">    img = ops[<span class="number">2</span>](img)</span><br><span class="line">    img = np.asarray(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机填充</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_expand</span>(<span class="params">img,</span></span><br><span class="line"><span class="params">                  gtboxes,</span></span><br><span class="line"><span class="params">                  max_ratio=<span class="number">4.</span>,</span></span><br><span class="line"><span class="params">                  fill=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  keep_ratio=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  thresh=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="keyword">if</span> random.random() &gt; thresh:</span><br><span class="line">        <span class="keyword">return</span> img, gtboxes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> max_ratio &lt; <span class="number">1.0</span>:</span><br><span class="line">        <span class="keyword">return</span> img, gtboxes</span><br><span class="line"></span><br><span class="line">    h, w, c = img.shape</span><br><span class="line">    ratio_x = random.uniform(<span class="number">1</span>, max_ratio)</span><br><span class="line">    <span class="keyword">if</span> keep_ratio:</span><br><span class="line">        ratio_y = ratio_x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ratio_y = random.uniform(<span class="number">1</span>, max_ratio)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 通过缩放与平移实现填充的目的</span></span><br><span class="line">    oh = <span class="built_in">int</span>(h * ratio_y)</span><br><span class="line">    ow = <span class="built_in">int</span>(w * ratio_x)</span><br><span class="line">    off_x = random.randint(<span class="number">0</span>, ow - w)</span><br><span class="line">    off_y = random.randint(<span class="number">0</span>, oh - h)</span><br><span class="line"></span><br><span class="line">    out_img = np.zeros((oh, ow, c))</span><br><span class="line">    <span class="keyword">if</span> fill <span class="keyword">and</span> <span class="built_in">len</span>(fill) == c:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(c):</span><br><span class="line">            out_img[:, :, i] = fill[i] * <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">    out_img[off_y:off_y + h, off_x:off_x + w, :] = img</span><br><span class="line">    gtboxes[:, <span class="number">0</span>] = ((gtboxes[:, <span class="number">0</span>] * w) + off_x) / <span class="built_in">float</span>(ow)</span><br><span class="line">    gtboxes[:, <span class="number">1</span>] = ((gtboxes[:, <span class="number">1</span>] * h) + off_y) / <span class="built_in">float</span>(oh)</span><br><span class="line">    gtboxes[:, <span class="number">2</span>] = gtboxes[:, <span class="number">2</span>] / ratio_x</span><br><span class="line">    gtboxes[:, <span class="number">3</span>] = gtboxes[:, <span class="number">3</span>] / ratio_y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out_img.astype(<span class="string">&#x27;uint8&#x27;</span>), gtboxes <span class="comment"># 返回填充后的图片与边界框</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机翻转</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_flip</span>(<span class="params">img, gtboxes, thresh=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="keyword">if</span> random.random() &gt; thresh:</span><br><span class="line">        <span class="comment"># 调整步长</span></span><br><span class="line">        img = img[:, ::-<span class="number">1</span>, :]</span><br><span class="line">        gtboxes[:, <span class="number">0</span>] = <span class="number">1.0</span> - gtboxes[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> img, gtboxes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打乱真实框排列顺序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shuffle_gtbox</span>(<span class="params">gtbox, gtlabel</span>):</span><br><span class="line">    gt = np.concatenate([gtbox, gtlabel[:, np.newaxis]], axis=<span class="number">1</span>)</span><br><span class="line">    idx = np.arange(gt.shape[<span class="number">0</span>])</span><br><span class="line">    np.random.shuffle(idx)</span><br><span class="line">    gt = gt[idx, :]</span><br><span class="line">    <span class="keyword">return</span> gt[:, :<span class="number">4</span>], gt[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机缩放</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_interp</span>(<span class="params">img, size, interp=<span class="literal">None</span></span>):</span><br><span class="line">    interp_method = [cv2.INTER_NEAREST,   <span class="comment"># 最近邻插值</span></span><br><span class="line">                    cv2.INTER_LINEAR,     <span class="comment"># 线性插值</span></span><br><span class="line">                    cv2.INTER_AREA,       <span class="comment"># 区域插值</span></span><br><span class="line">                    cv2.INTER_CUBIC,      <span class="comment"># 三次样条插值</span></span><br><span class="line">                    cv2.INTER_LANCZOS4]   <span class="comment"># LANCZOS4插值</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 随机选择缩放时的插值方法</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> interp <span class="keyword">or</span> interp <span class="keyword">not</span> <span class="keyword">in</span> interp_method:</span><br><span class="line">        interp = interp_method[random.randint(<span class="number">0</span>, <span class="built_in">len</span>(interp_method) - <span class="number">1</span>)]</span><br><span class="line">    h, w, _ = img.shape</span><br><span class="line">    im_scale_x = size / <span class="built_in">float</span>(w)</span><br><span class="line">    im_scale_y = size / <span class="built_in">float</span>(h)</span><br><span class="line">    <span class="comment"># 调整图像大小</span></span><br><span class="line">    img = cv2.resize(img, <span class="literal">None</span>, <span class="literal">None</span>, fx=im_scale_x, fy=im_scale_y, interpolation=interp)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像增广方法汇总</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_augment</span>(<span class="params">img, gtboxes, gtlabels, size, means=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 随机改变亮暗、对比度和颜色等</span></span><br><span class="line">    img = random_distort(img)</span><br><span class="line">    <span class="comment"># 随机填充</span></span><br><span class="line">    img, gtboxes = random_expand(img, gtboxes, fill=means)</span><br><span class="line">    <span class="comment"># 随机缩放</span></span><br><span class="line">    img = random_interp(img, size)</span><br><span class="line">    <span class="comment"># 随机翻转</span></span><br><span class="line">    img, gtboxes = random_flip(img, gtboxes)</span><br><span class="line">    <span class="comment"># 随机打乱真实框排列顺序</span></span><br><span class="line">    gtboxes, gtlabels = shuffle_gtbox(gtboxes, gtlabels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img.astype(<span class="string">&#x27;float32&#x27;</span>), gtboxes.astype(<span class="string">&#x27;float32&#x27;</span>), gtlabels.astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_img_data</span>(<span class="params">record, size=<span class="number">640</span></span>):</span><br><span class="line">    img, gt_boxes, gt_labels, scales = get_img_data_from_file(record)</span><br><span class="line">    img, gt_boxes, gt_labels = image_augment(img, gt_boxes, gt_labels, size)</span><br><span class="line">    mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">    std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">    mean = np.array(mean).reshape((<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">    std = np.array(std).reshape((<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">    img = (img / <span class="number">255.0</span> - mean) / std</span><br><span class="line">    img = img.astype(<span class="string">&#x27;float32&#x27;</span>).transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> img, gt_boxes, gt_labels, scales</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取一个批次内样本随机缩放的尺寸</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_img_size</span>(<span class="params">mode</span>):</span><br><span class="line">    <span class="keyword">if</span> (mode == <span class="string">&#x27;train&#x27;</span>) <span class="keyword">or</span> (mode == <span class="string">&#x27;valid&#x27;</span>):</span><br><span class="line">        inds = np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">        ii = np.random.choice(inds)</span><br><span class="line">        img_size = <span class="number">320</span> + ii * <span class="number">32</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        img_size = <span class="number">608</span></span><br><span class="line">    <span class="keyword">return</span> img_size</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将list形式的batch数据转化成多个array构成的tuple</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_array</span>(<span class="params">batch_data</span>):</span><br><span class="line">    img_array = np.array([item[<span class="number">0</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data], dtype = <span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    gt_box_array = np.array([item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data], dtype = <span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    gt_labels_array = np.array([item[<span class="number">2</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data], dtype = <span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    img_scale = np.array([item[<span class="number">3</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data], dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> img_array, gt_box_array, gt_labels_array, img_scale</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据读取类，继承Paddle.io.Dataset</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TrainDataset</span>(paddle.io.Dataset):</span><br><span class="line">    <span class="keyword">def</span>  <span class="title function_">__init__</span>(<span class="params">self, datadir, mode=<span class="string">&#x27;train&#x27;</span></span>):</span><br><span class="line">        self.datadir = datadir</span><br><span class="line">        cname2cid = get_insect_names()</span><br><span class="line">        self.records = get_annotations(cname2cid, datadir)</span><br><span class="line">        self.img_size = <span class="number">640</span>  <span class="comment"># get_img_size(mode)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        record = self.records[idx]</span><br><span class="line">        <span class="comment"># print(&quot;print: &quot;, record)</span></span><br><span class="line">        img, gt_bbox, gt_labels, im_shape = get_img_data(record, size=self.img_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, gt_bbox, gt_labels, np.array(im_shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.records)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 list形式的batch数据 转化成多个array构成的tuple</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_test_array</span>(<span class="params">batch_data</span>):</span><br><span class="line">    img_name_array = np.array([item[<span class="number">0</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data])</span><br><span class="line">    img_data_array = np.array([item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data], dtype = <span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    img_scale_array = np.array([item[<span class="number">2</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch_data], dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> img_name_array, img_data_array, img_scale_array</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据读取</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_data_loader</span>(<span class="params">datadir, batch_size= <span class="number">10</span>, test_image_size=<span class="number">608</span>, mode=<span class="string">&#x27;test&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载测试用的图片，测试数据没有groundtruth标签</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    image_names = os.listdir(datadir)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reader</span>():</span><br><span class="line">        batch_data = []</span><br><span class="line">        img_size = test_image_size</span><br><span class="line">        <span class="keyword">for</span> image_name <span class="keyword">in</span> image_names:</span><br><span class="line">            file_path = os.path.join(datadir, image_name)</span><br><span class="line">            img = cv2.imread(file_path)</span><br><span class="line">            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">            H = img.shape[<span class="number">0</span>]</span><br><span class="line">            W = img.shape[<span class="number">1</span>]</span><br><span class="line">            img = cv2.resize(img, (img_size, img_size))</span><br><span class="line"></span><br><span class="line">            mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">            std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">            mean = np.array(mean).reshape((<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">            std = np.array(std).reshape((<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">            out_img = (img / <span class="number">255.0</span> - mean) / std</span><br><span class="line">            out_img = out_img.astype(<span class="string">&#x27;float32&#x27;</span>).transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">            img = out_img <span class="comment">#np.transpose(out_img, (2,0,1))</span></span><br><span class="line">            im_shape = [H, W]</span><br><span class="line"></span><br><span class="line">            batch_data.append((image_name.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>], img, im_shape))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(batch_data) == batch_size:</span><br><span class="line">                <span class="keyword">yield</span> make_test_array(batch_data)</span><br><span class="line">                batch_data = []</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(batch_data) &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">yield</span> make_test_array(batch_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reader</span><br></pre></td></tr></table></figure>

<pre><code>开始解压......
解压完成
</code></pre>
<h1 id="二、单阶段目标检测模型YOLOv3"><a href="#二、单阶段目标检测模型YOLOv3" class="headerlink" title="二、单阶段目标检测模型YOLOv3"></a>二、单阶段目标检测模型YOLOv3</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><strong>1. 概述</strong></h2><p>经典的R-CNN系列算法也被称为<strong>两阶段目标检测算法</strong>，由于这种方法需要<strong>先产生候选区域，再对候选区域做分类和位置坐标的预测</strong>，因此算法速度非常慢，这类算法被称为两阶段目标检测算法。与此对应的是以YOLO算法为代表的<strong>单阶段检测算法</strong>，只需要一个网络即可<strong>同时产生候选区域并预测出物体的类别和位置坐标</strong>。</p>
<p>与R-CNN系列算法不同，YOLOv3使用单个网络结构，在产生候选区域的同时即可预测出物体类别和位置，不需要分成两阶段来完成检测任务。另外，YOLOv3算法产生的预测框数目比Faster R-CNN少很多。Faster R-CNN中每个真实框可能对应多个标签为正的候选区域，而YOLOv3里面每个真实框只对应一个正的候选区域。这些特性使得YOLOv3算法具有更快的速度，能到达实时响应的水平。</p>
<p>Joseph Redmon等人在2015年提出YOLO（You Only Look Once，YOLO）算法，通常也被称为YOLOv1；2016年，他们对算法进行改进，又提出YOLOv2版本；2018年发展出YOLOv3版本。<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/539932517">[YOLO家族进化史（v1-v7）]</a></p>
<h2 id="2-YOLOv3模型设计思想"><a href="#2-YOLOv3模型设计思想" class="headerlink" title="2. YOLOv3模型设计思想"></a><strong>2. YOLOv3模型设计思想</strong></h2><p>YOLOv3算法的基本思想可以分成两部分：</p>
<p><strong>在训练阶段</strong>：</p>
<ol>
<li>按一定规则在图片上产生一系列的候选区域，然后根据这些候选区域与图片上物体真实框之间的位置关系对候选区域进行标注。</li>
</ol>
<ul>
<li>跟真实框足够接近的那些候选区域会被标注为正样本，同时将真实框的位置作为正样本的位置目标。</li>
<li>偏离真实框较大的那些候选区域则会被标注为负样本，负样本不需要预测位置或者类别。</li>
</ul>
<ol start="2">
<li>使用卷积神经网络提取图片特征并对候选区域的位置和类别进行预测。这样每个预测框就可以看成是一个样本，根据真实框相对它的位置和类别进行了标注而获得标签值，通过网络模型预测其位置和类别，将网络预测值和标签值进行比较，就可以建立起损失函数。</li>
</ol>
<p><strong>在预测阶段</strong>：计算预测框得分和位置，然后使用非极大值抑制消除重合较大的框，得到最终结果。</p>
<p>YOLOv3的算法流程如 <strong>图1</strong> 所示。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/46fbb2f9d1734a10a79d342dd443a4a0ec9c362af417484a972d7ee9525d0c8c" width = "900"></center>
<center><br>图1：YOLOv3的算法流程图</br></center>

<p><br></br></p>
<h2 id="3-YOLOv3模型训练"><a href="#3-YOLOv3模型训练" class="headerlink" title="3. YOLOv3模型训练"></a><strong>3. YOLOv3模型训练</strong></h2><p>拆分来看，YOLOv3算法的训练流程可以分成两部分，如 <strong>图2</strong> 所示。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/362b1599a9bf403c982ccf76b6f35d23ead0a520921b4e84a6952181d6692d40" width = "800"></center>
<center><br>图2：YOLOv3算法训练流程图 </br></center>

<p><br></br></p>
<ul>
<li><strong>图2</strong> 左边是输入图片，上半部分所示的过程是使用卷积神经网络对图片提取特征，随着网络不断向前传播，特征图的尺寸越来越小，每个像素点会代表更加抽象的特征模式，直到输出特征图，其尺寸减小为原图的$\frac{1}{32}$。</li>
<li><strong>图2</strong> 下半部分描述了生成候选区域的过程，首先将原图划分成多个小方块，每个小方块的大小是$32 \times 32$，然后以每个小方块为中心分别生成一系列锚框，整张图片都会被锚框覆盖到。在每个锚框的基础上产生一个与之对应的预测框，根据锚框和预测框与图片上物体真实框之间的位置关系，对这些预测框进行标注。</li>
<li>将上方支路中输出的特征图与下方支路中产生的预测框标签建立关联，创建损失函数，开启端到端的训练过程。</li>
</ul>
<p>我们可以依据上面的图进一步对训练流程进行拆解，总结出实现方案：</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/0321f37cc92940888349662ad4526c95c3498bfa4a094f44a80650fe4147c5de" width = "800"></center>
<center><br>图3：训练流程问题拆解 </br></center>

<p><br></br></p>
<p>接下来具体介绍流程中各节点的算法原理。</p>
<h3 id="3-1-产生候选区域"><a href="#3-1-产生候选区域" class="headerlink" title="3.1 产生候选区域"></a><strong>3.1 产生候选区域</strong></h3><p>如何产生候选区域，是检测模型的核心设计方案。目前大多数基于卷积神经网络的模型所采用的方式大体如下：</p>
<ol>
<li>按一定的规则在图片上生成一系列位置固定的锚框，将这些锚框看作是可能的候选区域。</li>
<li>对锚框是否包含目标物体进行预测，如果包含目标物体，还需要预测所包含物体的类别，以及预测框相对于锚框位置需要调整的幅度。</li>
</ol>
<p><strong>1）生成锚框</strong></p>
<p>将原始图片划分成$m\times n$个区域，如 <strong>图3</strong> 所示，原始图片高度$H&#x3D;640$, 宽度$W&#x3D;480$，如果我们选择小块区域的尺寸为$32 \times 32$，则$m$和$n$分别为：</p>
<p>$$<br>m &#x3D; \frac{640}{32} &#x3D; 20<br>$$</p>
<p>$$<br>n &#x3D; \frac{480}{32} &#x3D; 15<br>$$</p>
<p>也就是说，我们将原始图像分成了20行15列小方块区域。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/2dd1cbeb53644552a8cb38f3f834dbdda5046a489465454d93cdc88d1ce65ca5" width = "400"></center>
<center><br>图4：将图片划分成多个32x32的小方块 </br></center>

<p><br></br></p>
<p>YOLOv3算法会在每个区域的中心，生成一系列锚框。为了展示方便，我们仅在图中第十行第四列的小方块位置附近画出生成的锚框，如 <strong>图5</strong> 所示。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/b9eca2257fc0432d9f59bdecc8d54d144dd590e990f54c6d82f60a1a1531915b" width = "400"></center>
<center><br>图5：在第10行第4列的小方块区域生成3个锚框 </br></center>

<p><br></br></p>
<hr>
<blockquote>
<p><strong>说明：</strong></p>
<p>这里为了跟程序中的编号对应，最上面的行号是第0行，最左边的列号是第0列。</p>
</blockquote>
<hr>
<p><strong>图6</strong> 展示在每个区域附近都生成3个锚框，很多锚框堆叠在一起可能不太容易看清楚，但过程跟上面类似，只是需要以每个区域的中心点为中心，分别生成3个锚框。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/0880c3b5ec2d40edb476f4fcbadd87aa9f37059cd24d4a1a9d37c627ce5f618a" width = "400"></center>
<center><br>图6：在每个小方块区域生成3个锚框 </br></center>

<p><br></br></p>
<p>在每个小方块区域都生成三个锚框，这会覆盖整张图片，在这张图片上一共生成了900个锚框。</p>
<p><strong>2）生成预测框</strong></p>
<p>在前面已经指出，锚框的位置都是固定好的，不可能刚好跟物体边界框重合，需要<strong>在锚框的基础上进行位置的微调以生成预测框</strong>。预测框相对于锚框会有不同的中心位置和大小，采用什么方式能得到预测框呢？我们先来考虑如何生成其中心位置坐标。</p>
<p>比如上面图中在第10行第4列的小方块区域中心生成的一个锚框，如绿色虚线框所示。以小方格的宽度为单位长度，</p>
<p>此小方块区域左上角的位置坐标是：<br>$$<br>c_x &#x3D; 4\<br>c_y &#x3D; 10<br>$$<br>此锚框的区域中心坐标是：<br>$$<br>center_x &#x3D; c_x + 0.5 &#x3D; 4.5\<br>center_y &#x3D; c_y + 0.5 &#x3D; 10.5<br>$$<br>可以通过下面的方式生成预测框的中心坐标：<br>$$<br>b_x &#x3D; c_x + \sigma(t_x)<br>$$</p>
<p>$$<br>b_y &#x3D; c_y + \sigma(t_y)<br>$$</p>
<p>其中$t_x$和$t_y$为实数，$\sigma(x)$是我们之前学过的Sigmoid函数，其定义如下：</p>
<p>$$<br>\sigma(x) &#x3D; \frac{1}{1 + exp(-x)}<br>$$<br>由于Sigmoid的函数值在$0 \thicksim 1$之间，因此由上面公式计算出来的预测框的中心点总是落在第十行第四列的小区域内部。</p>
<p>当$t_x&#x3D;t_y&#x3D;0$时，$b_x &#x3D; c_x + 0.5$，$b_y &#x3D; c_y + 0.5$，预测框中心与锚框中心重合，都是小区域的中心。</p>
<p>锚框的大小是预先设定好的，在模型中可以当作是超参数，下图中画出的锚框尺寸是</p>
<p>$$<br>p_h &#x3D; 350<br>$$</p>
<p>$$<br>p_w &#x3D; 250<br>$$</p>
<p>通过下面的公式生成预测框的大小：</p>
<p>$$<br>b_h &#x3D; p_h e^{t_h}<br>$$</p>
<p>$$<br>b_w &#x3D; p_w e^{t_w}<br>$$</p>
<p>如果$t_x&#x3D;t_y&#x3D;0, t_h&#x3D;t_w&#x3D;0$，则预测框跟锚框重合。</p>
<p>如果给$t_x, t_y, t_h, t_w$随机赋值如下：</p>
<p>$$<br>t_x &#x3D; 0.2,  t_y &#x3D; 0.3, t_w &#x3D; 0.1, t_h &#x3D; -0.12<br>$$<br>则可以得到预测框的坐标是(154.98, 357.44, 276.29, 310.42)，如 <strong>图7</strong> 中蓝色框所示。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/28ae0fbc087e42449cdea6c48ad53f64cffdf66216a646d884ae778f7c341149" width = "400"></center>
<center><br>图7：生成预测框 </br></center>

<p><br></br></p>
<hr>
<blockquote>
<p><strong>说明：</strong><br>这里坐标采用$xywh$的格式。预测框是在锚框的基础上进行的微调。</p>
</blockquote>
<hr>
<p>这里我们会问：当$t_x, t_y, t_w, t_h$取值为多少的时候，预测框能够跟真实框重合？为了回答问题，只需要将上面预测框坐标中的$b_x, b_y, b_h, b_w$设置为真实框的位置，即可求解出$t$的数值。</p>
<p>令：<br>$$<br>\sigma(t^*_x) + c_x &#x3D; gt_x<br>$$</p>
<p>$$<br>\sigma(t^*_y) + c_y &#x3D; gt_y<br>$$</p>
<p>$$<br>p_w e^{t^*_w} &#x3D; gt_h<br>$$</p>
<p>$$<br>p_h e^{t^*_h} &#x3D; gt_w<br>$$</p>
<p>可以求解出：$(t^*_x, t^*_y, t^*_w, t^*_h)$</p>
<p>如果$t$是网络预测的输出值，将$t^*$作为目标值，以他们之间的差距作为损失函数，则可以建立起一个回归问题，通过学习网络参数，使得$t$足够接近$t^*$，从而能够求解出预测框的位置坐标和大小。</p>
<p>预测框可以看作是在锚框基础上的一个微调，每个锚框会有一个跟它对应的预测框，我们需要确定上面计算式中的$t_x, t_y, t_w, t_h$，从而计算出与锚框对应的预测框的位置和形状。</p>
<p><strong>3）标注候选区域</strong></p>
<p>在YOLOv3中，每个区域会产生3种不同形状的锚框，每个锚框都是一个可能的候选区域，对这些候选区域我们需要了解如下几件事情：</p>
<ul>
<li>锚框是否包含物体，这可以看成是一个二分类问题，使用标签<code>objectness</code>来表示。</li>
</ul>
<p>当锚框包含了物体时，<code>objectness=1</code>，表示预测框属于正类；当锚框不包含物体时，设置<code>objectness=0</code>，表示锚框属于负类；</p>
<p>还有一种情况，有些预测框跟真实框之间的IoU很大，但并不是最大的那个，那么直接将其objectness标签设置为0当作负样本，可能并不妥当，为了避免这种情况，YOLOv3算法设置了一个IoU阈值<code>iou_threshold</code>，当预测框的objectness不为1，但是其与某个真实框的IoU大于iou_threshold时，就将其objectness标签设置为-1，不参与损失函数的计算。</p>
<ul>
<li><p>如果锚框包含了物体，那么就需要计算对应的预测框中心位置和大小应该是多少，或者说上文中的$t_x, t_y, t_w, t_h$应该是多少，使用<code>location</code>标签。</p>
</li>
<li><p>如果锚框包含了物体，那么就需要计算具体类别是什么，这里使用变量<code>label</code>来表示其所属类别的标签。</p>
</li>
</ul>
<p>总结起来，如 <strong>图8</strong> 所示。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/3b914be0c6274916bc7abe4922d4d0fb75be340172764f7096af5be0c2737c57" width = "700"></center>
<center><br>图8：标注流程示意图 </br></center>

<p><br></br></p>
<p>选取任意一个锚框对它进行标注，也就是需要确定其对应的<code>objectness</code>，<code>(t_x, t_y, t_w, t_h)</code>和<code>label</code>，下面将分别讲述如何确定这三个标签的值。</p>
<br>

<p><strong>①标注锚框是否包含物体（objectness）</strong></p>
<p>如 <strong>图9</strong> 所示，这里一共有3个目标，以最左边的人像为例，其真实框是$(133.96, 328.42, 186.06, 374.63)$。<br><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/f21679e68d2b496698ed788a16d4ea2e5bc6f82b253a44ef9508b6a4fc9b6be4" width = "600"></center>
<center><br>图9：选出与真实框中心位于同一区域的锚框 </br></center>

<p><br></br></p>
<p>真实框的中心点坐标是：</p>
<p>$$<br>center_x &#x3D; 133.96\<br>center_y &#x3D; 328.42\<br>i &#x3D; 133.96 &#x2F; 32 &#x3D; 4.18625\<br>j &#x3D; 328.42 &#x2F; 32 &#x3D; 10.263125<br>$$<br>它落在了第10行第4列的小方块内，如<strong>图10</strong>所示。此小方块区域可以生成3个不同形状的锚框，其在图上的编号和大小分别是$A_1(116, 90), A_2(156, 198), A_3(373, 326)$。</p>
<p>用这3个不同形状的锚框跟真实框计算IoU，选出IoU最大的锚框。这里为了简化计算，只考虑锚框的形状，不考虑其跟真实框中心之间的偏移，具体计算结果如 <strong>图14</strong> 所示。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/3008337ea66c44068042c670db54368edc56b1e43ced4b6b811bdc95b64ca3d5" width = "400"></center>
<center><br>图10：选出与真实框与锚框的IoU </br></center>

<p><br></br></p>
<p>其中跟真实框IoU最大的是锚框$A_3$，形状是$(373, 326)$，将它所对应的预测框的objectness标签设置为1，其所包括的物体类别就是真实框里面的物体所属类别。</p>
<p>依次可以找出其他几个真实框对应的IoU最大的锚框，然后将它们的预测框的objectness标签也都设置为1。这里一共有$20 \times 15 \times 3 &#x3D; 900$个锚框，只有3个预测框会被标注为正。</p>
<p>由于每个真实框只对应一个objectness标签为正的预测框，如果有些预测框跟真实框之间的IoU很大，但并不是最大的那个，那么直接将其objectness标签设置为0当作负样本，可能并不妥当。为了避免这种情况，YOLOv3算法设置了一个IoU阈值iou_threshold，当预测框的objectness不为1，但是其与某个真实框的IoU大于iou_threshold时，就将其objectness标签设置为-1，不参与损失函数的计算。</p>
<p>所有其他的预测框，其objectness标签均设置为0，表示负类。</p>
<p>对于objectness&#x3D;1的预测框，需要进一步确定其位置和包含物体的具体分类标签，但是对于objectness&#x3D;0或者-1的预测框，则不用管他们的位置和类别。</p>
<br>

<p><strong>②标注预测框的位置坐标标签（location）</strong></p>
<p>当锚框objectness&#x3D;1时，需要确定预测框位置相对于它微调的幅度，也就是锚框的位置标签。</p>
<p>在前面我们已经问过这样一个问题：当$t_x, t_y, t_w, t_h$取值为多少的时候，预测框能够跟真实框重合？其做法是将预测框坐标中的$b_x, b_y, b_h, b_w$设置为真实框的坐标，即可求解出$t$的数值。</p>
<p>令：<br>$$<br>\sigma(t^*_x) + c_x &#x3D; gt_x\<br>\sigma(t^*_y) + c_y &#x3D; gt_y\<br>p_w e^{t^*_w} &#x3D; gt_w\<br>p_h e^{t^*_h} &#x3D; gt_h<br>$$<br>对于$t_x^*$和$t_y^*$，由于Sigmoid的反函数不好计算，我们直接使用$\sigma(t^*_x)$和$\sigma(t^*_y)$作为回归的目标。</p>
<p>$$<br>d_x^* &#x3D; \sigma(t^*_x) &#x3D; gt_x - c_x\<br>d_y^* &#x3D; \sigma(t^*_y) &#x3D; gt_y - c_y\<br>t^*_w &#x3D; log(\frac{gt_w}{p_w})\<br>t^*_h &#x3D; log(\frac{gt_h}{p_h})<br>$$<br>如果$(t_x, t_y, t_h, t_w)$是网络预测的输出值，将$(d_x^*, d_y^*, t_w^*, t_h^*)$作为$(\sigma(t_x), \sigma(t_y), t_h, t_w)$的目标值，以它们之间的差距作为损失函数，则可以建立起一个回归问题，通过学习网络参数，使得$t$足够接近$t^*$，从而能够求解出预测框的位置。</p>
<br>

<p><strong>③标注锚框包含物体类别的标签（label）</strong></p>
<p>对于objectness&#x3D;1的锚框，需要确定其具体类别。正如上面所说，objectness标注为1的锚框，会有一个真实框跟它对应，该锚框所属物体类别，即是其所对应的真实框包含的物体类别。这里使用one-hot向量来表示类别标签label。比如一共有10个分类，而真实框里面包含的物体类别是第2类，则label为$(0,1,0,0,0,0,0,0,0,0)$</p>
<p><strong>4）标注锚框的具体程序</strong></p>
<p>最后，通过这种方式，我们在每个小方块区域都生成了一系列的锚框作为候选区域，并且根据图片上真实物体的位置，标注出了每个候选区域对应的objectness标签、位置需要调整的幅度以及包含的物体所属的类别。位置需要调整的幅度由4个变量描述$(t_x, t_y, t_w, t_h)$，objectness标签需要用一个变量描述$obj$，描述所属类别的变量长度等于类别数C。</p>
<p>对于每个锚框，模型需要预测输出$(t_x, t_y, t_w, t_h, P_{obj}, P_1, P_2,… , P_C)$，其中$P_{obj}$是锚框是否包含物体的概率，$P_1, P_2,… , P_C$则是锚框包含的物体属于每个类别的概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标注预测框的objectness</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_objectness_label</span>(<span class="params">img, gt_boxes, gt_labels, iou_threshold = <span class="number">0.7</span>,</span></span><br><span class="line"><span class="params">                         anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span></span><br><span class="line"><span class="params">                         num_classes=<span class="number">7</span>, downsample=<span class="number">32</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    img：是输入的图像数据，形状是[N, C, H, W]</span></span><br><span class="line"><span class="string">    gt_boxes：真实框，维度是[N, 50, 4]，其中50是真实框数目的上限，真实框坐标格式是xywh，这里使用相对值</span></span><br><span class="line"><span class="string">    gt_labels：真实框所属类别，维度是[N, 50]</span></span><br><span class="line"><span class="string">    iou_threshold：当预测框与真实框的iou大于iou_threshold时不将其看作是负样本</span></span><br><span class="line"><span class="string">    anchors：锚框可选的尺寸</span></span><br><span class="line"><span class="string">    anchor_masks：通过与anchors一起确定本层级的特征图应该选用多大尺寸的锚框</span></span><br><span class="line"><span class="string">    num_classes：类别数目</span></span><br><span class="line"><span class="string">    downsample：特征图相对于输入网络的图片尺寸变化的比例</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    img_shape = img.shape</span><br><span class="line">    batchsize = img_shape[<span class="number">0</span>]</span><br><span class="line">    num_anchors = <span class="built_in">len</span>(anchors) // <span class="number">2</span>		<span class="comment"># 锚框的数目</span></span><br><span class="line">    input_h = img_shape[<span class="number">2</span>]</span><br><span class="line">    input_w = img_shape[<span class="number">3</span>]</span><br><span class="line">    <span class="comment"># 将输入图片划分成num_rows x num_cols个小方块区域，每个小方块的边长是 downsample</span></span><br><span class="line">    <span class="comment"># 计算一共有多少行小方块</span></span><br><span class="line">    num_rows = input_h // downsample</span><br><span class="line">    <span class="comment"># 计算一共有多少列小方块</span></span><br><span class="line">    num_cols = input_w // downsample</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对象标签 3个</span></span><br><span class="line">    label_objectness = np.zeros([batchsize, num_anchors, num_rows, num_cols])</span><br><span class="line">    <span class="comment"># 类别标签 每个锚框7个类别</span></span><br><span class="line">    label_classification = np.zeros([batchsize, num_anchors, num_classes, num_rows, num_cols])</span><br><span class="line">    <span class="comment"># 位置坐标标签 每个锚框对应4个坐标值</span></span><br><span class="line">    label_location = np.zeros([batchsize, num_anchors, <span class="number">4</span>, num_rows, num_cols])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用来调节不同尺寸的锚框对损失函数的贡献，作为加权系数和位置损失函数相乘</span></span><br><span class="line">    scale_location = np.ones([batchsize, num_anchors, num_rows, num_cols])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对batchsize进行循环，依次处理每张图片</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(batchsize):</span><br><span class="line">        <span class="comment"># 对图片上的真实框进行循环，依次找出跟真实框形状最匹配的锚框</span></span><br><span class="line">        <span class="keyword">for</span> n_gt <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(gt_boxes[n])):</span><br><span class="line">            gt = gt_boxes[n][n_gt] <span class="comment"># 真实框</span></span><br><span class="line">            gt_cls = gt_labels[n][n_gt] <span class="comment"># 真实框所属类别</span></span><br><span class="line">            gt_center_x = gt[<span class="number">0</span>]</span><br><span class="line">            gt_center_y = gt[<span class="number">1</span>]</span><br><span class="line">            gt_width = gt[<span class="number">2</span>]</span><br><span class="line">            gt_height = gt[<span class="number">3</span>]</span><br><span class="line">            <span class="keyword">if</span> (gt_width &lt; <span class="number">1e-3</span>) <span class="keyword">or</span> (gt_height &lt; <span class="number">1e-3</span>):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            i = <span class="built_in">int</span>(gt_center_y * num_rows)</span><br><span class="line">            j = <span class="built_in">int</span>(gt_center_x * num_cols)</span><br><span class="line">            ious = []</span><br><span class="line">            <span class="keyword">for</span> ka <span class="keyword">in</span> <span class="built_in">range</span>(num_anchors):</span><br><span class="line">                bbox1 = [<span class="number">0.</span>, <span class="number">0.</span>, <span class="built_in">float</span>(gt_width), <span class="built_in">float</span>(gt_height)] <span class="comment"># 真实框</span></span><br><span class="line">                anchor_w = anchors[ka * <span class="number">2</span>]</span><br><span class="line">                anchor_h = anchors[ka * <span class="number">2</span> + <span class="number">1</span>]</span><br><span class="line">                bbox2 = [<span class="number">0.</span>, <span class="number">0.</span>, anchor_w/<span class="built_in">float</span>(input_w), anchor_h/<span class="built_in">float</span>(input_h)] <span class="comment"># 锚框</span></span><br><span class="line">                <span class="comment"># 计算iou</span></span><br><span class="line">                iou = box_iou_xywh(bbox1, bbox2)</span><br><span class="line">                ious.append(iou)</span><br><span class="line">            ious = np.array(ious)</span><br><span class="line">            inds = np.argsort(ious) <span class="comment"># 生成把ious从小到大排序后的索引</span></span><br><span class="line">            k = inds[-<span class="number">1</span>]</span><br><span class="line">            label_objectness[n, k, i, j] = <span class="number">1</span></span><br><span class="line">            c = gt_cls</span><br><span class="line">            label_classification[n, k, c, i, j] = <span class="number">1.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># for those prediction bbox with objectness =1, set label of location</span></span><br><span class="line">            dx_label = gt_center_x * num_cols - j</span><br><span class="line">            dy_label = gt_center_y * num_rows - i</span><br><span class="line">            dw_label = np.log(gt_width * input_w / anchors[k*<span class="number">2</span>])</span><br><span class="line">            dh_label = np.log(gt_height * input_h / anchors[k*<span class="number">2</span> + <span class="number">1</span>])</span><br><span class="line">            label_location[n, k, <span class="number">0</span>, i, j] = dx_label</span><br><span class="line">            label_location[n, k, <span class="number">1</span>, i, j] = dy_label</span><br><span class="line">            label_location[n, k, <span class="number">2</span>, i, j] = dw_label</span><br><span class="line">            label_location[n, k, <span class="number">3</span>, i, j] = dh_label</span><br><span class="line">            <span class="comment"># scale_location用来调节不同尺寸的锚框对损失函数的贡献，作为加权系数和位置损失函数相乘</span></span><br><span class="line">            scale_location[n, k, i, j] = <span class="number">2.0</span> - gt_width * gt_height <span class="comment"># scales--&gt;(h, w)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 目前根据每张图片上所有出现过的gt_box，都标注出了objectness为正的预测框，剩下的预测框则默认objectness为0</span></span><br><span class="line">    <span class="comment"># 对于objectness为1的预测框，标出了他们所包含的物体类别，以及位置回归的目标</span></span><br><span class="line">    <span class="keyword">return</span> label_objectness.astype(<span class="string">&#x27;float32&#x27;</span>), \</span><br><span class="line">            label_location.astype(<span class="string">&#x27;float32&#x27;</span>), \</span><br><span class="line">            label_classification.astype(<span class="string">&#x27;float32&#x27;</span>),\</span><br><span class="line">            scale_location.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算IoU，矩形框的坐标形式为xywh</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">box_iou_xywh</span>(<span class="params">box1, box2</span>):</span><br><span class="line">    x1min, y1min = box1[<span class="number">0</span>] - box1[<span class="number">2</span>]/<span class="number">2.0</span>, box1[<span class="number">1</span>] - box1[<span class="number">3</span>]/<span class="number">2.0</span></span><br><span class="line">    x1max, y1max = box1[<span class="number">0</span>] + box1[<span class="number">2</span>]/<span class="number">2.0</span>, box1[<span class="number">1</span>] + box1[<span class="number">3</span>]/<span class="number">2.0</span></span><br><span class="line">    s1 = box1[<span class="number">2</span>] * box1[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    x2min, y2min = box2[<span class="number">0</span>] - box2[<span class="number">2</span>]/<span class="number">2.0</span>, box2[<span class="number">1</span>] - box2[<span class="number">3</span>]/<span class="number">2.0</span></span><br><span class="line">    x2max, y2max = box2[<span class="number">0</span>] + box2[<span class="number">2</span>]/<span class="number">2.0</span>, box2[<span class="number">1</span>] + box2[<span class="number">3</span>]/<span class="number">2.0</span></span><br><span class="line">    s2 = box2[<span class="number">2</span>] * box2[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    xmin = np.maximum(x1min, x2min)</span><br><span class="line">    ymin = np.maximum(y1min, y2min)</span><br><span class="line">    xmax = np.minimum(x1max, x2max)</span><br><span class="line">    ymax = np.minimum(y1max, y2max)</span><br><span class="line">    inter_h = np.maximum(ymax - ymin, <span class="number">0.</span>)</span><br><span class="line">    inter_w = np.maximum(xmax - xmin, <span class="number">0.</span>)</span><br><span class="line">    intersection = inter_h * inter_w</span><br><span class="line"></span><br><span class="line">    union = s1 + s2 - intersection</span><br><span class="line">    iou = intersection / union</span><br><span class="line">    <span class="keyword">return</span> iou </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">TRAINDIR = <span class="string">&#x27;/home/aistudio/work/insects/train&#x27;</span></span><br><span class="line">TESTDIR = <span class="string">&#x27;/home/aistudio/work/insects/test&#x27;</span></span><br><span class="line">VALIDDIR = <span class="string">&#x27;/home/aistudio/work/insects/val&#x27;</span></span><br><span class="line">train_dataset = TrainDataset(TRAINDIR, mode=<span class="string">&#x27;train&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line">reader = paddle.io.DataLoader(</span><br><span class="line">                            train_dataset, </span><br><span class="line">                            batch_size=<span class="number">2</span>, </span><br><span class="line">                            shuffle=<span class="literal">True</span>, </span><br><span class="line">                            num_workers=<span class="number">1</span>, </span><br><span class="line">                            drop_last=<span class="literal">True</span>)</span><br><span class="line">img, gt_boxes, gt_labels, im_shape = <span class="built_in">next</span>(reader())</span><br><span class="line">img, gt_boxes, gt_labels, im_shape = img.numpy(), gt_boxes.numpy(), gt_labels.numpy(), im_shape.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算出锚框对应的标签</span></span><br><span class="line">label_objectness, \</span><br><span class="line">label_location, \</span><br><span class="line">label_classification, \</span><br><span class="line">scale_location \</span><br><span class="line">= get_objectness_label(img, gt_boxes, gt_labels, </span><br><span class="line">                        iou_threshold = <span class="number">0.7</span>,</span><br><span class="line">                        anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span><br><span class="line">                        num_classes=<span class="number">7</span>, downsample=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img.shape, gt_boxes.shape, gt_labels.shape, im_shape.shape</span><br></pre></td></tr></table></figure>


<pre><code>((2, 3, 640, 640), (2, 50, 4), (2, 50), (2, 2))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (批量，锚框数，偏移量/类别数，h，w)</span></span><br><span class="line">label_objectness.shape, label_location.shape, label_classification.shape, scale_location.shape</span><br></pre></td></tr></table></figure>


<pre><code>((2, 3, 20, 20), (2, 3, 4, 20, 20), (2, 3, 7, 20, 20), (2, 3, 20, 20))
</code></pre>
<p>上面的程序实现了对锚框进行标注，对于每个真实框，选出了与它形状最匹配的锚框，将其objectness标注为1，并且将$[d_x^*, d_y^*, t_h^*, t_w^*]$作为正样本位置的标签，真实框包含的物体类别作为锚框的类别。而其余的锚框，objectness将被标注为0，无需标注出位置和类别的标签。</p>
<p><strong>注意</strong>：这里还遗留一个小问题，前面我们说了对于与真实框IoU较大的那些锚框，需要将其objectness标注为-1，不参与损失函数的计算。我们先将这个问题放一放，等到后面建立损失函数的时候再补上。</p>
<h3 id="3-2-卷积网络提取特征"><a href="#3-2-卷积网络提取特征" class="headerlink" title="3.2 卷积网络提取特征"></a><strong>3.2 卷积网络提取特征</strong></h3><p>在上一节图像分类的课程中，我们已经学习过了通过卷积神经网络提取图像特征。通过连续使用多层卷积和池化等操作，能得到语义含义更加丰富的特征图。在检测问题中，也使用卷积神经网络逐层提取图像特征，通过最终的输出特征图来表征物体位置和类别等信息。</p>
<p><strong>骨干网络[backbone]</strong></p>
<p>YOLOv3算法使用的骨干网络是<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_48167570/article/details/120688156">Darknet53</a>。Darknet53网络的具体结构如 <strong>图11</strong> 所示：</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/d5cb1e88d3f44259be1427a90ee454a57738ee8083ad40269f5485988526f30d" width = "400"></center>
<center><br>图11：Darknet53网络结构 </br></center>

<p><br></br></p>
<p>在检测任务中，将图中C0后面的平均池化、全连接层和Softmax去掉，保留从输入到C0部分的网络结构，作为检测模型的基础网络结构，也称为骨干网络。YOLOv3模型会在骨干网络的基础上，再添加检测相关的网络模块。</p>
<hr>
<blockquote>
<ul>
<li><strong>名词解释</strong>：特征图的步幅</li>
</ul>
<p>在提取特征的过程中通常会使用步幅大于1的卷积或者池化，导致后面的特征图尺寸越来越小，<strong>特征图的步幅等于输入图片尺寸除以特征图尺寸</strong>。</p>
<p>例如：C0的尺寸是$20\times20$，原图尺寸是$640\times640$，则C0的步幅是$\frac{640}{20}&#x3D;32$。同理，C1的步幅是16，C2的步幅是8。</p>
</blockquote>
<hr>
<p>下面的程序是Darknet53骨干网络的实现代码，这里将上图中C0、C1、C2所表示的输出数据取出，并查看它们的形状分别是，$C0 [1, 1024, 20, 20]$，$C1 [1, 512, 40, 40]$，$C2 [1, 256, 80, 80]$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将卷积和批归一化封装为ConvBNLayer，方便后续复用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNLayer</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch_in, ch_out, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, groups=<span class="number">1</span>, padding=<span class="number">0</span>, act=<span class="string">&quot;leaky&quot;</span></span>):</span><br><span class="line">        <span class="comment"># act为激活函数</span></span><br><span class="line">        <span class="comment"># kernel_size=3 表示使用了3×3的卷积核</span></span><br><span class="line">        <span class="comment"># stride=1 表示步幅为1</span></span><br><span class="line">        <span class="built_in">super</span>(ConvBNLayer, self).__init__()</span><br><span class="line">        <span class="comment"># 创建卷积层</span></span><br><span class="line">        self.conv = paddle.nn.Conv2D(</span><br><span class="line">            in_channels=ch_in,</span><br><span class="line">            out_channels=ch_out,</span><br><span class="line">            kernel_size=kernel_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            padding=padding,</span><br><span class="line">            groups=groups,</span><br><span class="line">            <span class="comment"># 随机正态（高斯）分布初始化函数</span></span><br><span class="line">            weight_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Normal(<span class="number">0.</span>, <span class="number">0.02</span>)),</span><br><span class="line">            bias_attr=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 创建批归一化层</span></span><br><span class="line">        self.batch_norm = paddle.nn.BatchNorm2D(</span><br><span class="line">            num_features=ch_out,</span><br><span class="line">            weight_attr=paddle.ParamAttr(</span><br><span class="line">                <span class="comment"># 将参数随机初始化</span></span><br><span class="line">                initializer=paddle.nn.initializer.Normal(<span class="number">0.</span>, <span class="number">0.02</span>),</span><br><span class="line">                <span class="comment"># L2 权重衰减正则化，默认正则化系数为0.</span></span><br><span class="line">                regularizer=paddle.regularizer.L2Decay(<span class="number">0.</span>)),</span><br><span class="line">            bias_attr=paddle.ParamAttr(</span><br><span class="line">                initializer=paddle.nn.initializer.Constant(<span class="number">0.0</span>),</span><br><span class="line">                regularizer=paddle.regularizer.L2Decay(<span class="number">0.</span>)))</span><br><span class="line">        self.act = act</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):	<span class="comment"># 输入传入</span></span><br><span class="line">        out = self.conv(inputs)	<span class="comment"># 卷积</span></span><br><span class="line">        out = self.batch_norm(out)	<span class="comment"># 批量归一化</span></span><br><span class="line">        <span class="keyword">if</span> self.act == <span class="string">&#x27;leaky&#x27;</span>:</span><br><span class="line">            out = F.leaky_relu(x=out, negative_slope=<span class="number">0.1</span>)	<span class="comment"># 放入激活函数</span></span><br><span class="line">        <span class="keyword">return</span> out	<span class="comment"># 输出结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义下采样模块，使图片尺寸减半，每次运行完后高宽减半</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DownSample</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 ch_in,</span></span><br><span class="line"><span class="params">                 ch_out,</span></span><br><span class="line"><span class="params">                 kernel_size=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 stride=<span class="number">2</span>,</span></span><br><span class="line"><span class="params">                 padding=<span class="number">1</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(DownSample, self).__init__()</span><br><span class="line">        <span class="comment"># 使用 stride=2 的卷积，可以使图片尺寸减半</span></span><br><span class="line">        self.conv_bn_layer = ConvBNLayer(</span><br><span class="line">            ch_in=ch_in,</span><br><span class="line">            ch_out=ch_out,</span><br><span class="line">            kernel_size=kernel_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            padding=padding)</span><br><span class="line">        self.ch_out = ch_out</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        out = self.conv_bn_layer(inputs)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义残差块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;	</span></span><br><span class="line"><span class="string">    基本残差块的定义，输入x经过两层卷积，然后接第二层卷积的输出和输入x相加</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch_in, ch_out</span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        <span class="comment"># 第一个卷积层</span></span><br><span class="line">        self.conv1 = ConvBNLayer(</span><br><span class="line">            ch_in=ch_in,</span><br><span class="line">            ch_out=ch_out,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">0</span></span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 第二个卷积层</span></span><br><span class="line">        self.conv2 = ConvBNLayer(</span><br><span class="line">            ch_in=ch_out,</span><br><span class="line">            ch_out=ch_out*<span class="number">2</span>,	<span class="comment"># 输出通道×2</span></span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        conv1 = self.conv1(inputs)</span><br><span class="line">        conv2 = self.conv2(conv1)</span><br><span class="line">        <span class="comment"># 将第二个卷积层的输出和最初的输入值按元素对应位置相加（前提：形状不变）</span></span><br><span class="line">        out = paddle.add(x=inputs, y=conv2)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将多个残差块封装为一个层级，方便后续复用     </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LayerWarp</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    添加多层（count）残差块，组成Darknet53网络的一个层级</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch_in, ch_out, count, is_test=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LayerWarp,self).__init__()</span><br><span class="line">        self.basicblock0 = BasicBlock(ch_in, ch_out)</span><br><span class="line">        self.res_out_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, count):</span><br><span class="line">            <span class="comment"># 使用add_sublayer添加子层</span></span><br><span class="line">            res_out = self.add_sublayer(<span class="string">&quot;basic_block_%d&quot;</span> % (i),</span><br><span class="line">                BasicBlock(ch_out*<span class="number">2</span>, ch_out))</span><br><span class="line">            self.res_out_list.append(res_out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,inputs</span>):</span><br><span class="line">        y = self.basicblock0(inputs)</span><br><span class="line">        <span class="keyword">for</span> basic_block_i <span class="keyword">in</span> self.res_out_list:</span><br><span class="line">            y = basic_block_i(y)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="comment"># DarkNet 每组残差块的个数，来自DarkNet的网络结构图</span></span><br><span class="line">DarkNet_cfg = &#123;<span class="number">53</span>: ([<span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">4</span>])&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DarkNet53骨干网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DarkNet53_conv_body</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DarkNet53_conv_body, self).__init__()</span><br><span class="line">        self.stages = DarkNet_cfg[<span class="number">53</span>]</span><br><span class="line">        self.stages = self.stages[<span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第一层卷积</span></span><br><span class="line">        self.conv0 = ConvBNLayer(</span><br><span class="line">            ch_in=<span class="number">3</span>,</span><br><span class="line">            ch_out=<span class="number">32</span>,</span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下采样，使用stride=2的卷积来实现</span></span><br><span class="line">        self.downsample0 = DownSample(</span><br><span class="line">            ch_in=<span class="number">32</span>,</span><br><span class="line">            ch_out=<span class="number">32</span> * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 添加各个层级的实现</span></span><br><span class="line">        self.darknet53_conv_block_list = []</span><br><span class="line">        self.downsample_list = []</span><br><span class="line">        <span class="keyword">for</span> i, stage <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.stages):</span><br><span class="line">            conv_block = self.add_sublayer(</span><br><span class="line">                <span class="string">&quot;stage_%d&quot;</span> % (i),</span><br><span class="line">                LayerWarp(<span class="number">32</span>*(<span class="number">2</span>**(i+<span class="number">1</span>)),</span><br><span class="line">                <span class="number">32</span>*(<span class="number">2</span>**i),</span><br><span class="line">                stage))</span><br><span class="line">            self.darknet53_conv_block_list.append(conv_block)</span><br><span class="line">        <span class="comment"># 两个层级之间使用DownSample将尺寸减半</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.stages) - <span class="number">1</span>):</span><br><span class="line">            downsample = self.add_sublayer(</span><br><span class="line">                <span class="string">&quot;stage_%d_downsample&quot;</span> % i,</span><br><span class="line">                DownSample(ch_in=<span class="number">32</span>*(<span class="number">2</span>**(i+<span class="number">1</span>)),</span><br><span class="line">                    ch_out=<span class="number">32</span>*(<span class="number">2</span>**(i+<span class="number">2</span>))))</span><br><span class="line">            self.downsample_list.append(downsample)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,inputs</span>):</span><br><span class="line">        out = self.conv0(inputs)</span><br><span class="line">        <span class="comment">#print(&quot;conv1:&quot;,out.numpy())</span></span><br><span class="line">        out = self.downsample0(out)</span><br><span class="line">        <span class="comment">#print(&quot;downsample:&quot;,out.numpy())</span></span><br><span class="line">        blocks = []</span><br><span class="line">        <span class="comment"># 依次将各个层级作用在输入上面</span></span><br><span class="line">        <span class="keyword">for</span> i, conv_block_i <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.darknet53_conv_block_list):</span><br><span class="line">            out = conv_block_i(out)</span><br><span class="line">            blocks.append(out)</span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(self.stages) - <span class="number">1</span>:</span><br><span class="line">                out = self.downsample_list[i](out)</span><br><span class="line">        <span class="comment"># 将C0, C1, C2作为返回值</span></span><br><span class="line">        <span class="keyword">return</span> blocks[-<span class="number">1</span>:-<span class="number">4</span>:-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>下面这段示例代码，指定输入数据的形状是$(1, 3, 640, 640)$，则3个层级的输出特征图的形状分别是$C0 (1, 1024, 20, 20)$，$C1 (1, 512, 40, 40)$和$C2 (1, 256, 80, 80)$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Darknet53网络输出特征图</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">x = np.random.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">640</span>, <span class="number">640</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line"><span class="built_in">print</span>(C0.shape, C1.shape, C2.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 1024, 20, 20] [1, 512, 40, 40] [1, 256, 80, 80]
</code></pre>
<h2 id="4-根据输出特征图计算预测框位置和类别"><a href="#4-根据输出特征图计算预测框位置和类别" class="headerlink" title="4.根据输出特征图计算预测框位置和类别"></a>4.根据输出特征图计算预测框位置和类别</h2><p>YOLOv3中对每个预测框计算逻辑如下：</p>
<ul>
<li><p>预测框是否包含物体。也可理解为objectness&#x3D;1的概率是多少，可以用网络输出一个实数$x$，可以用$Sigmoid(x)$表示objectness为正的概率$P_{obj}$</p>
</li>
<li><p>预测物体位置和形状。物体位置和形状$t_x, t_y, t_w, t_h$可以用网络输出4个实数来表示$t_x, t_y, t_w, t_h$</p>
</li>
<li><p>预测物体类别。预测图像中物体的具体类别是什么，或者说其属于每个类别的概率分别是多少。总的类别数为C，需要预测物体属于每个类别的概率$(P_1, P_2, …, P_C)$，可以用网络输出C个实数$(x_1, x_2, …, x_C)$，对每个实数分别求Sigmoid函数，让$P_i &#x3D; Sigmoid(x_i)$，则可以表示出物体属于每个类别的概率。</p>
</li>
</ul>
<p>对于一个预测框，网络需要输出$(5 + C)$个实数来表征它是否包含物体、位置和形状尺寸以及属于每个类别的概率。由于我们在每个小方块区域都生成了K个预测框，则所有预测框一共需要网络输出的预测值数目是：</p>
<p>$$<br>[K(5 + C)] \times m \times n<br>$$<br>还有更重要的一点是网络输出必须要能区分出小方块区域的位置来，不能直接将特征图连接一个输出大小为$[K(5 + C)] \times m \times n$的全连接层。</p>
<h3 id="4-1建立输出特征图与预测框之间的关联"><a href="#4-1建立输出特征图与预测框之间的关联" class="headerlink" title="4.1建立输出特征图与预测框之间的关联"></a><strong>4.1建立输出特征图与预测框之间的关联</strong></h3><p>现在观察特征图，经过多次卷积核池化之后，其步幅stride&#x3D;32，$640 \times 480$大小的输入图片变成了$20\times15$的特征图；而小方块区域的数目正好是$20\times15$，也就是说可以让特征图上每个像素点分别跟原图上一个小方块区域对应。这也是为什么我们最开始将小方块区域的尺寸设置为32的原因，这样可以巧妙的将小方块区域跟特征图上的像素点对应起来，解决了空间位置的对应关系。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/59bd2592dd9f4f4dada8333307198888e667b15969ce434eb52c0232d9608a62" width = "600"></center>
<center><br>图12：特征图C0与小方块区域形状对比 </br></center>

<p><br></br></p>
<p>下面需要将像素点$(i,j)$与第i行第j列的小方块区域所需要的预测值关联起来，每个小方块区域产生K个预测框，每个预测框需要$(5 + C)$个实数预测值，则每个像素点相对应的要有$K(5 + C)$个实数。为了解决这一问题，对特征图进行多次卷积，并将最终的输出通道数设置为$K(5 + C)$，即可将生成的特征图与每个预测框所需要的预测值巧妙的对应起来。当然，这种对应是为了将骨干网络提取的特征对接输出层来形成Loss。实际中，这几个尺寸可以随着任务数据分布的不同而调整，只要保证特征图输出尺寸（控制卷积核和下采样）和输出层尺寸（控制小方块区域的大小）相同即可。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/f1d445d77cd84c60897ade92cc24f951a7672a72dc6f43b8aeb6932b6db778d6" width = "600"></center>
<center><br>图13：特征图C0与小方块区域一一对应 </br></center>

<p><br></br></p>
<p>骨干网络的输出特征图是C0，下面的程序是对C0进行多次卷积以得到跟预测框相关的特征图P0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 YOLOv3 后续连接的网络层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YoloDetectionBlock</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="comment"># 使用多层卷积和BN提取特征</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,ch_in,ch_out,is_test=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(YoloDetectionBlock, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> ch_out % <span class="number">2</span> == <span class="number">0</span>, \</span><br><span class="line">            <span class="string">&quot;channel &#123;&#125; cannot be divided by 2&quot;</span>.<span class="built_in">format</span>(ch_out)</span><br><span class="line"></span><br><span class="line">        self.conv0 = ConvBNLayer(</span><br><span class="line">            ch_in=ch_in,</span><br><span class="line">            ch_out=ch_out,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">0</span>)</span><br><span class="line">        self.conv1 = ConvBNLayer(</span><br><span class="line">            ch_in=ch_out,</span><br><span class="line">            ch_out=ch_out*<span class="number">2</span>,</span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = ConvBNLayer(</span><br><span class="line">            ch_in=ch_out*<span class="number">2</span>,</span><br><span class="line">            ch_out=ch_out,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">0</span>)</span><br><span class="line">        self.conv3 = ConvBNLayer(</span><br><span class="line">            ch_in=ch_out,</span><br><span class="line">            ch_out=ch_out*<span class="number">2</span>,</span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线性层</span></span><br><span class="line">        self.route = ConvBNLayer(</span><br><span class="line">            ch_in=ch_out*<span class="number">2</span>,</span><br><span class="line">            ch_out=ch_out,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 最末层</span></span><br><span class="line">        self.tip = ConvBNLayer(</span><br><span class="line">            ch_in=ch_out,</span><br><span class="line">            ch_out=ch_out*<span class="number">2</span>,</span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        out = self.conv0(inputs)</span><br><span class="line">        out = self.conv1(out)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        route = self.route(out)</span><br><span class="line">        tip = self.tip(route)</span><br><span class="line">        <span class="keyword">return</span> route, tip</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">NUM_ANCHORS = <span class="number">3</span> <span class="comment"># 锚框数</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span> <span class="comment"># 类别数</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred = paddle.nn.Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">640</span>, <span class="number">640</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(P0.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 36, 20, 20]
填充的存在大小不会发生变化
</code></pre>
<p>如上面的代码所示，可以由特征图C0生成特征图P0，P0的形状是$[1, 36, 20, 20]$。每个小方块区域生成的锚框或者预测框的数量是3，物体类别数目是7，每个区域需要的预测值个数是$3 \times (5 + 7) &#x3D; 36$，正好等于P0的输出通道数。</p>
<p>将$P0[t, 0:12, i, j]$与输入的第t张图片上小方块区域$(i, j)$第1个预测框所需要的12个预测值对应，$P0[t, 12:24, i, j]$与输入的第t张图片上小方块区域$(i, j)$第2个预测框所需要的12个预测值对应，$P0[t, 24:36, i, j]$与输入的第t张图片上小方块区域$(i, j)$第3个预测框所需要的12个预测值对应。</p>
<p>$P0[t, 0:4, i, j]$与输入的第t张图片上小方块区域$(i, j)$第1个预测框的位置对应，$P0[t, 4, i, j]$与输入的第t张图片上小方块区域$(i, j)$第1个预测框的objectness对应，$P0[t, 5:12, i, j]$与输入的第t张图片上小方块区域$(i, j)$第1个预测框的类别对应。</p>
<p>如 <strong>图14</strong> 所示，通过这种方式可以巧妙的将网络输出特征图，与每个小方块区域生成的预测框对应起来了。<br><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/9ea44b2c11f74f1484ab2bdc93be4008008cdee0b8d34dcb97bc9f89af935d1c" width = "800"></center>
<center><br>图14：特征图P0与候选区域的关联 </br></center>

<p><br></br></p>
<h3 id="4-2计算预测框是否包含物体的概率"><a href="#4-2计算预测框是否包含物体的概率" class="headerlink" title="4.2计算预测框是否包含物体的概率"></a><strong>4.2计算预测框是否包含物体的概率</strong></h3><p>根据前面的分析，$P0[t, 4, i, j]$与输入的第t张图片上小方块区域$(i, j)$第1个预测框的objectness对应，$P0[t, 4+12, i, j]$与第2个预测框的objectness对应，…，则可以使用下面的程序将objectness相关的预测取出，并使用<code>paddle.nn.functional.sigmoid</code>计算输出概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">NUM_ANCHORS = <span class="number">3</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred = paddle.nn.Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters,  kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">640</span>, <span class="number">640</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"></span><br><span class="line">reshaped_p0 = paddle.reshape(P0, [-<span class="number">1</span>, NUM_ANCHORS, NUM_CLASSES + <span class="number">5</span>, P0.shape[<span class="number">2</span>], P0.shape[<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(P0.shape, reshaped_p0.shape)</span><br><span class="line">pred_objectness = reshaped_p0[:, :, <span class="number">4</span>, :, :]</span><br><span class="line">pred_objectness_probability = F.sigmoid(pred_objectness)</span><br><span class="line"><span class="built_in">print</span>(pred_objectness.shape, pred_objectness_probability.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 36, 20, 20] [1, 3, 12, 20, 20]
[1, 3, 20, 20] [1, 3, 20, 20]
</code></pre>
<p>上面的输出程序显示，预测框是否包含物体的概率<code>pred_objectness_probability</code>，其数据形状是[1, 3, 20, 20]，与我们上面提到的预测框个数一致，数据大小在0～1之间，表示预测框为正样本的概率。</p>
<h3 id="4-3计算预测框位置坐标"><a href="#4-3计算预测框位置坐标" class="headerlink" title="4.3计算预测框位置坐标"></a><strong>4.3计算预测框位置坐标</strong></h3><p>$P0[t, 0:4, i, j]$与输入的第$t$张图片上小方块区域$(i, j)$第1个预测框的位置对应，$P0[t, 12:16, i, j]$与第2个预测框的位置对应，依此类推，则使用下面的程序可以从$P0$中取出跟预测框位置相关的预测值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">NUM_ANCHORS = <span class="number">3</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred =  paddle.nn.Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters,  kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">640</span>, <span class="number">640</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reshaped_p0 = paddle.reshape(P0, [-<span class="number">1</span>, NUM_ANCHORS, NUM_CLASSES + <span class="number">5</span>, P0.shape[<span class="number">2</span>], P0.shape[<span class="number">3</span>]])</span><br><span class="line">pred_objectness = reshaped_p0[:, :, <span class="number">4</span>, :, :]</span><br><span class="line">pred_objectness_probability = F.sigmoid(pred_objectness)</span><br><span class="line"></span><br><span class="line">pred_location = reshaped_p0[:, :, <span class="number">0</span>:<span class="number">4</span>, :, :]</span><br><span class="line"><span class="built_in">print</span>(pred_location.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 3, 4, 20, 20]
</code></pre>
<p>网络输出值是$(t_x, t_y, t_w, t_h)$，还需要将其转化为$(x_1, y_1, x_2, y_2)$这种形式的坐标表示。我们使用Numpy来实现这一过程。在后面的代码中使用飞桨<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/ops/yolo_box_cn.html#yolo-box">paddle.vision.ops.yolo_box</a> API可以直接计算出结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义Sigmoid函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span>/(<span class="number">1.0</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将网络特征图输出的[tx, ty, th, tw]转化成预测框的坐标[x1, y1, x2, y2]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_yolo_box_xxyy</span>(<span class="params">pred, anchors, num_classes, downsample</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    pred是网络输出特征图转化成的numpy.ndarray</span></span><br><span class="line"><span class="string">    anchors 是一个list。表示锚框的大小，</span></span><br><span class="line"><span class="string">                例如 anchors = [116, 90, 156, 198, 373, 326]，表示有三个锚框，</span></span><br><span class="line"><span class="string">                第一个锚框大小[w, h]是[116, 90]，第二个锚框大小是[156, 198]，第三个锚框大小是[373, 326]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batchsize = pred.shape[<span class="number">0</span>]</span><br><span class="line">    num_rows = pred.shape[-<span class="number">2</span>]</span><br><span class="line">    num_cols = pred.shape[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    input_h = num_rows * downsample</span><br><span class="line">    input_w = num_cols * downsample</span><br><span class="line"></span><br><span class="line">    num_anchors = <span class="built_in">len</span>(anchors) // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># pred的形状是[N, C, H, W]，其中C = NUM_ANCHORS * (5 + NUM_CLASSES)</span></span><br><span class="line">    <span class="comment"># 对pred进行reshape</span></span><br><span class="line">    pred = pred.reshape([-<span class="number">1</span>, num_anchors, <span class="number">5</span>+num_classes, num_rows, num_cols])</span><br><span class="line">    pred_location = pred[:, :, <span class="number">0</span>:<span class="number">4</span>, :, :]</span><br><span class="line">    pred_location = np.transpose(pred_location, (<span class="number">0</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>)) <span class="comment"># [N, H, W, NUM_ANCHORS, 4]</span></span><br><span class="line">    anchors_this = [] <span class="comment"># 输出锚框</span></span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(num_anchors):</span><br><span class="line">        anchors_this.append([anchors[ind*<span class="number">2</span>], anchors[ind*<span class="number">2</span>+<span class="number">1</span>]])</span><br><span class="line">    anchors_this = np.array(anchors_this).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 最终输出数据保存在pred_box中，其形状是[N, H, W, NUM_ANCHORS, 4]，</span></span><br><span class="line">    <span class="comment"># 其中最后一个维度4代表位置的4个坐标</span></span><br><span class="line">    pred_box = np.zeros(pred_location.shape)</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(batchsize):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_rows):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_cols):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(num_anchors):</span><br><span class="line">                    pred_box[n, i, j, k, <span class="number">0</span>] = j</span><br><span class="line">                    pred_box[n, i, j, k, <span class="number">1</span>] = i</span><br><span class="line">                    pred_box[n, i, j, k, <span class="number">2</span>] = anchors_this[k][<span class="number">0</span>]</span><br><span class="line">                    pred_box[n, i, j, k, <span class="number">3</span>] = anchors_this[k][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里使用相对坐标，pred_box的输出元素数值在0.~1.0之间</span></span><br><span class="line">    pred_box[:, :, :, :, <span class="number">0</span>] = (sigmoid(pred_location[:, :, :, :, <span class="number">0</span>]) + pred_box[:, :, :, :, <span class="number">0</span>]) / num_cols</span><br><span class="line">    pred_box[:, :, :, :, <span class="number">1</span>] = (sigmoid(pred_location[:, :, :, :, <span class="number">1</span>]) + pred_box[:, :, :, :, <span class="number">1</span>]) / num_rows</span><br><span class="line">    pred_box[:, :, :, :, <span class="number">2</span>] = np.exp(pred_location[:, :, :, :, <span class="number">2</span>]) * pred_box[:, :, :, :, <span class="number">2</span>] / input_w</span><br><span class="line">    pred_box[:, :, :, :, <span class="number">3</span>] = np.exp(pred_location[:, :, :, :, <span class="number">3</span>]) * pred_box[:, :, :, :, <span class="number">3</span>] / input_h</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将坐标从xywh转化成xyxy</span></span><br><span class="line">    pred_box[:, :, :, :, <span class="number">0</span>] = pred_box[:, :, :, :, <span class="number">0</span>] - pred_box[:, :, :, :, <span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line">    pred_box[:, :, :, :, <span class="number">1</span>] = pred_box[:, :, :, :, <span class="number">1</span>] - pred_box[:, :, :, :, <span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line">    pred_box[:, :, :, :, <span class="number">2</span>] = pred_box[:, :, :, :, <span class="number">0</span>] + pred_box[:, :, :, :, <span class="number">2</span>]</span><br><span class="line">    pred_box[:, :, :, :, <span class="number">3</span>] = pred_box[:, :, :, :, <span class="number">1</span>] + pred_box[:, :, :, :, <span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 截取 np.clip(a, a_min, a_max, out=None)</span></span><br><span class="line">    pred_box = np.clip(pred_box, <span class="number">0.</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pred_box</span><br></pre></td></tr></table></figure>

<p>通过调用上面定义的<code>get_yolo_box_xxyy</code>函数，可以从$P0$计算出预测框坐标来，具体程序如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">NUM_ANCHORS = <span class="number">3</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred = paddle.nn.Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters,  kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">640</span>, <span class="number">640</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"></span><br><span class="line">reshaped_p0 = paddle.reshape(P0, [-<span class="number">1</span>, NUM_ANCHORS, NUM_CLASSES + <span class="number">5</span>, P0.shape[<span class="number">2</span>], P0.shape[<span class="number">3</span>]])</span><br><span class="line">pred_objectness = reshaped_p0[:, :, <span class="number">4</span>, :, :]</span><br><span class="line">pred_objectness_probability = F.sigmoid(pred_objectness)</span><br><span class="line"></span><br><span class="line">pred_location = reshaped_p0[:, :, <span class="number">0</span>:<span class="number">4</span>, :, :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># anchors包含了预先设定好的锚框尺寸</span></span><br><span class="line">anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>]</span><br><span class="line"><span class="comment"># downsample 是特征图P0的步幅</span></span><br><span class="line"><span class="comment"># 由输出特征图P0计算预测框位置坐标</span></span><br><span class="line">pred_boxes = get_yolo_box_xxyy(P0.numpy(), anchors, num_classes=<span class="number">7</span>, downsample=<span class="number">32</span>)</span><br><span class="line"><span class="built_in">print</span>(pred_location.shape, pred_boxes.shape)</span><br><span class="line"><span class="built_in">print</span>(pred_boxes[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>].shape, pred_boxes[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]) <span class="comment"># 一个中心三个锚框 location</span></span><br></pre></td></tr></table></figure>

<pre><code>[1, 3, 4, 20, 20] (1, 20, 20, 3, 4)
(3, 4) [[0.         0.         0.11592992 0.09357996]
 [0.         0.         0.14583146 0.17757062]
 [0.         0.         0.32789061 0.26856107]]
</code></pre>
<h3 id="4-4计算物体属于每个类别概率"><a href="#4-4计算物体属于每个类别概率" class="headerlink" title="4.4计算物体属于每个类别概率"></a><strong>4.4计算物体属于每个类别概率</strong></h3><p>$P0[t, 5:12, i, j]$与输入的第$t$张图片上小方块区域$(i, j)$第1个预测框包含物体的类别对应，$P0[t, 17:24, i, j]$与第2个预测框的类别对应，依此类推，则使用下面的程序可以从$P0$中取出那些跟预测框类别相关的预测值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">NUM_ANCHORS = <span class="number">3</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred = paddle.nn.Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters,  kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">640</span>, <span class="number">640</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"></span><br><span class="line">reshaped_p0 = paddle.reshape(P0, [-<span class="number">1</span>, NUM_ANCHORS, NUM_CLASSES + <span class="number">5</span>, P0.shape[<span class="number">2</span>], P0.shape[<span class="number">3</span>]])</span><br><span class="line"><span class="comment"># 取出与objectness相关的预测值</span></span><br><span class="line">pred_objectness = reshaped_p0[:, :, <span class="number">4</span>, :, :]</span><br><span class="line">pred_objectness_probability = F.sigmoid(pred_objectness)</span><br><span class="line"><span class="comment"># 取出与位置相关的预测值</span></span><br><span class="line">pred_location = reshaped_p0[:, :, <span class="number">0</span>:<span class="number">4</span>, :, :]</span><br><span class="line"><span class="comment"># 取出与类别相关的预测值</span></span><br><span class="line">pred_classification = reshaped_p0[:, :, <span class="number">5</span>:<span class="number">5</span>+NUM_CLASSES, :, :]</span><br><span class="line">pred_classification_probability = F.sigmoid(pred_classification)</span><br><span class="line"><span class="built_in">print</span>(pred_objectness_probability.shape, pred_location.shape, pred_classification.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 3, 20, 20] [1, 3, 4, 20, 20] [1, 3, 7, 20, 20]
</code></pre>
<p>上面的程序通过$P0$计算出了预测框包含的物体所属类别的概率，<code>pred_classification_probability</code>的形状是$[1, 3, 7, 20, 20]$，数值在0~1之间。</p>
<h2 id="5-损失函数"><a href="#5-损失函数" class="headerlink" title="5.损失函数"></a><strong>5.损失函数</strong></h2><p>上面从概念上将输出特征图上的像素点与预测框关联起来了，那么要对神经网络进行求解，还必须从数学上将网络输出和预测框关联起来，也就是要建立起损失函数跟网络输出之间的关系。下面讨论如何建立起YOLOv3的损失函数。</p>
<p>对于每个预测框，YOLOv3模型会建立三种类型的损失函数：</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/fc7bbc5436d84fb0bb18b817125947cbd441dbdef7ae4365b55da5188ea161b8" width = "800"></center>
<center><br>图15：损失函数的建立思路 </br></center>

<p><br></br></p>
<ul>
<li><p>表征是否包含目标物体的损失函数，通过pred_objectness和label_objectness计算。</p>
<pre><code>loss_obj = paddle.nn.fucntional.binary_cross_entropy_with_logits(pred_objectness, label_objectness)
</code></pre>
</li>
<li><p>表征物体位置的损失函数，通过pred_location和label_location计算。</p>
<pre><code>pred_location_x = pred_location[:, :, 0, :, :]
pred_location_y = pred_location[:, :, 1, :, :]
pred_location_w = pred_location[:, :, 2, :, :]
pred_location_h = pred_location[:, :, 3, :, :]
loss_location_x = paddle.nn.fucntional.binary_cross_entropy_with_logits(pred_location_x, label_location_x)
loss_location_y = paddle.nn.fucntional.binary_cross_entropy_with_logits(pred_location_y, label_location_y)
loss_location_w = paddle.abs(pred_location_w - label_location_w)
loss_location_h = paddle.abs(pred_location_h - label_location_h)
loss_location = loss_location_x + loss_location_y + loss_location_w + loss_location_h
</code></pre>
</li>
<li><p>表征物体类别的损失函数，通过pred_classification和label_classification计算。</p>
<pre><code>loss_obj = paddle.nn.fucntional.binary_cross_entropy_with_logits(pred_classification, label_classification)
</code></pre>
</li>
</ul>
<p>我们已经知道怎么计算这些预测值和标签了，但是遗留了一个小问题，就是没有标注出哪些锚框的objectness为-1。为了完成这一步，我们需要计算出所有预测框跟真实框之间的IoU，然后把那些IoU大于阈值的真实框挑选出来。实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 挑选出跟真实框IoU大于阈值的预测框</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_iou_above_thresh_inds</span>(<span class="params">pred_box, gt_boxes, iou_threshold</span>):</span><br><span class="line">    batchsize = pred_box.shape[<span class="number">0</span>]</span><br><span class="line">    num_rows = pred_box.shape[<span class="number">1</span>]</span><br><span class="line">    num_cols = pred_box.shape[<span class="number">2</span>]</span><br><span class="line">    num_anchors = pred_box.shape[<span class="number">3</span>]</span><br><span class="line">    ret_inds = np.zeros([batchsize, num_rows, num_cols, num_anchors])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batchsize):</span><br><span class="line">        pred_box_i = pred_box[i]</span><br><span class="line">        gt_boxes_i = gt_boxes[i]</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(gt_boxes_i)):</span><br><span class="line">            <span class="comment"># 计算iou</span></span><br><span class="line">            gt = gt_boxes_i[k]</span><br><span class="line">            gtx_min = gt[<span class="number">0</span>] - gt[<span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line">            gty_min = gt[<span class="number">1</span>] - gt[<span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line">            gtx_max = gt[<span class="number">0</span>] + gt[<span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line">            gty_max = gt[<span class="number">1</span>] + gt[<span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line">            <span class="keyword">if</span> (gtx_max - gtx_min &lt; <span class="number">1e-3</span>) <span class="keyword">or</span> (gty_max - gty_min &lt; <span class="number">1e-3</span>):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            x1 = np.maximum(pred_box_i[:, :, :, <span class="number">0</span>], gtx_min)</span><br><span class="line">            y1 = np.maximum(pred_box_i[:, :, :, <span class="number">1</span>], gty_min)</span><br><span class="line">            x2 = np.minimum(pred_box_i[:, :, :, <span class="number">2</span>], gtx_max)</span><br><span class="line">            y2 = np.minimum(pred_box_i[:, :, :, <span class="number">3</span>], gty_max)</span><br><span class="line">            intersection = np.maximum(x2 - x1, <span class="number">0.</span>) * np.maximum(y2 - y1, <span class="number">0.</span>)</span><br><span class="line">            s1 = (gty_max - gty_min) * (gtx_max - gtx_min)</span><br><span class="line">            s2 = (pred_box_i[:, :, :, <span class="number">2</span>] - pred_box_i[:, :, :, <span class="number">0</span>]) * (pred_box_i[:, :, :, <span class="number">3</span>] - pred_box_i[:, :, :, <span class="number">1</span>])</span><br><span class="line">            union = s2 + s1 - intersection</span><br><span class="line">            iou = intersection / union</span><br><span class="line">            <span class="comment"># np.where(condition) 判断条件成立时返回索引坐标</span></span><br><span class="line">            above_inds = np.where(iou &gt; iou_threshold)</span><br><span class="line">            ret_inds[i][above_inds] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># [batchsize, num_rows, num_cols, num_anchors]--&gt;[batchsize, num_anchors, num_rows, num_cols]</span></span><br><span class="line">    ret_inds = np.transpose(ret_inds, (<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> ret_inds.astype(<span class="string">&#x27;bool&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>上面的函数可以得到哪些锚框的objectness需要被标注为-1，通过下面的程序，对label_objectness进行处理，将IoU大于阈值，但又不是正样本的锚框标注为-1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">label_objectness_ignore</span>(<span class="params">label_objectness, iou_above_thresh_indices</span>):</span><br><span class="line">    <span class="comment"># 注意：这里不能简单的使用 label_objectness[iou_above_thresh_indices] = -1，</span></span><br><span class="line">    <span class="comment">#         这样可能会造成label_objectness为1的点被设置为-1了</span></span><br><span class="line">    <span class="comment">#         只有将那些被标注为0，且与真实框IoU超过阈值的预测框才被标注为-1</span></span><br><span class="line">    negative_indices = (label_objectness &lt; <span class="number">0.5</span>)</span><br><span class="line">    ignore_indices = negative_indices * iou_above_thresh_indices</span><br><span class="line">    label_objectness[ignore_indices] = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> label_objectness</span><br></pre></td></tr></table></figure>

<p>下面通过调用这两个函数，实现如何将部分预测框的label_objectness设置为-1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">reader = paddle.io.DataLoader(train_dataset, batch_size=<span class="number">2</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line">img, gt_boxes, gt_labels, im_shape = <span class="built_in">next</span>(reader())</span><br><span class="line">img, gt_boxes, gt_labels, im_shape = img.numpy(), gt_boxes.numpy(), gt_labels.numpy(), im_shape.numpy()</span><br><span class="line"><span class="comment"># 计算出锚框对应的标签</span></span><br><span class="line">label_objectness, label_location, label_classification, scale_location = get_objectness_label(img,</span><br><span class="line">                                                                                              gt_boxes, gt_labels, </span><br><span class="line">                                                                                              iou_threshold = <span class="number">0.7</span>,</span><br><span class="line">                                                                                              anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span><br><span class="line">                                                                                              num_classes=<span class="number">7</span>, downsample=<span class="number">32</span>)</span><br><span class="line">                                               </span><br><span class="line">NUM_ANCHORS = <span class="number">3</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred = paddle.nn.Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters,  kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = paddle.to_tensor(img)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"></span><br><span class="line"><span class="comment"># anchors包含了预先设定好的锚框尺寸</span></span><br><span class="line">anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>]</span><br><span class="line"><span class="comment"># downsample是特征图P0的步幅</span></span><br><span class="line">pred_boxes = get_yolo_box_xxyy(P0.numpy(), anchors, num_classes=<span class="number">7</span>, downsample=<span class="number">32</span>)</span><br><span class="line">iou_above_thresh_indices = get_iou_above_thresh_inds(pred_boxes, gt_boxes, iou_threshold=<span class="number">0.7</span>)</span><br><span class="line">label_objectness = label_objectness_ignore(label_objectness, iou_above_thresh_indices)</span><br></pre></td></tr></table></figure>

<p>使用这种方式，就可以将那些没有被标注为正样本，但又与真实框IoU比较大的样本objectness标签设置为-1了，不计算其对任何一种损失函数的贡献。计算总的损失函数的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_loss</span>(<span class="params">output, label_objectness, label_location, label_classification, scales, num_anchors=<span class="number">3</span>, num_classes=<span class="number">7</span></span>):</span><br><span class="line">    <span class="comment"># 将output从[N, C, H, W]变形为[N, NUM_ANCHORS, NUM_CLASSES + 5, H, W]</span></span><br><span class="line">    reshaped_output = paddle.reshape(output, [-<span class="number">1</span>, num_anchors, num_classes + <span class="number">5</span>, output.shape[<span class="number">2</span>], output.shape[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从output中取出跟objectness相关的预测值</span></span><br><span class="line">    pred_objectness = reshaped_output[:, :, <span class="number">4</span>, :, :]</span><br><span class="line">    loss_objectness = F.binary_cross_entropy_with_logits(pred_objectness, label_objectness, reduction=<span class="string">&quot;none&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pos_samples 只有在正样本的地方取值为1.，其它地方取值全为0.</span></span><br><span class="line">    pos_objectness = label_objectness &gt; <span class="number">0</span> <span class="comment"># 正类样本</span></span><br><span class="line">    <span class="comment"># paddle.cast(x, dtype) 将 x 的数据类型转换为 dtype</span></span><br><span class="line">    pos_samples = paddle.cast(pos_objectness, <span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    pos_samples.stop_gradient=<span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从output中取出所有跟位置相关的预测值</span></span><br><span class="line">    tx = reshaped_output[:, :, <span class="number">0</span>, :, :]</span><br><span class="line">    ty = reshaped_output[:, :, <span class="number">1</span>, :, :]</span><br><span class="line">    tw = reshaped_output[:, :, <span class="number">2</span>, :, :]</span><br><span class="line">    th = reshaped_output[:, :, <span class="number">3</span>, :, :]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从label_location中取出各个位置坐标的标签</span></span><br><span class="line">    dx_label = label_location[:, :, <span class="number">0</span>, :, :]</span><br><span class="line">    dy_label = label_location[:, :, <span class="number">1</span>, :, :]</span><br><span class="line">    tw_label = label_location[:, :, <span class="number">2</span>, :, :]</span><br><span class="line">    th_label = label_location[:, :, <span class="number">3</span>, :, :]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建损失函数</span></span><br><span class="line">    loss_location_x = F.binary_cross_entropy_with_logits(tx, dx_label, reduction=<span class="string">&quot;none&quot;</span>)</span><br><span class="line">    loss_location_y = F.binary_cross_entropy_with_logits(ty, dy_label, reduction=<span class="string">&quot;none&quot;</span>)</span><br><span class="line">    loss_location_w = paddle.<span class="built_in">abs</span>(tw - tw_label)</span><br><span class="line">    loss_location_h = paddle.<span class="built_in">abs</span>(th - th_label)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算总的位置损失函数</span></span><br><span class="line">    loss_location = loss_location_x + loss_location_y + loss_location_h + loss_location_w</span><br><span class="line">    <span class="comment"># 乘以scales</span></span><br><span class="line">    loss_location = loss_location * scales <span class="comment"># scales--&gt;(h, w)</span></span><br><span class="line">    <span class="comment"># 只计算正样本的位置损失函数</span></span><br><span class="line">    loss_location = loss_location * pos_samples</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从output取出所有跟物体类别相关的像素点</span></span><br><span class="line">    pred_classification = reshaped_output[:, :, <span class="number">5</span>:<span class="number">5</span>+num_classes, :, :]</span><br><span class="line">    <span class="comment"># 计算分类相关的损失函数</span></span><br><span class="line">    loss_classification = F.binary_cross_entropy_with_logits(pred_classification, label_classification, reduction=<span class="string">&quot;none&quot;</span>)</span><br><span class="line">    <span class="comment"># 将损失求和</span></span><br><span class="line">    loss_classification = paddle.<span class="built_in">sum</span>(loss_classification, axis=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 只计算objectness为正的样本的分类损失函数</span></span><br><span class="line">    loss_classification = loss_classification * pos_samples</span><br><span class="line">    </span><br><span class="line">    total_loss = loss_objectness + loss_location + loss_classification</span><br><span class="line">    <span class="comment"># 对所有预测框的loss进行求和</span></span><br><span class="line">    total_loss = paddle.<span class="built_in">sum</span>(total_loss, axis=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 对所有样本求平均</span></span><br><span class="line">    total_loss = paddle.mean(total_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算出锚框对应的标签</span></span><br><span class="line">label_objectness, label_location, label_classification, scale_location = get_objectness_label(img,</span><br><span class="line">                                                                                              gt_boxes, gt_labels, </span><br><span class="line">                                                                                              iou_threshold = <span class="number">0.7</span>,</span><br><span class="line">                                                                                              anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span><br><span class="line">                                                                                              num_classes=<span class="number">7</span>, downsample=<span class="number">32</span>)                                                           </span><br><span class="line"></span><br><span class="line">NUM_ANCHORS = <span class="number">3</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line">num_filters=NUM_ANCHORS * (NUM_CLASSES + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">backbone = DarkNet53_conv_body()</span><br><span class="line">detection = YoloDetectionBlock(ch_in=<span class="number">1024</span>, ch_out=<span class="number">512</span>)</span><br><span class="line">conv2d_pred = Conv2D(in_channels=<span class="number">1024</span>, out_channels=num_filters,  kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = paddle.to_tensor(img)</span><br><span class="line">C0, C1, C2 = backbone(x)</span><br><span class="line">route, tip = detection(C0)</span><br><span class="line">P0 = conv2d_pred(tip)</span><br><span class="line"><span class="comment"># anchors包含了预先设定好的锚框尺寸</span></span><br><span class="line">anchors = [<span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>]</span><br><span class="line"><span class="comment"># downsample是特征图P0的步幅</span></span><br><span class="line">pred_boxes = get_yolo_box_xxyy(P0.numpy(), anchors, num_classes=<span class="number">7</span>, downsample=<span class="number">32</span>)</span><br><span class="line">iou_above_thresh_indices = get_iou_above_thresh_inds(pred_boxes, gt_boxes, iou_threshold=<span class="number">0.7</span>)</span><br><span class="line">label_objectness = label_objectness_ignore(label_objectness, iou_above_thresh_indices)</span><br><span class="line"></span><br><span class="line">label_objectness = paddle.to_tensor(label_objectness)</span><br><span class="line">label_location = paddle.to_tensor(label_location)</span><br><span class="line">label_classification = paddle.to_tensor(label_classification)</span><br><span class="line">scales = paddle.to_tensor(scale_location)</span><br><span class="line">label_objectness.stop_gradient=<span class="literal">True</span></span><br><span class="line">label_location.stop_gradient=<span class="literal">True</span></span><br><span class="line">label_classification.stop_gradient=<span class="literal">True</span></span><br><span class="line">scales.stop_gradient=<span class="literal">True</span></span><br><span class="line"></span><br><span class="line">total_loss = get_loss(P0, label_objectness, label_location, label_classification, scales,</span><br><span class="line">                          num_anchors=NUM_ANCHORS, num_classes=NUM_CLASSES)</span><br><span class="line">total_loss_data = total_loss.numpy()</span><br><span class="line"><span class="built_in">print</span>(total_loss_data)</span><br></pre></td></tr></table></figure>

<pre><code>[896.6715]
</code></pre>
<p>上面的程序计算出了总的损失函数，看到这里，读者已经了解到了YOLOv3算法的大部分内容，包括如何生成锚框、给锚框打上标签、通过卷积神经网络提取特征、将输出特征图跟预测框相关联、建立起损失函数。</p>
<h2 id="6-多尺度检测"><a href="#6-多尺度检测" class="headerlink" title="6.多尺度检测"></a><strong>6.多尺度检测</strong></h2><p>目前我们计算损失函数是在特征图P0的基础上进行的，它的步幅stride&#x3D;32。特征图的尺寸比较小，像素点数目比较少，每个像素点的感受野很大，具有非常丰富的高层级语义信息，可能比较容易检测到较大的目标。为了能够检测到尺寸较小的那些目标，需要在尺寸较大的特征图上面建立预测输出。</p>
<p>如果我们在C2或者C1这种层级的特征图上直接产生预测输出，可能面临新的问题，它们没有经过充分的特征提取，像素点包含的语义信息不够丰富，有可能难以提取到有效的特征模式。在目标检测中，解决这一问题的方式是，<strong>将高层级的特征图尺寸放大之后跟低层级的特征图进行融合</strong>，得到的新特征图既能包含丰富的语义信息，又具有较多的像素点，能够描述更加精细的结构。</p>
<p>具体的网络实现方式如 <strong>图16</strong> 所示：</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/b6d3b425644342e48bd0a50ebde90d882fd10717e0e44a53a44e98225bbb6df8" width = "800"></center>
<center><br>图16：生成多层级的输出特征图P0、P1、P2 </br></center>

<p><br></br></p>
<p>YOLOv3在每个区域的中心位置产生3个锚框，在3个层级的特征图上产生锚框的大小分别为P2 [(10×13),(16×30),(33×23)]，P1 [(30×61),(62×45),(59× 119)]，P0[(116 × 90), (156 × 198), (373 × 326]。越往后的特征图上用到的锚框尺寸也越大，能捕捉到大尺寸目标的信息；越往前的特征图上锚框尺寸越小，能捕捉到小尺寸目标的信息。</p>
<p>在完整网络定义时，我们需要使用 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/ops/yolo_loss_cn.html#yolo-loss">paddle.vision.ops.yolo_loss</a> API来计算损失函数，该API 将上述候选区域的标注以及多尺度的损失函数计算统一地进行了封装。</p>
<blockquote>
<p>paddle.vision.ops.yolo_loss(x, gt_box, gt_label, anchors, anchor_mask, class_num, ignore_thresh, downsample_ratio, gt_score&#x3D;None, use_label_smooth&#x3D;True, name&#x3D;None, scale_x_y&#x3D;1.0)</p>
</blockquote>
<p>关键参数说明如下：</p>
<ul>
<li>x: 输出特征图。</li>
<li>gt_box: 真实框。</li>
<li>gt_label: 真实框标签。</li>
<li>ignore_thresh，预测框与真实框IoU阈值超过ignore_thresh时，不作为负样本，YOLOv3模型里设置为0.7。</li>
<li>downsample_ratio，特征图P0的下采样比例，使用Darknet53骨干网络时为32。</li>
<li>gt_score，真实框的置信度，在使用了mixup（混类增强）技巧时用到。</li>
<li>use_label_smooth，一种训练技巧，如不使用，设置为False。</li>
<li>name，该层的名字，比如’yolov3_loss’，默认值为None，一般无需设置。</li>
</ul>
<p>对于使用了多层级特征图产生预测框的方法，其具体实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义上采样模块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Upsample</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, scale=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Upsample,self).__init__()</span><br><span class="line">        self.scale = scale</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="comment"># 获取上采样过程中的动态尺寸</span></span><br><span class="line">        shape_nchw = paddle.shape(inputs)</span><br><span class="line">        <span class="comment"># paddle.slice(input, axes, starts, ends)：沿多个轴生成 input 的切片</span></span><br><span class="line">        shape_hw = paddle.<span class="built_in">slice</span>(shape_nchw, axes=[<span class="number">0</span>], starts=[<span class="number">2</span>], ends=[<span class="number">4</span>])</span><br><span class="line">        shape_hw.stop_gradient = <span class="literal">True</span></span><br><span class="line">        in_shape = paddle.cast(shape_hw, dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">        out_shape = in_shape * self.scale</span><br><span class="line">        out_shape.stop_gradient = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 调整一个 batch 中图片的大小：NEAREST 最近邻插值</span></span><br><span class="line">        out = paddle.nn.functional.interpolate(x=inputs, scale_factor=self.scale, mode=<span class="string">&quot;NEAREST&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOv3</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(YOLOv3,self).__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        <span class="comment"># 提取图像特征的骨干代码</span></span><br><span class="line">        self.block = DarkNet53_conv_body()</span><br><span class="line">        self.block_outputs = []</span><br><span class="line">        self.yolo_blocks = []</span><br><span class="line">        self.route_blocks_2 = []</span><br><span class="line">        <span class="comment"># 生成3个层级的特征图P0, P1, P2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            <span class="comment"># 添加从ci生成ri和ti的模块</span></span><br><span class="line">            yolo_block = self.add_sublayer(</span><br><span class="line">                <span class="string">&quot;yolo_detecton_block_%d&quot;</span> % (i),</span><br><span class="line">                YoloDetectionBlock(</span><br><span class="line">                                   ch_in=<span class="number">512</span>//(<span class="number">2</span>**i)*<span class="number">2</span> <span class="keyword">if</span> i==<span class="number">0</span> <span class="keyword">else</span> <span class="number">512</span>//(<span class="number">2</span>**i)*<span class="number">2</span> + <span class="number">512</span>//(<span class="number">2</span>**i),</span><br><span class="line">                                   ch_out = <span class="number">512</span>//(<span class="number">2</span>**i)))</span><br><span class="line">            self.yolo_blocks.append(yolo_block)</span><br><span class="line"></span><br><span class="line">            num_filters = <span class="number">3</span> * (self.num_classes + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 添加从ti生成pi的模块，这是一个Conv2D操作，输出通道数为3 * (num_classes + 5)</span></span><br><span class="line">            block_out = self.add_sublayer(</span><br><span class="line">                <span class="string">&quot;block_out_%d&quot;</span> % (i),</span><br><span class="line">                paddle.nn.Conv2D(in_channels=<span class="number">512</span>//(<span class="number">2</span>**i)*<span class="number">2</span>,</span><br><span class="line">                       out_channels=num_filters,</span><br><span class="line">                       kernel_size=<span class="number">1</span>,</span><br><span class="line">                       stride=<span class="number">1</span>,</span><br><span class="line">                       padding=<span class="number">0</span>,</span><br><span class="line">                       weight_attr=paddle.ParamAttr(</span><br><span class="line">                           initializer=paddle.nn.initializer.Normal(<span class="number">0.</span>, <span class="number">0.02</span>)),</span><br><span class="line">                       bias_attr=paddle.ParamAttr(</span><br><span class="line">                           initializer=paddle.nn.initializer.Constant(<span class="number">0.0</span>),</span><br><span class="line">                           regularizer=paddle.regularizer.L2Decay(<span class="number">0.</span>))))</span><br><span class="line">            self.block_outputs.append(block_out)</span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># 对ri进行卷积</span></span><br><span class="line">                route = self.add_sublayer(<span class="string">&quot;route2_%d&quot;</span>%i,</span><br><span class="line">                                          ConvBNLayer(ch_in=<span class="number">512</span>//(<span class="number">2</span>**i),</span><br><span class="line">                                                      ch_out=<span class="number">256</span>//(<span class="number">2</span>**i),</span><br><span class="line">                                                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                                                      stride=<span class="number">1</span>,</span><br><span class="line">                                                      padding=<span class="number">0</span>))</span><br><span class="line">                self.route_blocks_2.append(route)</span><br><span class="line">            <span class="comment"># 将ri放大以便跟c_&#123;i+1&#125;保持同样的尺寸</span></span><br><span class="line">            self.upsample = Upsample()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = []</span><br><span class="line">        blocks = self.block(inputs)</span><br><span class="line">        <span class="keyword">for</span> i, block <span class="keyword">in</span> <span class="built_in">enumerate</span>(blocks):</span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 将r_&#123;i-1&#125;经过卷积和上采样之后得到特征图，与这一级的ci进行拼接</span></span><br><span class="line">                block = paddle.concat([route, block], axis=<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 从ci生成ti和ri</span></span><br><span class="line">            route, tip = self.yolo_blocks[i](block)</span><br><span class="line">            <span class="comment"># 从ti生成pi</span></span><br><span class="line">            block_out = self.block_outputs[i](tip)</span><br><span class="line">            <span class="comment"># 将pi放入列表</span></span><br><span class="line">            outputs.append(block_out)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># 对ri进行卷积调整通道数</span></span><br><span class="line">                route = self.route_blocks_2[i](route)</span><br><span class="line">                <span class="comment"># 对ri进行放大，使其尺寸和c_&#123;i+1&#125;保持一致</span></span><br><span class="line">                route = self.upsample(route)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_loss</span>(<span class="params">self, outputs, gtbox, gtlabel, gtscore=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 anchors = [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>, <span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>, <span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span></span><br><span class="line"><span class="params">                 anchor_masks = [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]],</span></span><br><span class="line"><span class="params">                 ignore_thresh=<span class="number">0.7</span>,</span></span><br><span class="line"><span class="params">                 use_label_smooth=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        使用 paddle.vision.ops.yolo_loss，直接计算损失函数，过程更简洁，速度也更快</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.losses = []</span><br><span class="line">        downsample = <span class="number">32</span></span><br><span class="line">        <span class="keyword">for</span> i, out <span class="keyword">in</span> <span class="built_in">enumerate</span>(outputs): <span class="comment"># 对三个层级分别求损失函数</span></span><br><span class="line">            anchor_mask_i = anchor_masks[i]</span><br><span class="line">            loss = paddle.vision.ops.yolo_loss(</span><br><span class="line">                    x=out,  <span class="comment"># out是P0, P1, P2中的一个</span></span><br><span class="line">                    gt_box=gtbox,  <span class="comment"># 真实框坐标</span></span><br><span class="line">                    gt_label=gtlabel,  <span class="comment"># 真实框类别</span></span><br><span class="line">                    gt_score=gtscore,  <span class="comment"># 真实框得分，使用mixup训练技巧时需要，不使用该技巧时直接设置为1，形状与gtlabel相同</span></span><br><span class="line">                    anchors=anchors,   <span class="comment"># 锚框尺寸，包含[w0, h0, w1, h1, ..., w8, h8]共9个锚框的尺寸</span></span><br><span class="line">                    anchor_mask=anchor_mask_i, <span class="comment"># 筛选锚框的mask，例如anchor_mask_i=[3, 4, 5]，将anchors中第3、4、5个锚框挑选出来给该层级使用</span></span><br><span class="line">                    class_num=self.num_classes, <span class="comment"># 分类类别数</span></span><br><span class="line">                    ignore_thresh=ignore_thresh, <span class="comment"># 当预测框与真实框IoU &gt; ignore_thresh，标注objectness = -1</span></span><br><span class="line">                    downsample_ratio=downsample, <span class="comment"># 特征图相对于原图缩小的倍数，例如P0是32， P1是16，P2是8</span></span><br><span class="line">                    use_label_smooth=<span class="literal">False</span>)      <span class="comment"># 使用label_smooth训练技巧时会用到，这里没用此技巧，直接设置为False</span></span><br><span class="line">            self.losses.append(paddle.mean(loss))  <span class="comment">#mean对每张图片求和</span></span><br><span class="line">            downsample = downsample // <span class="number">2</span> <span class="comment"># 下一级特征图的缩放倍数会减半</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.losses) <span class="comment"># 对每个层级求和</span></span><br></pre></td></tr></table></figure>

<h2 id="7-开启端到端训练"><a href="#7-开启端到端训练" class="headerlink" title="7.开启端到端训练"></a><strong>7.开启端到端训练</strong></h2><p>训练过程如 <strong>图17</strong> 所示，输入图片经过特征提取得到三个层级的输出特征图P0(stride&#x3D;32)、P1(stride&#x3D;16)和P2(stride&#x3D;8)，相应的分别使用不同大小的小方块区域去生成对应的锚框和预测框，并对这些锚框进行标注。</p>
<ul>
<li><p>P0层级特征图，对应着使用$32\times32$大小的小方块，在每个区域中心生成大小分别为$[116, 90]$, $[156, 198]$, $[373, 326]$的三种锚框。</p>
</li>
<li><p>P1层级特征图，对应着使用$16\times16$大小的小方块，在每个区域中心生成大小分别为$[30, 61]$, $[62, 45]$, $[59, 119]$的三种锚框。</p>
</li>
<li><p>P2层级特征图，对应着使用$8\times8$大小的小方块，在每个区域中心生成大小分别为$[10, 13]$, $[16, 30]$, $[33, 23]$的三种锚框。</p>
</li>
</ul>
<p>将三个层级的特征图与对应锚框之间的标签关联起来，并建立损失函数，总的损失函数等于三个层级的损失函数相加。通过极小化损失函数，可以开启端到端的训练过程。</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/736da9cd3a4f4a1c98187a6cdf1a0334af73470b6d7c4b2fbaa9660d4bd20621" width = "600"></center>
<center><br>图17：端到端训练流程 </br></center>

<p><br></br></p>
<p>训练过程的具体实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############# 这段代码运行前：请重启项目环境（GPU）#######################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">ANCHORS = [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>, <span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>, <span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>]</span><br><span class="line">ANCHOR_MASKS = [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">IGNORE_THRESH = <span class="number">.7</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_lr</span>(<span class="params">base_lr = <span class="number">0.0001</span>, lr_decay = <span class="number">0.1</span></span>):</span><br><span class="line">    bd = [<span class="number">10000</span>, <span class="number">20000</span>]</span><br><span class="line">    lr = [base_lr, base_lr * lr_decay, base_lr * lr_decay * lr_decay]</span><br><span class="line">    learning_rate = paddle.optimizer.lr.PiecewiseDecay(boundaries=bd, values=lr)</span><br><span class="line">    <span class="keyword">return</span> learning_rate</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    TRAINDIR = <span class="string">&#x27;/home/aistudio/work/insects/train&#x27;</span></span><br><span class="line">    TESTDIR = <span class="string">&#x27;/home/aistudio/work/insects/test&#x27;</span></span><br><span class="line">    VALIDDIR = <span class="string">&#x27;/home/aistudio/work/insects/val&#x27;</span></span><br><span class="line">    paddle.set_device(<span class="string">&quot;gpu:0&quot;</span>)</span><br><span class="line">    <span class="comment"># 创建数据读取类</span></span><br><span class="line">    train_dataset = TrainDataset(TRAINDIR, mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    valid_dataset = TrainDataset(VALIDDIR, mode=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">    test_dataset = TrainDataset(VALIDDIR, mode=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">    <span class="comment"># 使用paddle.io.DataLoader创建数据读取器，并设置batchsize，进程数量num_workers等参数</span></span><br><span class="line">    train_loader = paddle.io.DataLoader(train_dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, drop_last=<span class="literal">True</span>, use_shared_memory=<span class="literal">False</span>)</span><br><span class="line">    valid_loader = paddle.io.DataLoader(valid_dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>, drop_last=<span class="literal">False</span>, use_shared_memory=<span class="literal">False</span>)</span><br><span class="line">    model = YOLOv3(num_classes = NUM_CLASSES)    <span class="comment"># 创建模型</span></span><br><span class="line">    learning_rate = get_lr()</span><br><span class="line">    opt = paddle.optimizer.Momentum(</span><br><span class="line">                 learning_rate=learning_rate,</span><br><span class="line">                 momentum=<span class="number">0.9</span>,</span><br><span class="line">                 weight_decay=paddle.regularizer.L2Decay(<span class="number">0.0005</span>),</span><br><span class="line">                 parameters=model.parameters())  <span class="comment"># 创建优化器</span></span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.Adam(learning_rate=learning_rate, weight_decay=paddle.regularizer.L2Decay(0.0005), parameters=model.parameters())</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">####迭代周期数自行调整######</span></span><br><span class="line"></span><br><span class="line">    MAX_EPOCH = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH):</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">            img, gt_boxes, gt_labels, img_scale = data</span><br><span class="line">            gt_scores = np.ones(gt_labels.shape).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            gt_scores = paddle.to_tensor(gt_scores)</span><br><span class="line">            img = paddle.to_tensor(img)</span><br><span class="line">            gt_boxes = paddle.to_tensor(gt_boxes)</span><br><span class="line">            gt_labels = paddle.to_tensor(gt_labels)</span><br><span class="line">            outputs = model(img)  <span class="comment"># 前向传播，输出[P0, P1, P2]</span></span><br><span class="line">            loss = model.get_loss(outputs, gt_boxes, gt_labels, gtscore=gt_scores,</span><br><span class="line">                                  anchors = ANCHORS,</span><br><span class="line">                                  anchor_masks = ANCHOR_MASKS,</span><br><span class="line">                                  ignore_thresh=IGNORE_THRESH,</span><br><span class="line">                                  use_label_smooth=<span class="literal">False</span>)        <span class="comment"># 计算损失函数</span></span><br><span class="line"></span><br><span class="line">            loss.backward()    <span class="comment"># 反向传播计算梯度</span></span><br><span class="line">            opt.step()         <span class="comment"># 更新参数</span></span><br><span class="line">            opt.clear_grad()</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                timestring = time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>,time.localtime(time.time()))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;[TRAIN]epoch &#123;&#125;, iter &#123;&#125;, output loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(timestring, epoch, i, loss.numpy()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># save params of model</span></span><br><span class="line">        <span class="keyword">if</span> (epoch % <span class="number">5</span> == <span class="number">0</span>) <span class="keyword">or</span> (epoch == MAX_EPOCH -<span class="number">1</span>):</span><br><span class="line">            paddle.save(model.state_dict(), <span class="string">&#x27;yolo_epoch&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每个epoch结束之后在验证集上进行测试</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(valid_loader()):</span><br><span class="line">            img, gt_boxes, gt_labels, img_scale = data</span><br><span class="line">            gt_scores = np.ones(gt_labels.shape).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            gt_scores = paddle.to_tensor(gt_scores)</span><br><span class="line">            img = paddle.to_tensor(img)</span><br><span class="line">            gt_boxes = paddle.to_tensor(gt_boxes)</span><br><span class="line">            gt_labels = paddle.to_tensor(gt_labels)</span><br><span class="line">            outputs = model(img)</span><br><span class="line">            loss = model.get_loss(outputs, gt_boxes, gt_labels, gtscore=gt_scores,</span><br><span class="line">                                  anchors = ANCHORS,</span><br><span class="line">                                  anchor_masks = ANCHOR_MASKS,</span><br><span class="line">                                  ignore_thresh=IGNORE_THRESH,</span><br><span class="line">                                  use_label_smooth=<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                timestring = time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>,time.localtime(time.time()))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;[VALID]epoch &#123;&#125;, iter &#123;&#125;, output loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(timestring, epoch, i, loss.numpy()))</span><br><span class="line">        model.train()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">paddle.save(model.state_dict(), <span class="string">&quot;linear_net.pdparams&quot;</span>)</span><br><span class="line">paddle.save(opt.state_dict(), <span class="string">&quot;opt.pdopt&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load</span></span><br><span class="line"><span class="comment"># layer_state_dict = paddle.load(&quot;linear_net.pdparams&quot;)</span></span><br><span class="line"><span class="comment"># opt_state_dict = paddle.load(&quot;opt.pdopt&quot;)</span></span><br><span class="line"><span class="comment"># layer.set_state_dict(layer_state_dict)</span></span><br><span class="line"><span class="comment"># opt.set_state_dict(opt_state_dict)</span></span><br></pre></td></tr></table></figure>

<h2 id="8-预测"><a href="#8-预测" class="headerlink" title="8.预测"></a><strong>8.预测</strong></h2><p>预测过程流程 <strong>图18</strong> 如下所示：</p>
<p><br></br></p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/15c140b1844d419cbe237b1a70f4099266aa168c05dc413f8e232f688050fa75" width = "400"></center>
<center><br>图18：预测流程 </br></center>

<p><br></br></p>
<p><strong>预测过程可以分为两步</strong>：</p>
<ol>
<li>通过网络输出计算出预测框位置和所属类别的得分。 </li>
<li>使用非极大值抑制来消除重叠较大的预测框。</li>
</ol>
<p>对于第1步，前面我们已经讲过如何通过网络输出值计算pred_objectness_probability, pred_boxes以及pred_classification_probability，这里推荐大家直接使用<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/ops/yolo_box_cn.html#yolo-box">paddle.vision.ops.yolo_box</a>，关键参数含义如下：</p>
<p><code>paddle.vision.ops.yolo_box(x, img_size, anchors, class_num, conf_thresh, downsample_ratio, clip_bbox=True, name=None, scale_x_y=1.0)</code></p>
<ul>
<li>x，网络输出特征图，例如上面提到的P0或者P1、P2。</li>
<li>img_size，输入图片尺寸。</li>
<li>anchors，使用到的anchor的尺寸，如[10, 13, 16, 30, 33, 23, 30, 61, 62, 45, 59, 119, 116, 90, 156, 198, 373, 326]</li>
<li>class_num，物体类别数。</li>
<li>conf_thresh, 置信度阈值，得分低于该阈值的预测框位置数值不用计算直接设置为0.0。</li>
<li>downsample_ratio, 特征图的下采样比例，例如P0是32，P1是16，P2是8。</li>
<li>name&#x3D;None，名字，例如’yolo_box’，一般无需设置，默认值为None。</li>
</ul>
<p>返回值包括两项，<code>boxes</code>和<code>scores</code>，其中<code>boxes</code>是所有预测框的坐标值，<code>scores</code>是所有预测框的得分。</p>
<p>预测框得分的定义是所属类别的概率乘以其预测框是否包含目标物体的objectness概率，即</p>
<p>$$score &#x3D; P_{obj} \cdot P_{classification}$$</p>
<p>在上面定义的类YOLOv3下面添加函数<code>get_pred</code>，通过调用<code>paddle.vision.ops.yolo_box</code>获得P0、P1、P2三个层级的特征图对应的预测框和得分，并将他们拼接在一块，即可得到所有的预测框及其属于各个类别的得分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义YOLOv3模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOv3</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(YOLOv3,self).__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        <span class="comment"># 提取图像特征的骨干代码</span></span><br><span class="line">        self.block = DarkNet53_conv_body()</span><br><span class="line">        self.block_outputs = []</span><br><span class="line">        self.yolo_blocks = []</span><br><span class="line">        self.route_blocks_2 = []</span><br><span class="line">        <span class="comment"># 生成3个层级的特征图P0, P1, P2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            <span class="comment"># 添加从ci生成ri和ti的模块</span></span><br><span class="line">            yolo_block = self.add_sublayer(</span><br><span class="line">                <span class="string">&quot;yolo_detecton_block_%d&quot;</span> % (i),</span><br><span class="line">                YoloDetectionBlock(</span><br><span class="line">                                   ch_in=<span class="number">512</span>//(<span class="number">2</span>**i)*<span class="number">2</span> <span class="keyword">if</span> i==<span class="number">0</span> <span class="keyword">else</span> <span class="number">512</span>//(<span class="number">2</span>**i)*<span class="number">2</span> + <span class="number">512</span>//(<span class="number">2</span>**i),</span><br><span class="line">                                   ch_out = <span class="number">512</span>//(<span class="number">2</span>**i)))</span><br><span class="line">            self.yolo_blocks.append(yolo_block)</span><br><span class="line"></span><br><span class="line">            num_filters = <span class="number">3</span> * (self.num_classes + <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 添加从ti生成pi的模块，这是一个Conv2D操作，输出通道数为3 * (num_classes + 5)</span></span><br><span class="line">            block_out = self.add_sublayer(</span><br><span class="line">                <span class="string">&quot;block_out_%d&quot;</span> % (i),</span><br><span class="line">                paddle.nn.Conv2D(in_channels=<span class="number">512</span>//(<span class="number">2</span>**i)*<span class="number">2</span>,</span><br><span class="line">                       out_channels=num_filters,</span><br><span class="line">                       kernel_size=<span class="number">1</span>,</span><br><span class="line">                       stride=<span class="number">1</span>,</span><br><span class="line">                       padding=<span class="number">0</span>,</span><br><span class="line">                       weight_attr=paddle.ParamAttr(</span><br><span class="line">                           initializer=paddle.nn.initializer.Normal(<span class="number">0.</span>, <span class="number">0.02</span>)),</span><br><span class="line">                       bias_attr=paddle.ParamAttr(</span><br><span class="line">                           initializer=paddle.nn.initializer.Constant(<span class="number">0.0</span>),</span><br><span class="line">                           regularizer=paddle.regularizer.L2Decay(<span class="number">0.</span>))))</span><br><span class="line">            self.block_outputs.append(block_out)</span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># 对ri进行卷积</span></span><br><span class="line">                route = self.add_sublayer(<span class="string">&quot;route2_%d&quot;</span>%i,</span><br><span class="line">                                          ConvBNLayer(ch_in=<span class="number">512</span>//(<span class="number">2</span>**i),</span><br><span class="line">                                                      ch_out=<span class="number">256</span>//(<span class="number">2</span>**i),</span><br><span class="line">                                                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                                                      stride=<span class="number">1</span>,</span><br><span class="line">                                                      padding=<span class="number">0</span>))</span><br><span class="line">                self.route_blocks_2.append(route)</span><br><span class="line">            <span class="comment"># 将ri放大以便跟c_&#123;i+1&#125;保持同样的尺寸</span></span><br><span class="line">            self.upsample = Upsample()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = []</span><br><span class="line">        blocks = self.block(inputs)</span><br><span class="line">        <span class="keyword">for</span> i, block <span class="keyword">in</span> <span class="built_in">enumerate</span>(blocks):</span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 将r_&#123;i-1&#125;经过卷积和上采样之后得到特征图，与这一级的ci进行拼接</span></span><br><span class="line">                block = paddle.concat([route, block], axis=<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 从ci生成ti和ri</span></span><br><span class="line">            route, tip = self.yolo_blocks[i](block)</span><br><span class="line">            <span class="comment"># 从ti生成pi</span></span><br><span class="line">            block_out = self.block_outputs[i](tip)</span><br><span class="line">            <span class="comment"># 将pi放入列表</span></span><br><span class="line">            outputs.append(block_out)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># 对ri进行卷积调整通道数</span></span><br><span class="line">                route = self.route_blocks_2[i](route)</span><br><span class="line">                <span class="comment"># 对ri进行放大，使其尺寸和c_&#123;i+1&#125;保持一致</span></span><br><span class="line">                route = self.upsample(route)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_loss</span>(<span class="params">self, outputs, gtbox, gtlabel, gtscore=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 anchors = [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>, <span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>, <span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span></span><br><span class="line"><span class="params">                 anchor_masks = [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]],</span></span><br><span class="line"><span class="params">                 ignore_thresh=<span class="number">0.7</span>,</span></span><br><span class="line"><span class="params">                 use_label_smooth=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        使用paddle.vision.ops.yolo_loss，直接计算损失函数，过程更简洁，速度也更快</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.losses = []</span><br><span class="line">        downsample = <span class="number">32</span></span><br><span class="line">        <span class="keyword">for</span> i, out <span class="keyword">in</span> <span class="built_in">enumerate</span>(outputs): <span class="comment"># 对三个层级分别求损失函数</span></span><br><span class="line">            anchor_mask_i = anchor_masks[i]</span><br><span class="line">            loss = paddle.vision.ops.yolo_loss(</span><br><span class="line">                    x=out,  <span class="comment"># out是P0, P1, P2中的一个</span></span><br><span class="line">                    gt_box=gtbox,  <span class="comment"># 真实框坐标</span></span><br><span class="line">                    gt_label=gtlabel,  <span class="comment"># 真实框类别</span></span><br><span class="line">                    gt_score=gtscore,  <span class="comment"># 真实框得分，使用mixup训练技巧时需要，不使用该技巧时直接设置为1，形状与gtlabel相同</span></span><br><span class="line">                    anchors=anchors,   <span class="comment"># 锚框尺寸，包含[w0, h0, w1, h1, ..., w8, h8]共9个锚框的尺寸</span></span><br><span class="line">                    anchor_mask=anchor_mask_i, <span class="comment"># 筛选锚框的mask，例如anchor_mask_i=[3, 4, 5]，将anchors中第3、4、5个锚框挑选出来给该层级使用</span></span><br><span class="line">                    class_num=self.num_classes, <span class="comment"># 分类类别数</span></span><br><span class="line">                    ignore_thresh=ignore_thresh, <span class="comment"># 当预测框与真实框IoU &gt; ignore_thresh，标注objectness = -1</span></span><br><span class="line">                    downsample_ratio=downsample, <span class="comment"># 特征图相对于原图缩小的倍数，例如P0是32， P1是16，P2是8</span></span><br><span class="line">                    use_label_smooth=<span class="literal">False</span>)      <span class="comment"># 使用label_smooth训练技巧时会用到，这里没用此技巧，直接设置为False</span></span><br><span class="line">            self.losses.append(paddle.mean(loss))  <span class="comment">#mean对每张图片求和</span></span><br><span class="line">            downsample = downsample // <span class="number">2</span> <span class="comment"># 下一级特征图的缩放倍数会减半</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.losses) <span class="comment"># 对每个层级求和</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_pred</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 outputs,</span></span><br><span class="line"><span class="params">                 im_shape=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 anchors = [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>, <span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>, <span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>],</span></span><br><span class="line"><span class="params">                 anchor_masks = [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]],</span></span><br><span class="line"><span class="params">                 valid_thresh = <span class="number">0.01</span></span>):</span><br><span class="line">        downsample = <span class="number">32</span></span><br><span class="line">        total_boxes = []</span><br><span class="line">        total_scores = []</span><br><span class="line">        <span class="keyword">for</span> i, out <span class="keyword">in</span> <span class="built_in">enumerate</span>(outputs):</span><br><span class="line">            anchor_mask = anchor_masks[i]</span><br><span class="line">            anchors_this_level = []</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> anchor_mask:</span><br><span class="line">                anchors_this_level.append(anchors[<span class="number">2</span> * m])</span><br><span class="line">                anchors_this_level.append(anchors[<span class="number">2</span> * m + <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            boxes, scores = paddle.vision.ops.yolo_box(</span><br><span class="line">                   x=out,</span><br><span class="line">                   img_size=im_shape,</span><br><span class="line">                   anchors=anchors_this_level,</span><br><span class="line">                   class_num=self.num_classes,</span><br><span class="line">                   conf_thresh=valid_thresh,</span><br><span class="line">                   downsample_ratio=downsample,</span><br><span class="line">                   name=<span class="string">&quot;yolo_box&quot;</span> + <span class="built_in">str</span>(i))</span><br><span class="line">            total_boxes.append(boxes)</span><br><span class="line">            total_scores.append(</span><br><span class="line">                        paddle.transpose(</span><br><span class="line">                        scores, perm=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]))</span><br><span class="line">            downsample = downsample // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        yolo_boxes = paddle.concat(total_boxes, axis=<span class="number">1</span>)</span><br><span class="line">        yolo_scores = paddle.concat(total_scores, axis=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> yolo_boxes, yolo_scores</span><br></pre></td></tr></table></figure>

<p>第1步的计算结果会在每个小方块区域上生成多个预测框，而这些预测框中很多都有较大的重合度，因此需要消除重叠较大的冗余检测框。</p>
<p>下面示例代码中的预测框是使用模型对图片预测之后输出的，这里一共选出了11个预测框，在图上画出预测框如下所示。在每个人像周围，都出现了多个预测框，需要消除冗余的预测框以得到最终的预测结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 画图展示目标物体边界框</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"><span class="keyword">from</span> matplotlib.image <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义画矩形框的程序    </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_rectangle</span>(<span class="params">currentAxis, bbox, edgecolor = <span class="string">&#x27;k&#x27;</span>, facecolor = <span class="string">&#x27;y&#x27;</span>, fill=<span class="literal">False</span>, linestyle=<span class="string">&#x27;-&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># currentAxis，坐标轴，通过plt.gca()获取</span></span><br><span class="line">    <span class="comment"># bbox，边界框，包含四个数值的list， [x1, y1, x2, y2]</span></span><br><span class="line">    <span class="comment"># edgecolor，边框线条颜色</span></span><br><span class="line">    <span class="comment"># facecolor，填充颜色</span></span><br><span class="line">    <span class="comment"># fill, 是否填充</span></span><br><span class="line">    <span class="comment"># linestype，边框线型</span></span><br><span class="line">    <span class="comment"># patches.Rectangle需要传入左上角坐标、矩形区域的宽度、高度等参数</span></span><br><span class="line">    rect=patches.Rectangle((bbox[<span class="number">0</span>], bbox[<span class="number">1</span>]), bbox[<span class="number">2</span>]-bbox[<span class="number">0</span>]+<span class="number">1</span>, bbox[<span class="number">3</span>]-bbox[<span class="number">1</span>]+<span class="number">1</span>, linewidth=<span class="number">1</span>,</span><br><span class="line">                           edgecolor=edgecolor,facecolor=facecolor,fill=fill, linestyle=linestyle)</span><br><span class="line">    currentAxis.add_patch(rect)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;/home/aistudio/000000086956.jpg&#x27;</span></span><br><span class="line">im = imread(filename)</span><br><span class="line">plt.imshow(im)</span><br><span class="line"></span><br><span class="line">currentAxis=plt.gca()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测框位置</span></span><br><span class="line">boxes = np.array([[<span class="number">4.21716537e+01</span>, <span class="number">1.28230896e+02</span>, <span class="number">2.26547668e+02</span>, <span class="number">6.00434631e+02</span>],</span><br><span class="line">       [<span class="number">3.18562988e+02</span>, <span class="number">1.23168472e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.05688416e+02</span>],</span><br><span class="line">       [<span class="number">2.62704697e+01</span>, <span class="number">1.39430557e+02</span>, <span class="number">2.20587097e+02</span>, <span class="number">6.38959656e+02</span>],</span><br><span class="line">       [<span class="number">4.24965363e+01</span>, <span class="number">1.42706665e+02</span>, <span class="number">2.25955185e+02</span>, <span class="number">6.35671204e+02</span>],</span><br><span class="line">       [<span class="number">2.37462646e+02</span>, <span class="number">1.35731537e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.31451294e+02</span>],</span><br><span class="line">       [<span class="number">3.19390472e+02</span>, <span class="number">1.29295090e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.33003845e+02</span>],</span><br><span class="line">       [<span class="number">3.28933838e+02</span>, <span class="number">1.22736115e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.39000000e+02</span>],</span><br><span class="line">       [<span class="number">4.44292603e+01</span>, <span class="number">1.70438187e+02</span>, <span class="number">2.26841858e+02</span>, <span class="number">6.39000000e+02</span>],</span><br><span class="line">       [<span class="number">2.17988785e+02</span>, <span class="number">3.02472412e+02</span>, <span class="number">4.06062927e+02</span>, <span class="number">6.29106628e+02</span>],</span><br><span class="line">       [<span class="number">2.00241089e+02</span>, <span class="number">3.23755096e+02</span>, <span class="number">3.96929321e+02</span>, <span class="number">6.36386108e+02</span>],</span><br><span class="line">       [<span class="number">2.14310303e+02</span>, <span class="number">3.23443665e+02</span>, <span class="number">4.06732849e+02</span>, <span class="number">6.35775269e+02</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测框得分</span></span><br><span class="line">scores = np.array([<span class="number">0.5247661</span> , <span class="number">0.51759845</span>, <span class="number">0.86075854</span>, <span class="number">0.9910175</span> , <span class="number">0.39170712</span>,</span><br><span class="line">       <span class="number">0.9297706</span> , <span class="number">0.5115228</span> , <span class="number">0.270992</span>  , <span class="number">0.19087596</span>, <span class="number">0.64201415</span>, <span class="number">0.879036</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出所有预测框</span></span><br><span class="line"><span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">    draw_rectangle(currentAxis, box)</span><br></pre></td></tr></table></figure>


<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/72.png" alt="png"></p>
<br>

<p><strong>非极大值抑制（non-maximum suppression, nms）</strong></p>
<p>这里使用非极大值抑制来消除冗余框。基本思想是，如果有多个预测框都对应同一个物体，则只选出得分最高的那个预测框，剩下的预测框被丢弃掉。如何判断两个预测框对应的是同一个物体呢，标准该怎么设置？<strong>如果两个预测框的类别一样，而且他们的位置重合度比较大，则可以认为他们是在预测同一个目标</strong>。</p>
<p><code>非极大值抑制的做法是，选出某个类别得分最高的预测框，然后看哪些预测框跟它的IoU大于阈值，就把这些预测框给丢弃掉。这里IoU的阈值是超参数，需要提前设置，YOLOv3模型里面设置的是0.5</code>。</p>
<p>比如在上面的程序中，boxes里面一共对应11个预测框，scores给出了它们预测”人”这一类别的得分。</p>
<ul>
<li>Step0：创建选中列表，keep_list &#x3D; []</li>
<li>Step1：对得分进行排序，remain_list &#x3D; [ 3,  5, 10,  2,  9,  0,  1,  6,  4,  7,  8]， </li>
<li>Step2：选出boxes[3]，此时keep_list为空，不需要计算IoU，直接将其放入keep_list，keep_list &#x3D; [3]， remain_list&#x3D;[5, 10,  2,  9,  0,  1,  6,  4,  7,  8]</li>
<li>Step3：选出boxes[5]，此时keep_list中已经存在boxes[3]，计算出IoU(boxes[3], boxes[5]) &#x3D; 0.0，显然小于阈值，则keep_list&#x3D;[3, 5], remain_list &#x3D; [10,  2,  9,  0,  1,  6,  4,  7,  8]</li>
<li>Step4：选出boxes[10]，此时keep_list&#x3D;[3, 5]，计算IoU(boxes[3], boxes[10])&#x3D;0.0268，IoU(boxes[5], boxes[10])&#x3D;0.0268 &#x3D; 0.24，都小于阈值，则keep_list &#x3D; [3, 5, 10]，remain_list&#x3D;[2,  9,  0,  1,  6,  4,  7,  8]</li>
<li>Step5：选出boxes[2]，此时keep_list &#x3D; [3, 5, 10]，计算IoU(boxes[3], boxes[2]) &#x3D; 0.88，超过了阈值，直接将boxes[2]丢弃，keep_list&#x3D;[3, 5, 10]，remain_list&#x3D;[9,  0,  1,  6,  4,  7,  8]</li>
<li>Step6：选出boxes[9]，此时keep_list &#x3D; [3, 5, 10]，计算IoU(boxes[3], boxes[9]) &#x3D; 0.0577，IoU(boxes[5], boxes[9]) &#x3D; 0.205，IoU(boxes[10], boxes[9]) &#x3D; 0.88，超过了阈值，将boxes[9]丢弃掉。keep_list&#x3D;[3, 5, 10]，remain_list&#x3D;[0,  1,  6,  4,  7,  8]</li>
<li>Step7：重复上述Step6直到remain_list为空。</li>
</ul>
<p>最终得到keep_list&#x3D;[3, 5, 10]，也就是预测框3、5、10被最终挑选出来了，如下图所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 画图展示目标物体边界框</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"><span class="keyword">from</span> matplotlib.image <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义画矩形框的程序    </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_rectangle</span>(<span class="params">currentAxis, bbox, edgecolor = <span class="string">&#x27;k&#x27;</span>, facecolor = <span class="string">&#x27;y&#x27;</span>, fill=<span class="literal">False</span>, linestyle=<span class="string">&#x27;-&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># currentAxis，坐标轴，通过plt.gca()获取</span></span><br><span class="line">    <span class="comment"># bbox，边界框，包含四个数值的list， [x1, y1, x2, y2]</span></span><br><span class="line">    <span class="comment"># edgecolor，边框线条颜色</span></span><br><span class="line">    <span class="comment"># facecolor，填充颜色</span></span><br><span class="line">    <span class="comment"># fill, 是否填充</span></span><br><span class="line">    <span class="comment"># linestype，边框线型</span></span><br><span class="line">    <span class="comment"># patches.Rectangle需要传入左上角坐标、矩形区域的宽度、高度等参数</span></span><br><span class="line">    rect=patches.Rectangle((bbox[<span class="number">0</span>], bbox[<span class="number">1</span>]), bbox[<span class="number">2</span>]-bbox[<span class="number">0</span>]+<span class="number">1</span>, bbox[<span class="number">3</span>]-bbox[<span class="number">1</span>]+<span class="number">1</span>, linewidth=<span class="number">1</span>,</span><br><span class="line">                           edgecolor=edgecolor,facecolor=facecolor,fill=fill, linestyle=linestyle)</span><br><span class="line">    currentAxis.add_patch(rect)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;000000086956.jpg&#x27;</span></span><br><span class="line">im = imread(filename)</span><br><span class="line">plt.imshow(im)</span><br><span class="line"></span><br><span class="line">currentAxis=plt.gca()</span><br><span class="line"></span><br><span class="line">boxes = np.array([[<span class="number">4.21716537e+01</span>, <span class="number">1.28230896e+02</span>, <span class="number">2.26547668e+02</span>, <span class="number">6.00434631e+02</span>],</span><br><span class="line">       [<span class="number">3.18562988e+02</span>, <span class="number">1.23168472e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.05688416e+02</span>],</span><br><span class="line">       [<span class="number">2.62704697e+01</span>, <span class="number">1.39430557e+02</span>, <span class="number">2.20587097e+02</span>, <span class="number">6.38959656e+02</span>],</span><br><span class="line">       [<span class="number">4.24965363e+01</span>, <span class="number">1.42706665e+02</span>, <span class="number">2.25955185e+02</span>, <span class="number">6.35671204e+02</span>],</span><br><span class="line">       [<span class="number">2.37462646e+02</span>, <span class="number">1.35731537e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.31451294e+02</span>],</span><br><span class="line">       [<span class="number">3.19390472e+02</span>, <span class="number">1.29295090e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.33003845e+02</span>],</span><br><span class="line">       [<span class="number">3.28933838e+02</span>, <span class="number">1.22736115e+02</span>, <span class="number">4.79000000e+02</span>, <span class="number">6.39000000e+02</span>],</span><br><span class="line">       [<span class="number">4.44292603e+01</span>, <span class="number">1.70438187e+02</span>, <span class="number">2.26841858e+02</span>, <span class="number">6.39000000e+02</span>],</span><br><span class="line">       [<span class="number">2.17988785e+02</span>, <span class="number">3.02472412e+02</span>, <span class="number">4.06062927e+02</span>, <span class="number">6.29106628e+02</span>],</span><br><span class="line">       [<span class="number">2.00241089e+02</span>, <span class="number">3.23755096e+02</span>, <span class="number">3.96929321e+02</span>, <span class="number">6.36386108e+02</span>],</span><br><span class="line">       [<span class="number">2.14310303e+02</span>, <span class="number">3.23443665e+02</span>, <span class="number">4.06732849e+02</span>, <span class="number">6.35775269e+02</span>]])</span><br><span class="line"> </span><br><span class="line">scores = np.array([<span class="number">0.5247661</span> , <span class="number">0.51759845</span>, <span class="number">0.86075854</span>, <span class="number">0.9910175</span> , <span class="number">0.39170712</span>,</span><br><span class="line">       <span class="number">0.9297706</span> , <span class="number">0.5115228</span> , <span class="number">0.270992</span>  , <span class="number">0.19087596</span>, <span class="number">0.64201415</span>, <span class="number">0.879036</span>])</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出最终保留的预测框</span></span><br><span class="line">inds = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    box = boxes[inds[i]]</span><br><span class="line">    draw_rectangle(currentAxis, box, edgecolor=colors[i])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/73.png" alt="png"></p>
<p>非极大值抑制的具体实现代码如下面的<code>nms</code>函数的定义，需要说明的是数据集中含有多个类别的物体，所以这里需要做多分类非极大值抑制，其实现原理与非极大值抑制相同，区别在于需要对每个类别都做非极大值抑制，实现代码如下面的<code>multiclass_nms</code>所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 非极大值抑制</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nms</span>(<span class="params">bboxes, scores, score_thresh, nms_thresh, pre_nms_topk, i=<span class="number">0</span>, c=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    nms</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 从小到大排列取出索引</span></span><br><span class="line">    inds = np.argsort(scores)</span><br><span class="line">    inds = inds[::-<span class="number">1</span>]</span><br><span class="line">    keep_inds = []</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">len</span>(inds) &gt; <span class="number">0</span>):</span><br><span class="line">        cur_ind = inds[<span class="number">0</span>]</span><br><span class="line">        cur_score = scores[cur_ind]</span><br><span class="line">        <span class="comment"># if score of the box is less than score_thresh, just drop it</span></span><br><span class="line">        <span class="keyword">if</span> cur_score &lt; score_thresh:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        keep = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> ind <span class="keyword">in</span> keep_inds:</span><br><span class="line">            current_box = bboxes[cur_ind]</span><br><span class="line">            remain_box = bboxes[ind]</span><br><span class="line">            iou = box_iou_xyxy(current_box, remain_box)</span><br><span class="line">            <span class="keyword">if</span> iou &gt; nms_thresh:</span><br><span class="line">                keep = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="comment">#if i == 0 and c == 4 and cur_ind == 951:</span></span><br><span class="line">            <span class="comment">#print(&#x27;suppressed, &#x27;, keep, i, c, cur_ind, ind, iou)</span></span><br><span class="line">        <span class="keyword">if</span> keep:</span><br><span class="line">            keep_inds.append(cur_ind)</span><br><span class="line">        inds = inds[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(keep_inds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多分类非极大值抑制</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multiclass_nms</span>(<span class="params">bboxes, scores, score_thresh=<span class="number">0.01</span>, nms_thresh=<span class="number">0.45</span>, pre_nms_topk=<span class="number">1000</span>, pos_nms_topk=<span class="number">100</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This is for multiclass_nms</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batch_size = bboxes.shape[<span class="number">0</span>]</span><br><span class="line">    class_num = scores.shape[<span class="number">1</span>]</span><br><span class="line">    rets = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">        bboxes_i = bboxes[i]</span><br><span class="line">        scores_i = scores[i]</span><br><span class="line">        ret = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(class_num):</span><br><span class="line">            scores_i_c = scores_i[c]</span><br><span class="line">            keep_inds = nms(bboxes_i, scores_i_c, score_thresh, nms_thresh, pre_nms_topk, i=i, c=c)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(keep_inds) &lt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            keep_bboxes = bboxes_i[keep_inds]</span><br><span class="line">            keep_scores = scores_i_c[keep_inds]</span><br><span class="line">            keep_results = np.zeros([keep_scores.shape[<span class="number">0</span>], <span class="number">6</span>])</span><br><span class="line">            keep_results[:, <span class="number">0</span>] = c</span><br><span class="line">            keep_results[:, <span class="number">1</span>] = keep_scores[:]</span><br><span class="line">            keep_results[:, <span class="number">2</span>:<span class="number">6</span>] = keep_bboxes[:, :]</span><br><span class="line">            ret.append(keep_results)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ret) &lt; <span class="number">1</span>:</span><br><span class="line">            rets.append(ret)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        ret_i = np.concatenate(ret, axis=<span class="number">0</span>)</span><br><span class="line">        scores_i = ret_i[:, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(scores_i) &gt; pos_nms_topk:</span><br><span class="line">            inds = np.argsort(scores_i)[::-<span class="number">1</span>]</span><br><span class="line">            inds = inds[:pos_nms_topk]</span><br><span class="line">            ret_i = ret_i[inds]</span><br><span class="line"></span><br><span class="line">        rets.append(ret_i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> rets</span><br></pre></td></tr></table></figure>

<p>下面是完整的测试程序，在测试数据集上的输出结果将会被保存在<code>pred_results.json</code>文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算IoU，矩形框的坐标形式为xyxy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">box_iou_xyxy</span>(<span class="params">box1, box2</span>):</span><br><span class="line">    <span class="comment"># 获取box1左上角和右下角的坐标</span></span><br><span class="line">    x1min, y1min, x1max, y1max = box1[<span class="number">0</span>], box1[<span class="number">1</span>], box1[<span class="number">2</span>], box1[<span class="number">3</span>]</span><br><span class="line">    <span class="comment"># 计算box1的面积</span></span><br><span class="line">    s1 = (y1max - y1min + <span class="number">1.</span>) * (x1max - x1min + <span class="number">1.</span>)</span><br><span class="line">    <span class="comment"># 获取box2左上角和右下角的坐标</span></span><br><span class="line">    x2min, y2min, x2max, y2max = box2[<span class="number">0</span>], box2[<span class="number">1</span>], box2[<span class="number">2</span>], box2[<span class="number">3</span>]</span><br><span class="line">    <span class="comment"># 计算box2的面积</span></span><br><span class="line">    s2 = (y2max - y2min + <span class="number">1.</span>) * (x2max - x2min + <span class="number">1.</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算相交矩形框的坐标</span></span><br><span class="line">    xmin = np.maximum(x1min, x2min)</span><br><span class="line">    ymin = np.maximum(y1min, y2min)</span><br><span class="line">    xmax = np.minimum(x1max, x2max)</span><br><span class="line">    ymax = np.minimum(y1max, y2max)</span><br><span class="line">    <span class="comment"># 计算相交矩形行的高度、宽度、面积</span></span><br><span class="line">    inter_h = np.maximum(ymax - ymin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">    inter_w = np.maximum(xmax - xmin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">    intersection = inter_h * inter_w</span><br><span class="line">    <span class="comment"># 计算相并面积</span></span><br><span class="line">    union = s1 + s2 - intersection</span><br><span class="line">    <span class="comment"># 计算交并比</span></span><br><span class="line">    iou = intersection / union</span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压 yolo_epoch50 数据脚本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;开始解压......&#x27;</span>)</span><br><span class="line">!unzip  -o -q -d  /home/aistudio /home/aistudio/data/data170339/yolo_epoch50.<span class="built_in">zip</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;解压完成&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>开始解压......
解压完成
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">ANCHORS = [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>, <span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>, <span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>]</span><br><span class="line">ANCHOR_MASKS = [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">VALID_THRESH = <span class="number">0.01</span></span><br><span class="line">NMS_TOPK = <span class="number">400</span></span><br><span class="line">NMS_POSK = <span class="number">100</span></span><br><span class="line">NMS_THRESH = <span class="number">0.45</span></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    TRAINDIR = <span class="string">&#x27;/home/aistudio/work/insects/train/images&#x27;</span></span><br><span class="line">    TESTDIR = <span class="string">&#x27;/home/aistudio/work/insects/test/images&#x27;</span></span><br><span class="line">    VALIDDIR = <span class="string">&#x27;/home/aistudio/work/insects/val&#x27;</span></span><br><span class="line"></span><br><span class="line">    model = YOLOv3(num_classes=NUM_CLASSES)</span><br><span class="line">    params_file_path = <span class="string">&#x27;/home/aistudio/yolo_epoch50.pdparams&#x27;</span></span><br><span class="line">    model_state_dict = paddle.load(params_file_path)</span><br><span class="line">    model.load_dict(model_state_dict)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    total_results = []</span><br><span class="line">    test_loader = test_data_loader(TESTDIR, batch_size= <span class="number">1</span>, mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">        img_name, img_data, img_scale_data = data</span><br><span class="line">        img = paddle.to_tensor(img_data)</span><br><span class="line">        img_scale = paddle.to_tensor(img_scale_data)</span><br><span class="line"></span><br><span class="line">        outputs = model.forward(img)</span><br><span class="line">        bboxes, scores = model.get_pred(outputs,</span><br><span class="line">                                 im_shape=img_scale,</span><br><span class="line">                                 anchors=ANCHORS,</span><br><span class="line">                                 anchor_masks=ANCHOR_MASKS,</span><br><span class="line">                                 valid_thresh = VALID_THRESH)</span><br><span class="line"></span><br><span class="line">        bboxes_data = bboxes.numpy()</span><br><span class="line">        scores_data = scores.numpy()</span><br><span class="line">        result = multiclass_nms(bboxes_data, scores_data,</span><br><span class="line">                      score_thresh=VALID_THRESH, </span><br><span class="line">                      nms_thresh=NMS_THRESH, </span><br><span class="line">                      pre_nms_topk=NMS_TOPK, </span><br><span class="line">                      pos_nms_topk=NMS_POSK)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result)):</span><br><span class="line">            result_j = result[j]</span><br><span class="line">            img_name_j = img_name[j]</span><br><span class="line">            total_results.append([img_name_j, result_j.tolist()])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;processed &#123;&#125; pictures&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(total_results)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    json.dump(total_results, <span class="built_in">open</span>(<span class="string">&#x27;pred_results.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>json文件中保存着测试结果，是包含所有图片预测结果的list，其构成如下：</p>
<pre><code>[[img_name, [[label, score, x1, y1, x2, y2], ..., [label, score, x1, y1, x2, y2]]], 
 [img_name, [[label, score, x1, y1, x2, y2], ..., [label, score, x1, y1, x2, y2]]],
  ...
 [img_name, [[label, score, x1, y1, x2, y2],..., [label, score, x1, y1, x2, y2]]]]
</code></pre>
<p>list中的每一个元素是一张图片的预测结果，list的总长度等于图片的数目，每张图片预测结果的格式是：</p>
<pre><code> [img_name, [[label, score, x1, y1, x2, y2],..., [label, score, x1, y1, x2, y2]]]
</code></pre>
<p>其中第一个元素是图片名称image_name，第二个元素是包含该图片所有预测框的list， 预测框列表：</p>
<pre><code> [[label, score, x1, x2, y1, y2],..., [label, score, x1, y1, x2, y2]]
</code></pre>
<p>预测框列表中每个元素[label, score, x1, y1, x2, y2]描述了一个预测框，label是预测框所属类别标签，score是预测框的得分；x1, y1, x2, y2对应预测框左上角坐标(x1, y1)，右下角坐标(x2, y2)。每张图片可能有很多个预测框，则将其全部放在预测框列表中。</p>
<h2 id="9-模型效果及可视化展示"><a href="#9-模型效果及可视化展示" class="headerlink" title="9.模型效果及可视化展示"></a><strong>9.模型效果及可视化展示</strong></h2><p>上面的程序展示了如何读取测试数据集的图片，并将最终结果保存在json格式的文件中。为了更直观的给读者展示模型效果，下面的程序添加了如何读取单张图片，并画出其产生的预测框。</p>
<p><strong>1. 创建数据读取器以读取单张图片的数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取单张测试图片</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">single_image_data_loader</span>(<span class="params">filename, test_image_size=<span class="number">608</span>, mode=<span class="string">&#x27;test&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载测试用的图片，测试数据没有groundtruth标签</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batch_size= <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reader</span>():</span><br><span class="line">        batch_data = []</span><br><span class="line">        img_size = test_image_size</span><br><span class="line">        file_path = os.path.join(filename)</span><br><span class="line">        img = cv2.imread(file_path)</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">        H = img.shape[<span class="number">0</span>]</span><br><span class="line">        W = img.shape[<span class="number">1</span>]</span><br><span class="line">        img = cv2.resize(img, (img_size, img_size))</span><br><span class="line"></span><br><span class="line">        mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">        std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">        mean = np.array(mean).reshape((<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">        std = np.array(std).reshape((<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">        out_img = (img / <span class="number">255.0</span> - mean) / std</span><br><span class="line">        out_img = out_img.astype(<span class="string">&#x27;float32&#x27;</span>).transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        img = out_img <span class="comment">#np.transpose(out_img, (2,0,1))</span></span><br><span class="line">        im_shape = [H, W]</span><br><span class="line"></span><br><span class="line">        batch_data.append((image_name.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>], img, im_shape))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(batch_data) == batch_size:</span><br><span class="line">            <span class="keyword">yield</span> make_test_array(batch_data)</span><br><span class="line">            batch_data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reader</span><br></pre></td></tr></table></figure>

<p><strong>2. 定义绘制预测框的画图函数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义画图函数</span></span><br><span class="line">INSECT_NAMES = [<span class="string">&#x27;Boerner&#x27;</span>, <span class="string">&#x27;Leconte&#x27;</span>, <span class="string">&#x27;Linnaeus&#x27;</span>, </span><br><span class="line">                <span class="string">&#x27;acuminatus&#x27;</span>, <span class="string">&#x27;armandi&#x27;</span>, <span class="string">&#x27;coleoptera&#x27;</span>, <span class="string">&#x27;linnaeus&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义画矩形框的函数 </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_rectangle</span>(<span class="params">currentAxis, bbox, edgecolor = <span class="string">&#x27;k&#x27;</span>, facecolor = <span class="string">&#x27;y&#x27;</span>, fill=<span class="literal">False</span>, linestyle=<span class="string">&#x27;-&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># currentAxis，坐标轴，通过plt.gca()获取</span></span><br><span class="line">    <span class="comment"># bbox，边界框，包含四个数值的list， [x1, y1, x2, y2]</span></span><br><span class="line">    <span class="comment"># edgecolor，边框线条颜色</span></span><br><span class="line">    <span class="comment"># facecolor，填充颜色</span></span><br><span class="line">    <span class="comment"># fill, 是否填充</span></span><br><span class="line">    <span class="comment"># linestype，边框线型</span></span><br><span class="line">    <span class="comment"># patches.Rectangle需要传入左上角坐标、矩形区域的宽度、高度等参数</span></span><br><span class="line">    rect=patches.Rectangle((bbox[<span class="number">0</span>], bbox[<span class="number">1</span>]), bbox[<span class="number">2</span>]-bbox[<span class="number">0</span>]+<span class="number">1</span>, bbox[<span class="number">3</span>]-bbox[<span class="number">1</span>]+<span class="number">1</span>, linewidth=<span class="number">1</span>,</span><br><span class="line">                           edgecolor=edgecolor,facecolor=facecolor,fill=fill, linestyle=linestyle)</span><br><span class="line">    currentAxis.add_patch(rect)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义绘制预测结果的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_results</span>(<span class="params">result, filename, draw_thresh=<span class="number">0.5</span></span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">    im = imread(filename)</span><br><span class="line">    plt.imshow(im)</span><br><span class="line">    currentAxis=plt.gca()</span><br><span class="line">    colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;purple&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">        box = item[<span class="number">2</span>:<span class="number">6</span>]</span><br><span class="line">        label = <span class="built_in">int</span>(item[<span class="number">0</span>])</span><br><span class="line">        name = INSECT_NAMES[label]</span><br><span class="line">        <span class="keyword">if</span> item[<span class="number">1</span>] &gt; draw_thresh:</span><br><span class="line">            draw_rectangle(currentAxis, box, edgecolor = colors[label])</span><br><span class="line">            plt.text(box[<span class="number">0</span>], box[<span class="number">1</span>], name, fontsize=<span class="number">12</span>, color=colors[label])</span><br></pre></td></tr></table></figure>

<p><strong>3. 读取与预测可视化</strong></p>
<p>使用上面定义的single_image_data_loader函数读取指定的图片，输入网络并计算出预测框和得分，然后使用多分类非极大值抑制消除冗余的框。将最终结果画图展示出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">ANCHORS = [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">33</span>, <span class="number">23</span>, <span class="number">30</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">45</span>, <span class="number">59</span>, <span class="number">119</span>, <span class="number">116</span>, <span class="number">90</span>, <span class="number">156</span>, <span class="number">198</span>, <span class="number">373</span>, <span class="number">326</span>]</span><br><span class="line">ANCHOR_MASKS = [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">VALID_THRESH = <span class="number">0.01</span></span><br><span class="line">NMS_TOPK = <span class="number">400</span></span><br><span class="line">NMS_POSK = <span class="number">100</span></span><br><span class="line">NMS_THRESH = <span class="number">0.45</span></span><br><span class="line"></span><br><span class="line">NUM_CLASSES = <span class="number">7</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    image_name = <span class="string">&#x27;/home/aistudio/work/insects/test/images/1880.jpeg&#x27;</span></span><br><span class="line">    params_file_path = <span class="string">&#x27;/home/aistudio/yolo_epoch50.pdparams&#x27;</span></span><br><span class="line"></span><br><span class="line">    model = YOLOv3(num_classes=NUM_CLASSES)</span><br><span class="line">    model_state_dict = paddle.load(params_file_path)</span><br><span class="line">    model.load_dict(model_state_dict)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    total_results = []</span><br><span class="line">    test_loader = single_image_data_loader(image_name, mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">        img_name, img_data, img_scale_data = data</span><br><span class="line">        img = paddle.to_tensor(img_data)</span><br><span class="line">        img_scale = paddle.to_tensor(img_scale_data)</span><br><span class="line"></span><br><span class="line">        outputs = model.forward(img)</span><br><span class="line">        bboxes, scores = model.get_pred(outputs,</span><br><span class="line">                                 im_shape=img_scale,</span><br><span class="line">                                 anchors=ANCHORS,</span><br><span class="line">                                 anchor_masks=ANCHOR_MASKS,</span><br><span class="line">                                 valid_thresh = VALID_THRESH)</span><br><span class="line"></span><br><span class="line">        bboxes_data = bboxes.numpy()</span><br><span class="line">        scores_data = scores.numpy()</span><br><span class="line">        results = multiclass_nms(bboxes_data, scores_data,</span><br><span class="line">                      score_thresh=VALID_THRESH, </span><br><span class="line">                      nms_thresh=NMS_THRESH, </span><br><span class="line">                      pre_nms_topk=NMS_TOPK, </span><br><span class="line">                      pos_nms_topk=NMS_POSK)</span><br><span class="line"></span><br><span class="line">result = results[<span class="number">0</span>]</span><br><span class="line">draw_results(result, image_name, draw_thresh=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>


<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/74.png" alt="png"></p>
<p>通过上面的程序，清晰的给读者展示了如何使用训练好的权重，对图片进行预测并将结果可视化。最终输出的图片上，检测出了每个昆虫，标出了它们的边界框和具体类别。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space">小漁头&amp;小戴</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.3-YOLOv3%E5%AE%9E%E7%8E%B0AI%E8%AF%86%E8%99%AB%EF%BC%88%E4%B8%8B%EF%BC%89/">http://blog.dai2yutou.space/2023/01/03/深度学习6.3-YOLOv3实现AI识虫（下）/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.dai2yutou.space" target="_blank">小漁头|小戴</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/paddle/">paddle</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%AB%98%E7%BA%A7-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B9%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">深度学习高级_计算机视觉之目标检测</a></div><div class="post_share"><div class="social-share" data-image="https://picbed.dai2yutou.space/web_img/19.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css" media="print" onload="this.media='all'"><script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.2-YOLOv3%E5%AE%9E%E7%8E%B0AI%E8%AF%86%E8%99%AB%EF%BC%88%E4%B8%8A%EF%BC%89/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">深度学习6.2-YOLOv3实现AI识虫（上）</div></div></a></div><div class="next-post pull-right"><a href="/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.4-%E5%85%B6%E4%BB%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习6.4-其他目标检测模型概述</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.2-YOLOv3%E5%AE%9E%E7%8E%B0AI%E8%AF%86%E8%99%AB%EF%BC%88%E4%B8%8A%EF%BC%89/" title="深度学习6.2-YOLOv3实现AI识虫（上）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-03</div><div class="title">深度学习6.2-YOLOv3实现AI识虫（上）</div></div></a></div><div><a href="/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" title="深度学习6.1-目标检测基本概念"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-03</div><div class="title">深度学习6.1-目标检测基本概念</div></div></a></div><div><a href="/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.4-%E5%85%B6%E4%BB%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/" title="深度学习6.4-其他目标检测模型概述"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-03</div><div class="title">深度学习6.4-其他目标检测模型概述</div></div></a></div><div><a href="/2022/12/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="深度学习1.1-深度学习概论"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-18</div><div class="title">深度学习1.1-深度学习概论</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/" title="深度学习2.1-线性回归模型的实现"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.1-线性回归模型的实现</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" title="深度学习2.2-神经网络中的分类任务"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.2-神经网络中的分类任务</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="animate__fadeIn card-info card-widget wow" data-wow-delay="0" data-wow-duration="" data-wow-iteration="" data-wow-offset="" style="visibility: visible; animation-name: fadeIn;"><div class="author-info-top"><div class="card-info-avatar"><a class="avatar-img" data-pjax-state="" href="/about"><img class="entered loaded" alt="avatar" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/apple-touch-icon.jpg" onerror="this.onerror=null,this.src=&quot;/img/friend_404.gif&quot;"/></a><div class="author-status-box"><div class="author-status"><g-emoji class="g-emoji" alias="palm_tree" fallback-src="/img/tree_icon.png">🐟</g-emoji><span>摸鱼中~</span></div></div></div></div><div class="author-info__sayhi" id="author-info__sayhi">晚安😴！我是</div><h1 class="author-info__name">XiaoYutou|XiaoDai</h1><div class="author-info__description">热爱生活点滴，分享时刻精彩。</div><a id="card-info-btn" data-pjax-state="" onclick="pjax.loadUrl(/about/)"><i></i><span style="padding-left:32px;font-weight:600;font-size:large">了解更多<i class="faa-passing animated" style="padding-left:-2px;display:inline-block;vertical-align:middle;"><span style="height:28px;width:28px;fill:currentColor;position:relative;top:-1.5px">💨</span></i></span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xiaoyutoua" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2143191301@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>主域名:<a target="_blank" rel="noopener" href="https://www.dai2yutou.space">小漁头|小戴</a><br><span>技术问题欢迎交流🧐</span><span color="#3eb8be">VX:yuguolong_001</span></center></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%9F%BA%E4%BA%8EYOLOv3%E7%9A%84AI%E8%AF%86%E8%99%AB%E5%AE%9E%E9%AA%8C"><span class="toc-text">一、基于YOLOv3的AI识虫实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="toc-text">实验环境</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%8D%95%E9%98%B6%E6%AE%B5%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8BYOLOv3"><span class="toc-text">二、单阶段目标检测模型YOLOv3</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A6%82%E8%BF%B0"><span class="toc-text">1. 概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-YOLOv3%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">2. YOLOv3模型设计思想</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-YOLOv3%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-text">3. YOLOv3模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E4%BA%A7%E7%94%9F%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F"><span class="toc-text">3.1 产生候选区域</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81"><span class="toc-text">3.2 卷积网络提取特征</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%A0%B9%E6%8D%AE%E8%BE%93%E5%87%BA%E7%89%B9%E5%BE%81%E5%9B%BE%E8%AE%A1%E7%AE%97%E9%A2%84%E6%B5%8B%E6%A1%86%E4%BD%8D%E7%BD%AE%E5%92%8C%E7%B1%BB%E5%88%AB"><span class="toc-text">4.根据输出特征图计算预测框位置和类别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1%E5%BB%BA%E7%AB%8B%E8%BE%93%E5%87%BA%E7%89%B9%E5%BE%81%E5%9B%BE%E4%B8%8E%E9%A2%84%E6%B5%8B%E6%A1%86%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E8%81%94"><span class="toc-text">4.1建立输出特征图与预测框之间的关联</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2%E8%AE%A1%E7%AE%97%E9%A2%84%E6%B5%8B%E6%A1%86%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E7%89%A9%E4%BD%93%E7%9A%84%E6%A6%82%E7%8E%87"><span class="toc-text">4.2计算预测框是否包含物体的概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3%E8%AE%A1%E7%AE%97%E9%A2%84%E6%B5%8B%E6%A1%86%E4%BD%8D%E7%BD%AE%E5%9D%90%E6%A0%87"><span class="toc-text">4.3计算预测框位置坐标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4%E8%AE%A1%E7%AE%97%E7%89%A9%E4%BD%93%E5%B1%9E%E4%BA%8E%E6%AF%8F%E4%B8%AA%E7%B1%BB%E5%88%AB%E6%A6%82%E7%8E%87"><span class="toc-text">4.4计算物体属于每个类别概率</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">5.损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%A3%80%E6%B5%8B"><span class="toc-text">6.多尺度检测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%BC%80%E5%90%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AE%AD%E7%BB%83"><span class="toc-text">7.开启端到端训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E9%A2%84%E6%B5%8B"><span class="toc-text">8.预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B1%95%E7%A4%BA"><span class="toc-text">9.模型效果及可视化展示</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/06/07/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%9F%EF%BC%9F%EF%BC%9F/" title="如何学习动态规划？？？"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/28.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何学习动态规划？？？"/></a><div class="content"><a class="title" href="/2023/06/07/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%9F%EF%BC%9F%EF%BC%9F/" title="如何学习动态规划？？？">如何学习动态规划？？？</a><time datetime="2023-06-07T15:58:25.000Z" title="发表于 2023-06-07 23:58:25">2023-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/30/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E7%9A%84%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="基于时间片轮转的进程管理系统的设计与实现"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/27.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于时间片轮转的进程管理系统的设计与实现"/></a><div class="content"><a class="title" href="/2023/05/30/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E7%9A%84%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="基于时间片轮转的进程管理系统的设计与实现">基于时间片轮转的进程管理系统的设计与实现</a><time datetime="2023-05-30T15:25:36.000Z" title="发表于 2023-05-30 23:25:36">2023-05-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/29/Python%E5%9B%9B%E5%A4%A7%E6%B3%95%E5%AE%9D/" title="Python四大法宝"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python四大法宝"/></a><div class="content"><a class="title" href="/2023/05/29/Python%E5%9B%9B%E5%A4%A7%E6%B3%95%E5%AE%9D/" title="Python四大法宝">Python四大法宝</a><time datetime="2023-05-29T05:19:20.000Z" title="发表于 2023-05-29 13:19:20">2023-05-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 小漁头&小戴</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.6/translate/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script defer src="/js/light.js"></script><canvas id="universe"></canvas><script defer src="/js/starry_sky.js"></script><script defer src="/js/console.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script async data-pjax src="/js/card_author.js"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JzK9w99AgP1g6fso",ck:"JzK9w99AgP1g6fso"})</script><script type="text/javascript" src ="/js/reward.js" ></script><script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.6.16/dist/sweetalert2.all.min.js"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = 'b16a1fa0e63c46a4b8f28abfb06ae3fe';
  var gaud_map_key = 'e2b04289e870b005374ee030148d64fd&s=rsv3';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/4.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">英文水平不高，咋翻译论文？</a><div class="blog-slider__text">英文水平不高，咋翻译论文？</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/web_background2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-17</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">🐌博客搭建学习笔记</a><div class="blog-slider__text">这是再搭建博客已经写文章时遇到的bug和对博客的一些必要操作，不定时更新哦~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/9.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">Butterfly外挂标签</a><div class="blog-slider__text">本文是撰写博客文章时可能会用到的外挂标签汇总，放到一起，便于查阅和使用</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/3.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">第一篇文章</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">Hexo发生error：spawn failed错误的解决方法</a><div class="blog-slider__text">Hexo发生error：spawn failed错误的解决方法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-06</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">Hexo博客备份与恢复</a><div class="blog-slider__text">本文旨在解决在不同电脑上都能维护博客或配置、发布的内容丢失可恢复的问题。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">Echarts社区地址</a><div class="blog-slider__text">一些Echarts图标的开源网站。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '2');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__bounceInRight');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/about/'|| '/about/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.dai2yutou.space/api?xiaoyutoua",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xiaoyutoua')
    }
  </script><!-- hexo injector body_end end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>