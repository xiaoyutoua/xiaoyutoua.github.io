<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>深度学习5.1-从全连接层到卷积 | 小漁头|小戴</title><meta name="author" content="小漁头&amp;小戴"><meta name="copyright" content="小漁头&amp;小戴"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="本文是深度学习的第九篇，主要分析了全连接层在图像识别上的局限性，介绍了卷积的基本结构、应用和池化">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习5.1-从全连接层到卷积">
<meta property="og:url" content="http://blog.dai2yutou.space/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.1-%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF/index.html">
<meta property="og:site_name" content="小漁头|小戴">
<meta property="og:description" content="本文是深度学习的第九篇，主要分析了全连接层在图像识别上的局限性，介绍了卷积的基本结构、应用和池化">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picbed.dai2yutou.space/web_img/19.png">
<meta property="article:published_time" content="2023-01-01T12:52:49.000Z">
<meta property="article:modified_time" content="2023-03-30T12:12:49.956Z">
<meta property="article:author" content="小漁头&amp;小戴">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="paddle">
<meta property="article:tag" content="深度学习基础_卷积基本概念及经典模型复现">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picbed.dai2yutou.space/web_img/19.png"><link rel="shortcut icon" href="/img/basketball.png"><link rel="canonical" href="http://blog.dai2yutou.space/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.1-%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 小漁头&小戴","link":"链接: ","source":"来源: 小漁头|小戴","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习5.1-从全连接层到卷积',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-30 20:12:49'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/css.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/at.alicdn.com/t/c/font_3829236_a49e40pee5.css"><link rel="stylesheet" href="/css/font-awesome.css"><link rel="stylesheet" href="/css/progress_bar.css"><link rel="stylesheet" href="/css/nav_menu.css"><link rel="stylesheet" href="/css/color.css"><link rel="apple-touch-icon" href="/img/apple-touch-icon.jpg"><meta name="apple-mobile-web-app-title" content="小漁头🏀"><link rel="bookmark" href="/img/apple-touch-icon.jpg"><link rel="apple-touch-icon-precomposed" sizes="180x180" href="/img/apple-touch-icon.jpg" ><link rel="stylesheet" href="/css/card_author.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (ture) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picbed.dai2yutou.space/web_img/19.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">小漁头|小戴</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习5.1-从全连接层到卷积</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-01T12:52:49.000Z" title="发表于 2023-01-01 20:52:49">2023-01-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-30T12:12:49.956Z" title="更新于 2023-03-30 20:12:49">2023-03-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>51分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习5.1-从全连接层到卷积"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="从全连接层到卷积"><a href="#从全连接层到卷积" class="headerlink" title="从全连接层到卷积"></a><strong>从全连接层到卷积</strong></h1><p>:label:<code>sec_why-conv</code></p>
<p>学习本节，希望你能够掌握以下知识点：</p>
<ul>
<li>能够分析全连接层的局限，分析利弊；</li>
<li>理解卷积神经网络理论提出的依据，即空间不变性；</li>
</ul>
<hr>
<h2 id="一、全连接层的局限"><a href="#一、全连接层的局限" class="headerlink" title="一、全连接层的局限"></a>一、全连接层的局限</h2><p>我们之前讨论的多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。</p>
<p>对于表格数据，我们寻找的模式可能涉及特征之间的交互，但是我们不能预先假设任何与特征交互相关的先验结构。此时，多层感知机可能是最好的选择，然而对于高维感知数据，这种缺少结构的网络可能会变得不实用。也就是说，MLP是一种稠密特征提取方式，而大多数时候，我们学习到的很可能是一种稀疏的特征。比如下面的图片识别：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/9868a70ef4af44329e7220f869d239ba1df8397ad1cc41beb279754572d82cfc" width = "500"></center>
<center><br>图1：实际场景中的图片数据</br></center>

<hr>
<blockquote>
<p><strong>扩展</strong>：稠密特征与稀疏特征</p>
<p>假如每个维度上都有值，本来是在 n 个维度上来表达这个样本，而现在只有个别维度上有效地表达了这个样本，这个特征可以说是稀疏特征。</p>
<p>稠密特征一般是相对稀疏特征来说的，类别特征经过独热编码之后比较稀疏，比如类别<code>[&#39;小猫&#39;,&#39;小狗&#39;,&#39;小熊&#39;,&#39;小猴&#39;]</code>被独热编码后的数据结构为<code>[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]</code>。但是像桌子的长度这种稠密特征数据的表达方式就是<code>[3.4,2.6,8.9,6.7]</code>。</p>
</blockquote>
<hr>
<p>我们都知道，图片在计算机内部以像素值的方式被存储，也就是说两张图在计算机看来，其实是这样子的。其中1代表白色，-1代表黑色。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/492f53fee2aa4c07864943a1952c463bb0f3ccd95ff043878d97b78f8caa1cb8" width = "500"></center>
<center><br>图2：计算机眼中的图片数据</br></center>

<p>如果把像素拆开，按照每像素逐个比较肯定是不科学的，因为单个像素是无法反映整体的，这样做会导致输入数据的<code>空间信息</code>被丢失。</p>
<p>除此以外，使用全连接网络参数过多时，网络训练缓慢。例如，在猫狗分类的例子中：假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。即使将隐藏层维度降低到1000，这个全连接层也将有$10^6 \times 10^3 = 10^9$个参数。想要训练这个模型将不可实现，因为需要有大量的GPU、分布式优化训练的经验和超乎常人的耐心。</p>
<p>虽然我们会认为要求百万像素的分辨率可能不是必要的。然而，即使分辨率减小为十万像素，使用 1000 个隐藏单元的隐藏层也可能不足以学习到良好的图像特征，在真实的系统中我们仍然需要数十亿个参数。</p>
<p>为了解决上述问题，我们引入<strong>卷积神经网络进行特征提取</strong>，既能提取到<strong>相邻像素点之间</strong>的特征模式，又能保证参数的个数不随图片尺寸变化。</p>
<p>下图是一个典型的卷积神经网络结构，多层卷积和池化层组合作用在输入图片上，在网络的最后通常会加入一系列全连接层，ReLU 激活函数一般加在卷积或者全连接层的输出上，网络中通常还会加入 Dropout 来防止过拟合。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/6d1440daa10944c899a7c98e1bed3931a09bae52730d4c20a65b322193d284e1" width = "1000"></center>
<center><br>图3：卷积神经网络经典结构</br></center>

<hr>
<h2 id="二、空间不变性"><a href="#二、空间不变性" class="headerlink" title="二、空间不变性"></a>二、空间不变性</h2><p>想象一下，假设你想从一张图片中找到某个物体。合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。理想情况下，我们的系统应该能够利用常识：猪通常不在天上飞，飞机通常不在水里游泳。但是，如果一只猪出现在图片顶部，我们还是应该认出它。</p>
<p>我们可以从儿童游戏”沃尔多在哪里”中得到灵感：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/207441057fea4c52a46c4362b5158dbae7ca2ffec7214b1f876f34929f5d00df" width = "700"></center>
<center><br>图4：Where's Waldo?</br></center>

<p>在这个游戏中包含了许多充斥着活动的混乱场景，而沃尔多通常潜伏在一些不太可能的位置，读者的目标就是找出他。尽管沃尔多的装扮很有特点，但是在眼花缭乱的场景中找到他也如大海捞针。</p>
<p>然而沃尔多的样子并不取决于他潜藏的地方，因此我们可以使用一个“沃尔多检测器”扫描图像，该检测器将图像分割成多个区域，并为每个区域包含沃尔多的可能性打分。</p>
<p>卷积神经网络正是将<strong>空间不变性（spatial invariance）</strong> 的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络架构：</p>
<ol>
<li><p><strong>平移不变性（translation invariance）</strong>：识别器的标准是统一的，不管检测对象出现在图像中的哪个位置，识别器应该对相同的图像区域具有相似的反应。</p>
</li>
<li><p><strong>局部性（locality）</strong>：识别器应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系。最终，可以聚合这些局部特征，以在整个图像级别进行预测。</p>
</li>
</ol>
<p>让我们看看这些原则是如何转化为数学表示的。首先，多层感知机的输入是二维图像$\mathbf{X}$（宽度、高度），其隐藏表示$\mathbf{H}$在数学上是一个矩阵，在代码中表示为二维张量。<br>其中$\mathbf{X}$和$\mathbf{H}$具有相同的形状。使用$[\mathbf{X}]_{i, j}$和$[\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置（$i$,$j$）处的像素。为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量$\mathsf{W}$。也就是说，我们从接收输入的长度变化变成了接收输入的高宽两个维度的变化，输入和输出各增加了一个维度，因此我们的权重变为<code>四维</code>。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/2c7a0cf210544349a96eb6c3c0e42cf7bfd86b3674ae4d5e90614e09f3a20b12" width = "600"></center>
<center><br>图5：全连接与卷积对比</br></center>

<p>假设$\mathbf{U}$包含偏置参数，我们可以将全连接层形式化地表示为</p>
<script type="math/tex; mode=display">
\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=   [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned}</script><p>其中，从$\mathsf{W}$到$\mathsf{V}$的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。<br>我们只需重新索引下标$(k, l)$，原来的$(k, l)$代表的是像素在图片中的绝对位置，现在我们引入了索引$a$和$b$通过在正偏移和负偏移之间移动覆盖了整个图像，使$k = i+a$、$l = j+b$，由此可得$[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+b}$。<br>也就是说，我们使用$a$和$b$来表示相对于某一任意点$(i, j)$的相对位置。对于隐藏表示中任意给定位置（$i$,$j$）处的像素值$[\mathbf{H}]_{i, j}$，可以通过在$x$中以$(i, j)$为中心对像素进行加权求和得到，加权使用的权重为$[\mathsf{V}]_{i, j, a, b}$。</p>
<blockquote>
<p>只考虑当前观察器扫到的区域，不考虑图片的其他他区域，所以用相对位置更为方便。</p>
</blockquote>
<h3 id="1）平移不变性"><a href="#1）平移不变性" class="headerlink" title="1）平移不变性"></a>1）平移不变性</h3><p>现在引用上述的第一个原则：平移不变性。这意味着检测对象在输入$\mathbf{X}$中的平移，应该仅导致隐藏表示$\mathbf{H}$中的平移。也就是说，$\mathsf{V}$和$\mathbf{U}$实际上不依赖于$(i, j)$的值，即$[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$。无论识别出来的目标特征在什么位置，我们的权重都是不变的。</p>
<p>我们希望，图像的一部分的统计特性与其他部分是一样的，因为我们可以将这一部分学习的特征用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。这就是<strong>卷积核（convolution kernel）</strong> 的概念，我们可以使用同一张卷积核遍历整张图片。并且$\mathbf{U}$是一个常数，比如$u$。因此，我们可以简化$\mathbf{H}$定义为：</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b} [\mathbf{X}]_{i+a, j+b}.</script><p>这就是<strong>卷积（convolution）</strong>。我们是在使用系数$[\mathbf{V}]_{a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\mathbf{H}]_{i, j}$。注意，$[\mathbf{V}]_{a, b}$的系数比$[\mathsf{V}]_{i, j, a, b}$少很多，因为前者不再依赖于图像中的位置。</p>
<p>在神经网络中，卷积被定义为不同位置的特征检测器，也就意味着，无论目标出现在图像中的哪个位置，它都会检测到同样的这些特征，输出同样的响应。比如人脸被移动到了图像左下角，卷积核直到移动到左下角的位置才会检测到它的特征。</p>
<h3 id="2）局部性"><a href="#2）局部性" class="headerlink" title="2）局部性"></a>2）局部性</h3><p>现在引用上述的第二个原则：局部性。如上所述，为了收集用来训练参数$[\mathbf{H}]_{i, j}$的相关信息，我们不应偏离到距$(i, j)$很远的地方。这意味着在$|a|&gt; \Delta$或$|b| &gt; \Delta$的范围之外，我们可以设置$[\mathbf{V}]_{a, b} = 0$。以 $(i, y)$ 为中心位置，我们允许向前向后移动 ${\Delta}$ 个位置，因此，我们可以将$[\mathbf{H}]_{i, j}$重写为</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.</script><p>通过这种方式，我们卷积层的权指的数量会成倍的减少，但仍然考虑到了整个图片的权指的信息。既考虑到整个的属性，又照顾到了跟它局部相关的点。对全连接层使用平移不变性和局部性会得到卷积层，所以卷积是一个特殊的全连接层。</p>
<h3 id="3）多通道"><a href="#3）多通道" class="headerlink" title="3）多通道"></a><strong>3）多通道</strong></h3><p>然而这种方法有一个问题：我们忽略了图像一般包含三个通道/三种原色（红色、绿色和蓝色）。实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含$1024 \times 1024 \times 3$个像素。前两个轴与像素的空间位置有关，而第三个轴可以看作是每个像素的多维表示。因此，我们将$\mathsf{X}$索引为$[\mathsf{X}]_{i, j, k}$。由此卷积相应地调整为$[\mathsf{V}]_{a,b,c}$，而不是$[\mathbf{V}]_{a,b}$。</p>
<p>此外，由于输入图像是三维的，我们的隐藏表示$\mathsf{H}$也最好采用三维张量。换句话说，对于每一个空间位置，我们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。</p>
<p>因此，我们可以把隐藏表示想象为一系列具有二维张量的通道（channel）。这些通道有时也被称为<strong>特征映射（feature maps）</strong>，因为每个通道都向后续层提供一组空间化的学习特征。在实际应用中，CNN可能使用更多的甚至几十个特征映射，以手写数字识别为例，学习到的特征如下，这20张图片对应了20个特征映射，每一个特征映射由 <em>5X5</em> 的图像表示：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/9474ec1bab0b4081b18fd6e34c77063d640d7618f993459fb68d6270bb94553f" width = "600"></center>
<center><br>图6：特征映射</br></center>

<p>为了支持输入$\mathsf{X}$和隐藏表示$\mathsf{H}$中的多个通道，我们可以在$\mathsf{V}$中添加第四个坐标，即$[\mathsf{V}]_{a, b, c, d}$。综上所述，</p>
<script type="math/tex; mode=display">
[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c},</script><p>其中隐藏表示$\mathsf{H}$中的索引$d$表示输出通道，而随后的输出将继续以三维张量$\mathsf{H}$作为输入进入下一个卷积层。所以这个最终的公式可以定义具有多个通道的卷积层，而其中$\mathsf{V}$是该卷积层的权重。</p>
<h2 id="三、卷积（Convolution）"><a href="#三、卷积（Convolution）" class="headerlink" title="三、卷积（Convolution）"></a>三、卷积（Convolution）</h2><p>这一小节将介绍卷积算法的原理和实现方案，并通过具体的案例展示如何使用卷积对图片进行操作，学习本节需要掌握如下内容：</p>
<ul>
<li><p>卷积计算</p>
</li>
<li><p>填充（padding）</p>
</li>
<li><p>步幅（stride）</p>
</li>
<li><p>感受野（Receptive Field）</p>
</li>
<li><p>多输入通道、多输出通道</p>
</li>
<li><p>飞桨卷积API介绍</p>
</li>
<li><p>卷积算子应用举例</p>
</li>
</ul>
<hr>
<h3 id="1）卷积计算"><a href="#1）卷积计算" class="headerlink" title="1）卷积计算"></a>1）卷积计算</h3><blockquote>
<p>将卷积核与图片关联起来。</p>
</blockquote>
<p>卷积是数学分析中的一种积分变换的方法，在图像处理中采用的是卷积的离散形式。这里需要说明的是，在卷积神经网络中，卷积层的实现方式实际上是数学中定义的<strong>互相关（cross-correlation）</strong> 运算，与数学分析中的卷积定义有所不同，这里跟其他框架和卷积神经网络的教程保持一致，都使用互相关运算作为卷积的定义，互相关是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。</p>
<p>具体的计算过程如 <strong>图7</strong> 所示。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/d5019afe174745efbf7a3d3c604b9c85eeddc947f7184446a9147d128863864d" width = "700"></center>
<center><br>图7：卷积计算过程</br></center>

<hr>
<blockquote>
<p><strong>说明：</strong></p>
<p><strong>卷积核（kernel）</strong> 也被叫做<strong>滤波器（filter）</strong>，假设卷积核的高和宽分别为$k_h$和$k_w$，则将称为$k_h\times k_w$卷积，比如$3\times5$卷积，就是指卷积核的高为3, 宽为5。</p>
</blockquote>
<hr>
<ul>
<li>如图7（a）所示：左边的图大小是$3\times3$，表示输入数据是一个维度为$3\times3$的二维数组；中间的图大小是$2\times2$，表示一个维度为$2\times2$的二维数组，我们将这个二维数组称为卷积核。先将卷积核的左上角与输入数据的左上角（即：输入数据的(0, 0)位置）对齐，把卷积核的每个元素跟其位置对应的输入数据中的元素相乘，再把所有乘积相加，得到卷积输出的第一个结果：</li>
</ul>
<script type="math/tex; mode=display">
0\times1 + 1\times2 + 2\times4 + 3\times5 = 25  \ \ \ \ \ \ \ (a)</script><ul>
<li>如图7（b）所示：将卷积核向右滑动，让卷积核左上角与输入数据中的(0,1)位置对齐，同样将卷积核的每个元素跟其位置对应的输入数据中的元素相乘，再把这4个乘积相加，得到卷积输出的第二个结果：</li>
</ul>
<script type="math/tex; mode=display">
0\times2 + 1\times3 + 2\times5 + 3\times6 = 31  \ \ \ \ \ \ \ (b)</script><ul>
<li>如图7（c）所示：将卷积核向下滑动，让卷积核左上角与输入数据中的(1, 0)位置对齐，可以计算得到卷积输出的第三个结果：</li>
</ul>
<script type="math/tex; mode=display">
0\times4 + 1\times5 + 2\times7 + 3\times8 = 43   \ \ \ \ \ \ \ (c)</script><ul>
<li>如图7（d）所示：将卷积核向右滑动，让卷积核左上角与输入数据中的(1, 1)位置对齐，可以计算得到卷积输出的第四个结果：</li>
</ul>
<script type="math/tex; mode=display">
0\times5 + 1\times6 + 2\times8 + 3\times9 = 49   \ \ \ \ \ \ \ (d)</script><center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/4219539eac53411281d1318343d84c38e1d21662c69742b8bd89df7c906cbe45" width = "700"></center>

<p>注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1，而卷积核只与图像中每个大小完全适合的位置进行互相关运算，这就导致必然会有一些值不参与运算。</p>
<p>所以，输出大小等于输入大小减去卷积核大小$k_h \times k_w$再加上舍弃掉的值，即：</p>
<script type="math/tex; mode=display">
H_{out} = H - k_h + 1</script><script type="math/tex; mode=display">
W_{out} = W - k_w + 1</script><p>我们可以使用一个式子来表示输出值$Y$，其中，$W$和$b$都是我们需要学习的参数：</p>
<script type="math/tex; mode=display">
Y = X·W + b</script><p>因为我们需要足够的空间在图像上“移动”卷积核。稍后，我们将看到如何通过<strong>在图像边界周围填充零</strong>来保证有足够的空间移动卷积核，从而保持输出大小不变。</p>
<p><strong>实现卷积运算</strong></p>
<p>接下来，我们在<code>corr2d</code>函数中实现如上过程，该函数接受输入张量<code>X</code>和卷积核张量<code>K</code>，并返回输出张量<code>Y</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">X = paddle.to_tensor([[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]])</span><br><span class="line">K = paddle.to_tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d</span>(<span class="params">X, K</span>):</span><br><span class="line">    h, w = K.shape</span><br><span class="line">    <span class="comment"># 根据上面公式计算输出的h和w</span></span><br><span class="line">    Y = paddle.zeros(shape=(X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i+h, j:j+w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(corr2d(X, K))</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[25., 31.],
        [43., 49.]])
</code></pre><h3 id="2）填充"><a href="#2）填充" class="headerlink" title="2）填充"></a><strong>2）填充</strong></h3><p>在上面的例子中，输入图片尺寸为$3\times3$，输出图片尺寸为$2\times2$，经过一次卷积之后，图片尺寸变小。卷积输出特征图的尺寸计算方法如下（卷积核的高和宽分别为$k_h$和$k_w$）：</p>
<script type="math/tex; mode=display">
H_{out} = H - k_h + 1</script><script type="math/tex; mode=display">
W_{out} = W - k_w + 1</script><p>如果输入尺寸为4，卷积核大小为3时，输出尺寸为$4-3+1=2$。当卷积核尺寸大于1时，输出特征图的尺寸会小于输入图片尺寸。如果经过多次卷积，输出图片尺寸会不断减小。为了避免卷积之后图片尺寸变小，通常会在图片的外围进行<strong>填充(padding)</strong>：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/01d311ec2c65435f85059953a84ec7ea8ef2fd236452450e912346a7da201c5f" width = "700"></center>
<center><br>图8：图形填充 </br></center>

<ul>
<li><p>如图8（a）所示：填充的大小为1，填充值为0。填充之后，输入图片尺寸从$4\times4$变成了$6\times6$，使用$3\times3$的卷积核，输出图片尺寸为$4\times4$。</p>
</li>
<li><p>如图8（b）所示：填充的大小为2，填充值为0。填充之后，输入图片尺寸从$4\times4$变成了$8\times8$，使用$3\times3$的卷积核，输出图片尺寸为$6\times6$。</p>
</li>
</ul>
<p>如果在图片高度方向，在第一行之前填充$p_{h1}$行，在最后一行之后填充$p_{h2}$行；在图片的宽度方向，在第1列之前填充$p_{w1}$列，在最后1列之后填充$p_{w2}$列；则填充之后的图片尺寸为$(H + p_{h1} + p_{h2})\times(W + p_{w1} + p_{w2})$。经过大小为$k_h\times k_w$的卷积核操作之后，输出图片的尺寸为：</p>
<script type="math/tex; mode=display">
H_{out} = H + p_{h1} + p_{h2} - k_h + 1</script><script type="math/tex; mode=display">
W_{out} = W + p_{w1} + p_{w2} - k_w + 1</script><p>在卷积计算过程中，通常会在高度或者宽度的两侧采取等量填充，即$p_{h1} = p_{h2} = p_h,\ \ p_{w1} = p_{w2} = p_w$，上面计算公式也就变为：</p>
<script type="math/tex; mode=display">
H_{out} = H + 2p_h - k_h + 1</script><script type="math/tex; mode=display">
W_{out} = W + 2p_w - k_w + 1</script><p>卷积核大小通常使用<code>1，3，5，7</code>这样的奇数，如果使用的填充大小为$p_h=(k_h-1)/2 ，p_w=(k_w-1)/2$，则卷积之后图像尺寸不变。例如当<code>卷积核大小为3时，padding大小为1</code>，卷积之后图像尺寸不变；同理，如果<code>卷积核大小为5，padding大小为2</code>，也能保持图像尺寸不变。</p>
<p>比如，在下面的例子中，我们创建一个高度和宽度为3的二维卷积层，并在所有侧边填充1个像素。给定高度和宽度为8的输入，则输出的高度和宽度也是8。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span><br><span class="line">    <span class="comment"># 这里的（1，1）表示批量大小和通道数都是1，X为（批量大小，通道数，高度，宽度）</span></span><br><span class="line">    X = X.reshape([<span class="number">1</span>, <span class="number">1</span>] + X.shape)</span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="built_in">print</span>(Y.shape)</span><br><span class="line">    <span class="keyword">return</span> Y.reshape(Y.shape[<span class="number">2</span>:]) <span class="comment"># 省略前两个维度：批量大小和通道</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;填充&#x27;&#x27;&#x27;</span></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment"># 这里每边都填充了1行或1列，因此总共添加了2行或2列</span></span><br><span class="line">X = paddle.rand(shape=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, 4, 4]
[4, 4]
</code></pre><p>当卷积核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">3</span>), padding=(<span class="number">2</span>, <span class="number">1</span>)) <span class="comment">#ph = kh-1</span></span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, 4, 4]
[4, 4]
</code></pre><h3 id="3）步幅"><a href="#3）步幅" class="headerlink" title="3）步幅"></a><strong>3）步幅</strong></h3><p><strong>图8</strong> 中卷积核每次滑动一个像素点，这是<strong>步幅（stride）</strong> 为1的特殊情况。<strong>图9</strong> 是步幅为2的卷积过程，卷积核在图片上移动时，每次移动大小为2个像素点。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/afdae9af02fc45eabdd9663ee6474e4da86675fa1f444c78aea0e21539b32cf0" width = "800"></center>
<center><br>图9：步幅为2的卷积过程 </br></center>

<p>当宽和高方向的步幅分别为$s_h$和$s_w$时，输出特征图尺寸的计算公式是：</p>
<script type="math/tex; mode=display">
H_{out} = \frac{H + 2p_h - k_h}{s_h} + 1</script><script type="math/tex; mode=display">
W_{out} = \frac{W + 2p_w - k_w}{s_w} + 1</script><p>假设输入图片尺寸是$H\times W = 100 \times 100$，卷积核大小$k_h \times k_w = 3 \times 3$，填充$p_h = p_w = 1$，步幅为$s_h = s_w = 2$，则输出特征图的尺寸为：</p>
<script type="math/tex; mode=display">
H_{out} = \frac{100 + 2 - 3}{2} + 1 = 50</script><script type="math/tex; mode=display">
W_{out} = \frac{100 + 2 - 3}{2} + 1 = 50</script><p>下面，我将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;步幅&#x27;&#x27;&#x27;</span></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, 2, 2]
[2, 2]
</code></pre><p>接下来，看一个稍微复杂的例子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = paddle.rand(shape=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># [(4+0-3)/3]+1		[(4+2-5)/4]+1</span></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">5</span>), padding=(<span class="number">0</span>, <span class="number">1</span>), stride=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, 1, 1]
[1, 1]
</code></pre><h3 id="4）感受野"><a href="#4）感受野" class="headerlink" title="4）感受野"></a><strong>4）感受野</strong></h3><p>输出特征图上每个点的数值，是由输入图片上大小为$k_h\times k_w$的区域的元素与卷积核每个元素相乘再相加得到的，所以输入图像上$k_h\times k_w$区域内每个元素数值的改变，都会影响输出点的像素值。我们将这个区域叫做输出特征图上对应点的<strong>感受野（Receptive Field）</strong>。感受野内每个元素数值的变动，都会影响输出点的数值变化。比如$3\times3$卷积对应的感受野大小就是$3\times3$，如 <strong>图10</strong> 所示。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/1021536721524f4d8f4c1aefa89693c4b0fd388f21a347b583d413b3ac41241b" width = "800"></center>
<center><br>图10：感受野为3×3的卷积 </br></center>

<p>而当通过两层$3\times3$的卷积之后，感受野的大小将会增加到$5\times5$，如 <strong>图11</strong> 所示。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/ac14916db81e40a48a25ab894d7a95e33fa0eece71d44a55af7bffab462fb7a7" width = "800"></center>
<center><br>图11：感受野为5×5的卷积 </br></center>

<p>因此，当增加卷积网络深度的同时，感受野将会增大，输出特征图中的一个像素点将会包含更多的图像语义信息。</p>
<h3 id="5）多输入通道、多输出通道"><a href="#5）多输入通道、多输出通道" class="headerlink" title="5）多输入通道、多输出通道"></a>5）多输入通道、多输出通道</h3><p>前面介绍的卷积计算过程比较简单，实际应用时，处理的问题要复杂的多。例如：对于彩色图片有RGB三个通道，需要处理多输入通道的场景。输出特征图往往也会具有多个通道，而且在神经网络的计算中常常是把一个批次的样本放在一起计算，所以卷积算子需要具有批量处理多输入和多输出通道数据的功能，下面将分别介绍这几种场景的操作方式。</p>
<p><strong>多输入通道场景</strong></p>
<p>上面的例子中，卷积层的数据是一个2维数组，但实际上一张图片往往含有RGB三个通道，要计算卷积的输出结果，卷积核的形式也会发生变化。假设输入图片的通道数为$C_{in}$，输入数据的形状是$C_{in}\times{H_{in}}\times{W_{in}}$，计算过程如 <strong>图12</strong> 所示。</p>
<ol>
<li><p>对每个通道分别设计一个2维数组作为卷积核，卷积核数组的形状是$C_{in}\times{k_h}\times{k_w}$。</p>
</li>
<li><p>对任一通道$C_{in} \in [0, C_{in})$，分别用大小为$k_h\times{k_w}$的卷积核在大小为$H_{in}\times{W_{in}}$的二维数组上做卷积。</p>
</li>
<li><p>将这$C_{in}$个通道的计算结果相加，得到的是一个形状为$H_{out}\times{W_{out}}$的二维数组。</p>
</li>
</ol>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/92186667b8424a7ca781b22de6766fa62e31512cf2e24e33a4b796541177c9dd" width = "800"></center>
<center><br>图12：多输入通道计算过程 </br></center>

<p>为了加深理解，我们实现一下多输入通道互相关运算。简而言之，我们所做的就是对每个通道执行互相关操作，然后将结果相加。</p>
<hr>
<blockquote>
<p>说明：</p>
<p><code>zip()</code>函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。</p>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in</span>(<span class="params">X, K</span>): </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> <span class="built_in">zip</span>(X, K)) </span><br><span class="line"></span><br><span class="line">X = paddle.to_tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]],</span><br><span class="line">               [[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]]])</span><br><span class="line"></span><br><span class="line">K = paddle.to_tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]], [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]]])</span><br><span class="line"></span><br><span class="line">corr2d_multi_in(X, K)</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[56. , 72. ],
        [104., 120.]])
</code></pre><p><strong>多输出通道场景</strong></p>
<p>一般来说，卷积操作的输出特征图也会具有多个通道$C_{out}$，这时我们需要设计$C_{out}$个维度为$C_{in}\times{k_h}\times{k_w}$的卷积核，卷积核数组的维度是$C_{out}\times C_{in}\times{k_h}\times{k_w}$，如 <strong>图13</strong> 所示。</p>
<ol>
<li>对任一输出通道$c_{out} \in [0, C_{out})$，分别使用上面描述的形状为$C_{in}\times{k_h}\times{k_w}$的卷积核对输入图片做卷积。</li>
<li>将这$C_{out}$个形状为$H_{out}\times{W_{out}}$的二维数组拼接在一起，形成维度为$C_{out}\times{H_{out}}\times{W_{out}}$的三维数组。</li>
</ol>
<hr>
<blockquote>
<p><strong>说明：</strong></p>
<p>通常将卷积核的输出通道数叫做卷积核的个数。</p>
<p>一组输入一个输出</p>
</blockquote>
<hr>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/cf1fbddc141349e4b7aaeade9a201b78a16d249e069c4f8aaeb77e0ea1a95c31" width = "800"></center>
<center><br>图13：多输出通道计算过程 </br></center>

<p>如下所示，我们实现一个计算多个通道的输出的互相关函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="keyword">return</span> paddle.stack([corr2d_multi_in(X, k) <span class="keyword">for</span> k <span class="keyword">in</span> K], <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># paddle.stack 最后将所有结果都叠加在一起</span></span><br><span class="line">    <span class="comment"># 输入 x 为 N 个 Shape 为 [A, B]的 Tensor, 如果 axis = 0 , 则输出 Tensor 的 Shape 为 [N, A, B]</span></span><br><span class="line"></span><br><span class="line">K = paddle.to_tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]], [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]]])</span><br><span class="line">K = paddle.stack((K, K + <span class="number">1</span>, K + <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;(C_out,C_in,k_h,k_w)：&#x27;</span>, K.shape)</span><br><span class="line"></span><br><span class="line">corr2d_multi_in_out(X, K)</span><br></pre></td></tr></table></figure>
<pre><code>(C_out,C_in,k_h,k_w)： [3, 2, 2, 2]
Tensor(shape=[3, 2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[56. , 72. ],
         [104., 120.]],

        [[76. , 100.],
         [148., 172.]],

        [[96. , 128.],
         [192., 224.]]])
</code></pre><p><strong>批量操作</strong></p>
<p>在卷积神经网络的计算中，通常将多个样本放在一起形成一个mini-batch进行批量操作，即输入数据的维度是$N\times{C_{in}}\times{H_{in}}\times{W_{in}}$。由于会对每张图片使用同样的卷积核进行卷积操作，卷积核的维度与上面多输出通道的情况一样，仍然是$C_{out}\times C_{in}\times{k_h}\times{k_w}$，输出特征图的维度是$N\times{C_{out}}\times{H_{out}}\times{W_{out}}$，如 <strong>图14</strong> 所示。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/60760d68001c40d6a6c500b17f57d8deae7b5921631b4b6b896b057b904d24b1" width = "800"></center>
<center><br>图14：批量操作 </br></center>

<h3 id="6）1-times-1-卷积层"><a href="#6）1-times-1-卷积层" class="headerlink" title="6）1 $\times$ 1 卷积层"></a><strong>6）1 $\times$ 1 卷积层</strong></h3><p>因为使用了最小窗口，$1\times 1$卷积失去了卷积层的特有能力，即在高度和宽度维度上，识别相邻元素间相互作用的能力。其实$1\times 1$卷积的作用在于：它不识别空间模式，只是融合通道。下图展示了使用$1\times 1$卷积核与$3$个输入通道和$2$个输出通道的互相关计算：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/1b206e97ea5f4e3aabbd335848830262280ee32c91cd4b5e8bad5b8b0f9ed8d4" width = "450"></center>
<center><br>图15：1×1卷积 </br></center>

<blockquote>
<p>通道融合：将三个通道的数×卷积并相加在了一起。</p>
</blockquote>
<p>这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。我们可以将$1\times 1$卷积层看作是在每个像素位置应用的全连接层，以$c_i$个输入值转换为$c_o$个输出值。因为这仍然是一个卷积层，所以跨像素的权重是一致的。我们可以简单的认为，这样的目的更多的是为了实现通道的线性变换，重新排列组合为更好的特征基底。</p>
<p>下面，我们使用全连接层和互相关函数分别实现$1 \times 1$卷积。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;1 x 1 的卷积层&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out_1x1</span>(<span class="params">X, K</span>):</span><br><span class="line">    c_i, h, w = X.shape</span><br><span class="line">    c_o = K.shape[<span class="number">0</span>]</span><br><span class="line">    X = X.reshape((c_i, h * w))</span><br><span class="line">    K = K.reshape((c_o, c_i))</span><br><span class="line">    Y = paddle.matmul(K, X) <span class="comment"># matmul 矩阵乘法</span></span><br><span class="line">    <span class="keyword">return</span> Y.reshape((c_o, h, w))</span><br><span class="line"></span><br><span class="line">X = paddle.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)) <span class="comment">#（输入，h*w）</span></span><br><span class="line">K = paddle.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># （输出，输入，1*1）</span></span><br><span class="line"></span><br><span class="line">Y1 = corr2d_multi_in_out_1x1(X, K)</span><br><span class="line">Y2 = corr2d_multi_in_out(X, K)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">float</span>(paddle.<span class="built_in">abs</span>(Y1 - Y2).<span class="built_in">sum</span>()) &lt; <span class="number">1e-6</span> <span class="comment"># 由于浮点数精度的区别，几乎认为Y1=Y2，也就是全连接与1*1互相关运算的结果相同。</span></span><br><span class="line">paddle.<span class="built_in">abs</span>(Y1 - Y2).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1], dtype=float32, place=Place(cpu), stop_gradient=True,
       [0.00000015])
</code></pre><h2 id="四、飞桨卷积API介绍"><a href="#四、飞桨卷积API介绍" class="headerlink" title="四、飞桨卷积API介绍"></a>四、飞桨卷积API介绍</h2><p>飞桨卷积算子对应的API是 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Conv2D_cn.html">paddle.nn.Conv2D</a>，用户可以直接调用API进行计算，也可以在此基础上修改。Conv2D名称中的“2D”表明卷积核是二维的，多用于处理图像数据。类似的，也有Conv3D可以用于处理视频数据（图像的序列）。</p>
<blockquote>
<p><em>class</em> paddle.nn.Conv2D(<em>in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode=’zeros’, weight_attr=None, bias_attr=None, data_format=’NCHW’</em>)</p>
</blockquote>
<p>常用的参数如下：</p>
<ul>
<li><code>in_channels(int)</code> - 输入图像的通道数。</li>
<li><code>out_channels(int)</code> - 卷积核的个数，和输出特征图通道数相同，相当于上文中的$C_{out}$。</li>
<li><code>kernel_size(int|list|tuple)</code> - 卷积核大小，可以是整数，比如3，表示卷积核的高和宽均为3 ；或者是两个整数的list，例如[3,2]，表示卷积核的高为3，宽为2。</li>
<li><code>stride(int|list|tuple，可选)</code> - 步长大小，可以是整数，默认值为1，表示垂直和水平滑动步幅均为1；或者是两个整数的list，例如[3,2]，表示垂直滑动步幅为3，水平滑动步幅为2。</li>
<li><code>padding(int|list|tuple|str，可选)</code> - 填充大小，可以是整数，比如1，表示竖直和水平边界填充大小均为1；或者是两个整数的list，例如[2,1]，表示竖直边界填充大小为2，水平边界填充大小为1。</li>
</ul>
<hr>
<blockquote>
<p><strong>强调</strong>：</p>
<ul>
<li>输入数据维度：$[N, C_{in}, H_{in}, W_{in}]$     【图片数,输入通道数,图片的高,图片的宽】</li>
<li>输出数据维度：$[N, out_channels, H_{out}, W_{out}]$     【批量维：生成的特征组数，输出通道数(可以调整)】</li>
<li>权重参数$w$的维度：$[out_channels, C_{in}, filter_size_h, filter_size_w]$</li>
<li>偏置参数$b$的维度是：$[out_channels]$</li>
</ul>
<p>注意，<strong>即使输入只有一张灰度图片$[H_{in}, W_{in}]$，也需要处理成四个维度的输入向量$[1, 1, H_{in}, W_{in}]$</strong>。</p>
</blockquote>
<hr>
<h3 id="卷积算子应用举例"><a href="#卷积算子应用举例" class="headerlink" title="卷积算子应用举例"></a><strong>卷积算子应用举例</strong></h3><p>下面介绍卷积算子在图片中应用的三个案例，并观察其计算结果。</p>
<h5 id="案例1——简单的黑白边界检测"><a href="#案例1——简单的黑白边界检测" class="headerlink" title="案例1——简单的黑白边界检测"></a>案例1——简单的黑白边界检测</h5><p>下面是使用Conv2D算子完成一个图像边界检测的任务。图像左边为光亮部分，右边为黑暗部分，需要检测出光亮跟黑暗的分界处。</p>
<p>设置宽度方向的卷积核为$[1, 0, -1]$，此卷积核会将宽度方向间隔为1的两个像素点的数值相减。当卷积核在图片上滑动时，如果它所覆盖的像素点位于亮度相同的区域，则左右间隔为1的两个像素点数值的差为0。只有当卷积核覆盖的像素点有的处于光亮区域，有的处在黑暗区域时，左右间隔为1的两个点像素值的差才不为0。将此卷积核作用到图片上，输出特征图上只有对应黑白分界线的地方像素值才不为0。具体代码如下所示，结果输出在下方的图案中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> paddle.nn.initializer <span class="keyword">import</span> Assign</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建输入图片，图片左边的像素点取值为1，右边的像素点取值为0</span></span><br><span class="line">img = np.ones([<span class="number">50</span>, <span class="number">50</span>], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">img[:, <span class="number">30</span>:] = <span class="number">0.</span></span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图片形状调整为[N, C, H, W]的形式</span></span><br><span class="line">x = img.reshape([<span class="number">1</span>, <span class="number">1</span>, <span class="number">50</span>, <span class="number">50</span>])</span><br><span class="line">x = paddle.to_tensor(x)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/深度学习/45.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建初始化权重参数w</span></span><br><span class="line">w = np.array([<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># 将权重参数调整成维度为[cout, cin, kh, kw]的四维张量</span></span><br><span class="line">w = w.reshape([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建卷积算子，设置输出通道数，卷积核大小，和初始化权重参数，通过参数属性weight_attr指定参数初始化方式（默认Xavier）</span></span><br><span class="line">conv = Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=[<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       weight_attr=paddle.ParamAttr(initializer=Assign(value=w)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用卷积算子作用在输入图片上</span></span><br><span class="line">y = conv(x)</span><br><span class="line"><span class="comment"># 将输出tensor转化为numpy.ndarray</span></span><br><span class="line">out = y.numpy()</span><br></pre></td></tr></table></figure>
<p>卷积算子Conv2D输出数据形状为<code>[N, C, H, W]</code>形式，此处输出数据形状为<code>[1, 1, H, W]</code>，是 4 维数组，但是画图函数<code>plt.imshow</code>画灰度图时，只接受 2 维数组。通过 <code>numpy.squeeze</code> 函数将大小为1的维度消除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制子图</span></span><br><span class="line">f = plt.subplot(<span class="number">121</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;input image&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">f = plt.subplot(<span class="number">122</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;output featuremap&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(out.squeeze(), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/深度学习/46.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看卷积层的权重参数名字和数值</span></span><br><span class="line"><span class="built_in">print</span>(conv.weight)</span><br><span class="line"><span class="comment"># 参看卷积层的偏置参数名字和数值</span></span><br><span class="line"><span class="built_in">print</span>(conv.bias)</span><br></pre></td></tr></table></figure>
<pre><code>Parameter containing:
Tensor(shape=[1, 1, 1, 3], dtype=float32, place=Place(cpu), stop_gradient=False,
       [[[[ 1.,  0., -1.]]]])
Parameter containing:
Tensor(shape=[1], dtype=float32, place=Place(cpu), stop_gradient=False,
       [0.])
</code></pre><h5 id="案例2——图像中物体边缘检测"><a href="#案例2——图像中物体边缘检测" class="headerlink" title="案例2——图像中物体边缘检测"></a>案例2——图像中物体边缘检测</h5><p>上面展示的是一个人为构造出来的简单图片，使用卷积网络检测图片明暗分界处的示例。</p>
<p>对于真实的图片，也可以使用合适的卷积核（$3X3$卷积核的中间值是 $8$ ，周围一圈的值是 $-1$ ）对其进行操作，用来检测物体的外形轮廓，观察输出特征图跟原图之间的对应关系，如下代码所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> paddle.nn.initializer <span class="keyword">import</span> Assign</span><br><span class="line"></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;work/1.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 将读入的图片转化为float32类型的numpy.ndarray</span></span><br><span class="line">x = np.array(img).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)	<span class="comment"># (672,960,3)</span></span><br><span class="line"><span class="comment"># 图片读入成ndarry时，形状是[H, W, 3]，将通道这一维度调整到最前面</span></span><br><span class="line">x = np.transpose(x, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(x.shape)	<span class="comment"># (3,672,960)</span></span><br><span class="line"><span class="comment"># 将数据形状调整为[N, C, H, W]格式</span></span><br><span class="line">x = x.reshape(<span class="number">1</span>, <span class="number">3</span>, img.height, img.width)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line"><span class="built_in">print</span>(x.shape)	 [<span class="number">1</span>, <span class="number">3</span>, <span class="number">672</span>, <span class="number">960</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置卷积核参数</span></span><br><span class="line"><span class="comment"># 下面除以8的原因是向对卷积核的数值进行算放，表示成分数</span></span><br><span class="line">w = np.array([[-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>], [-<span class="number">1</span>,<span class="number">8</span>,-<span class="number">1</span>], [-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>]], dtype=<span class="string">&#x27;float32&#x27;</span>)/<span class="number">8</span></span><br><span class="line">w = w.reshape([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 由于输入通道数是3，将卷积核的形状从[1,1,3,3]通过repeat方式调整为[1,3,3,3]</span></span><br><span class="line">w = np.repeat(w, <span class="number">3</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 创建卷积算子，输出通道数为1，卷积核大小为3x3，并使用上面的设置好的数值作为卷积核权重的初始化参数</span></span><br><span class="line">conv = Conv2D(in_channels=<span class="number">3</span>, out_channels=<span class="number">1</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], </span><br><span class="line">            weight_attr=paddle.ParamAttr(initializer=Assign(value=w)))</span><br><span class="line"></span><br><span class="line">y = conv(x)</span><br><span class="line">out = y.numpy()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制子图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</span><br><span class="line">f = plt.subplot(<span class="number">121</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;input image&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"></span><br><span class="line">f = plt.subplot(<span class="number">122</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;output feature map&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(out.squeeze(), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/深度学习/47.png" alt="png"></p>
<h5 id="案例3——图像均值模糊"><a href="#案例3——图像均值模糊" class="headerlink" title="案例3——图像均值模糊"></a>案例3——图像均值模糊</h5><p>另外一种比较常见的卷积核（$5X5$的卷积核中每个值均为$1$）是用当前像素跟它邻域内的像素取平均，这样可以能够有效的抑制噪声，平滑图像（高斯滤波），如下代码所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> paddle.nn.initializer <span class="keyword">import</span> Assign</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入图片并转成numpy.ndarray</span></span><br><span class="line"><span class="comment"># 换成灰度图</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;work/2.jpg&#x27;</span>).convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">img = np.array(img)</span><br><span class="line">x = img.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = x.reshape(<span class="number">1</span>, <span class="number">1</span>, img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>])</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1, 1, 720, 1280], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[[191., 195., 195., ..., 185., 184., 184.],
          [189., 193., 194., ..., 185., 186., 186.],
          [191., 195., 195., ..., 185., 186., 186.],
          ...,
          [184., 183., 181., ..., 210., 209., 216.],
          [178., 179., 179., ..., 208., 208., 213.],
          [171., 172., 174., ..., 211., 210., 210.]]]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建初始化参数</span></span><br><span class="line">w = np.ones([<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>], dtype = <span class="string">&#x27;float32&#x27;</span>)/<span class="number">25</span></span><br><span class="line">conv = Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], </span><br><span class="line">        weight_attr=paddle.ParamAttr(initializer=Assign(value=w)))</span><br><span class="line"></span><br><span class="line">y = conv(x)</span><br><span class="line">out = y.numpy()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">f = plt.subplot(<span class="number">121</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;input image&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">f = plt.subplot(<span class="number">122</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;output feature map&#x27;</span>)</span><br><span class="line">out = out.squeeze()	<span class="comment"># 剔除掉前面的两个维度，得到二维的数据</span></span><br><span class="line">plt.imshow(out, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/深度学习/48.png" alt="png"></p>
<h2 id="五、池化（Pooling）"><a href="#五、池化（Pooling）" class="headerlink" title="五、池化（Pooling）"></a>五、池化（Pooling）</h2><p>​    池化是使用某一位置的相邻输出的总体统计特征代替网络在该位置的输出，其好处是当输入数据做出少量平移时，经过池化函数后的大多数输出还能保持不变。比如：当识别一张图像是否是人脸时，我们需要知道人脸左边有一只眼睛，右边也有一只眼睛，而不需要知道眼睛的精确位置，这时候通过池化某一片区域的像素点来得到总体统计特征会显得很有用。</p>
<p>​    使用池化层，使得图像压缩时去掉一些无关紧要的信息，而留下的信息则是具有<strong>尺度不变性</strong>的特征，是最能表达图像的特征。由于池化之后特征图会变得更小，如果后面连接的是全连接层，能有效的减小神经元的个数，节省存储空间并提高计算效率。</p>
<p>​    总结来说，池化层的主要目的是：<code>降低卷积层对位置的敏感性</code>。</p>
<h3 id="5-1-平均池化与最大池化"><a href="#5-1-平均池化与最大池化" class="headerlink" title="5.1 平均池化与最大池化"></a>5.1 平均池化与最大池化</h3><p>如 <strong>图15</strong> 所示，将一个$2\times 2$的区域<strong>池化（Pooling）</strong> 成一个像素点。</p>
<p>不同于卷积层中的输入与卷积核之间的互相关计算，池化层不包含参数。 相反，池运算是确定性的，我们通常计算池化窗口中所有元素的最大值或平均值。这些操作分别称为最大池化（maximum pooling）和平均池化（average pooling）。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/5479daa3734d424bb710615d3c4f7e017ba2558808a8421ca7c914f3fced0a48" width = "600"></center>
<center><br>图15：池化 </br></center>

<ul>
<li>如图15（a）：平均池化。这里使用大小为$2\times2$的池化窗口，每次移动的步幅为2，对池化窗口覆盖区域内的像素取平均值，得到相应的输出特征图的像素值。</li>
<li>如图15（b）：最大池化。对池化窗口覆盖区域内的像素取最大值，得到输出特征图的像素值。当池化窗口在图片上滑动时，会得到整张输出特征图。池化窗口的大小称为池化大小，用$k_h \times k_w$表示。在卷积神经网络中用的比较多的是窗口大小为$2 \times 2$，步幅为2的池化。</li>
</ul>
<p>与卷积核类似，池化窗口在图片上滑动时，每次移动的步长称为步幅，当宽和高方向的移动大小不一样时，分别用$s_w$和$s_h$表示。也可以对需要进行池化的图片进行填充，填充方式与卷积类似，假设在第一行之前填充$p_{h1}$行，在最后一行后面填充$p_{h2}$行。在第一列之前填充$p_{w1}$列，在最后一列之后填充$p_{w2}$列，则池化层的输出特征图大小为：</p>
<script type="math/tex; mode=display">
H_{out} = \frac{H + p_{h1} + p_{h2} - k_h}{s_h} + 1</script><script type="math/tex; mode=display">
W_{out} = \frac{W + p_{w1} + p_{w2} - k_w}{s_w} + 1</script><p>在卷积神经网络中，通常使用$2\times2$大小的池化窗口，步幅也使用2，填充为0，则输出特征图的尺寸为：</p>
<script type="math/tex; mode=display">
H_{out} = \frac{H}{2}</script><script type="math/tex; mode=display">
W_{out} = \frac{W}{2}</script><p>通过这种方式的池化，输出特征图的高和宽都减半，但通道数不会改变。</p>
<p>在下面的代码中的<code>pool2d</code>函数，我们实现池化层的前向传播。这类似于之前中的<code>corr2d</code>函数。然而，这里我们没有卷积核，输出为输入中每个区域的最大值或平均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">X = paddle.to_tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line"><span class="built_in">print</span>(X, X.shape)	<span class="comment"># [3,3]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># X为需要池化的输入数据</span></span><br><span class="line">    <span class="comment"># pool_size为池化的大小</span></span><br><span class="line">    <span class="comment"># mode表示是以最大池化还是均值池化</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    <span class="comment"># 计算Y的形状</span></span><br><span class="line">    Y = paddle.zeros(shape=(X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 下面计算数值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="comment"># 下面移动的步长都为1</span></span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="built_in">print</span>(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>), <span class="string">&#x27;avg&#x27;</span>))</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[3, 3], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]) [3, 3]
Tensor(shape=[2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[4., 5.],
        [7., 8.]])
Tensor(shape=[2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[2., 3.],
        [5., 6.]])
</code></pre><h3 id="5-2-填充和步幅"><a href="#5-2-填充和步幅" class="headerlink" title="5.2 填充和步幅"></a>5.2 填充和步幅</h3><p>与卷积层一样，池化层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。</p>
<p>下面，我们用深度学习框架中内置的二维最大池化层，来演示池化层中填充和步幅的使用。我们首先构造了一个输入张量$X$，它有四个维度，其中样本数和通道数都是1。</p>
<p><code>paddle.nn.MaxPool2D(kernel_size, stride=None, padding=0)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = paddle.arange(<span class="number">16</span>, dtype=paddle.float32).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">X</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1, 1, 4, 4], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[[0. , 1. , 2. , 3. ],
          [4. , 5. , 6. , 7. ],
          [8. , 9. , 10., 11.],
          [12., 13., 14., 15.]]]])
</code></pre><p>默认情况下，深度学习框架中的步幅与池化窗口的大小相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pool2d = nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 这里是2×2的池化窗口，步长为2，最大池化</span></span><br><span class="line">pool2d(X)</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1, 1, 2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[[5. , 7. ],
          [13., 15.]]]])
</code></pre><p>当然，我们可以设定一个任意大小的矩形池化窗口，并分别设定填充和步幅的高度和宽度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pool2d = nn.MaxPool2D((<span class="number">2</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">3</span>), padding=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 这里2×3的池化窗口，高度2步长宽度3步长，高度方向不填充，宽度方向上左右各填充一列</span></span><br><span class="line">pool2d(X)</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1, 1, 2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[[5. , 7. ],
          [13., 15.]]]])
</code></pre><h3 id="5-3-多个通道"><a href="#5-3-多个通道" class="headerlink" title="5.3 多个通道"></a>5.3 多个通道</h3><p>在处理多通道输入数据时，池化层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总。这意味着<strong>池化层的输出通道数与输入通道数相同</strong>。</p>
<p>下面，我们将在通道维度上连结张量$X$和$X + 1$，以构建具有 2 个通道的输入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = paddle.concat((X, X + <span class="number">1</span>), <span class="number">1</span>)X</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1, 2, 4, 4], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[[0. , 1. , 2. , 3. ],
          [4. , 5. , 6. , 7. ],
          [8. , 9. , 10., 11.],
          [12., 13., 14., 15.]],

         [[1. , 2. , 3. , 4. ],
          [5. , 6. , 7. , 8. ],
          [9. , 10., 11., 12.],
          [13., 14., 15. 16.]]]])
</code></pre><p>如下所示，池化后输出通道的数量仍然是2。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pool2d = nn.MaxPool2D(<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">pool2d(X)</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[1, 2, 2, 2], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[[[5. , 7. ],
          [13., 15.]],

         [[6. , 8. ],
          [14., 16.]]]])
</code></pre><h2 id="六、批归一化（Batch-Normalization）"><a href="#六、批归一化（Batch-Normalization）" class="headerlink" title="六、批归一化（Batch Normalization）"></a>六、批归一化（Batch Normalization）</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">批归一化方法</a>（Batch Normalization，BatchNorm）是由Ioffe和Szegedy于2015年提出的，已被广泛应用在深度学习中，其目的是对神经网络中间层的输出进行标准化处理，使得中间层的输出更加稳定。</p>
<p>通常我们会对神经网络的数据进行标准化处理，处理后的样本数据集满足均值为0，方差为1的统计分布，这是因为当输入数据的分布比较固定时，有利于算法的稳定和收敛。对于深度神经网络来说，由于参数是不断更新的，即使输入数据已经做过标准化处理，但是对于比较靠后的那些层，其接收到的输入仍然是剧烈变化的，通常会导致数值不稳定，模型很难收敛。BatchNorm能够使神经网络中间层的输出变得更加稳定，并有如下三个优点：</p>
<ul>
<li><p>使学习快速进行（能够使用较大的学习率）</p>
</li>
<li><p>降低模型对初始值的敏感性</p>
</li>
<li><p>从一定程度上抑制过拟合</p>
</li>
</ul>
<p>BatchNorm主要思路是在训练时以mini-batch为单位，对神经元的数值进行归一化，使数据的分布满足均值为0，方差为1。具体计算过程如下：</p>
<p><strong>1. 计算mini-batch内样本的均值</strong></p>
<script type="math/tex; mode=display">
\mu_B \leftarrow \frac{1}{m}\sum_{i=1}^mx^{(i)}</script><p>其中$x^{(i)}$表示mini-batch中的第$i$个样本。</p>
<p>例如输入mini-batch包含3个样本，每个样本有2个特征，分别是：</p>
<script type="math/tex; mode=display">
x^{(1)} = (1,2), \ \ x^{(2)} = (3,6), \ \ x^{(3)} = (5,10)</script><p>对每个特征分别计算mini-batch内样本的均值：</p>
<script type="math/tex; mode=display">
\mu_{B0} = \frac{1+3+5}{3} = 3, \ \ \ \mu_{B1} = \frac{2+6+10}{3} = 6</script><p>则样本均值是:</p>
<script type="math/tex; mode=display">
\mu_{B} = (\mu_{B0}, \mu_{B1}) = (3, 6)</script><p><strong>2. 计算mini-batch内样本的方差</strong></p>
<script type="math/tex; mode=display">
\sigma_B^2 \leftarrow \frac{1}{m}\sum_{i=1}^m(x^{(i)} - \mu_B)^2</script><p>上面的计算公式先计算一个批次内样本的均值$\mu_B$和方差$\sigma_B^2$，然后再对输入数据做归一化，将其调整成均值为0，方差为1的分布。</p>
<p>对于上述给定的输入数据$x^{(1)}, x^{(2)}, x^{(3)}$，可以计算出每个特征对应的方差：</p>
<script type="math/tex; mode=display">
\sigma_{B0}^2 = \frac{1}{3} \cdot ((1-3)^2 + (3-3)^2 + (5-3)^2) = \frac{8}{3}</script><script type="math/tex; mode=display">
\sigma_{B1}^2 = \frac{1}{3} \cdot ((2-6)^2 + (6-6)^2 + (10-6)^2) = \frac{32}{3}</script><p>则样本方差是：</p>
<script type="math/tex; mode=display">
\sigma_{B}^2 = (\sigma_{B0}^2, \sigma_{B1}^2) = (\frac{8}{3}, \frac{32}{3})</script><p><strong>3. 计算标准化之后的输出</strong></p>
<script type="math/tex; mode=display">
\hat{x}^{(i)} \leftarrow \frac{x^{(i)} - \mu_B}{\sqrt{(\sigma_B^2 + \epsilon)}}</script><p>其中$\epsilon$是一个微小值（例如$1e-7$），其主要作用是为了防止分母为0。</p>
<p>对于上述给定的输入数据$x^{(1)}, x^{(2)}, x^{(3)}$，可以计算出标准化之后的输出：</p>
<script type="math/tex; mode=display">
\hat{x}^{(1)} = (\frac{1 - 3}{\sqrt{\frac{8}{3}}}, \ \ \frac{2 - 6}{\sqrt{\frac{32}{3}}}) = (-\sqrt{\frac{3}{2}}, \ \ -\sqrt{\frac{3}{2}})</script><script type="math/tex; mode=display">
\hat{x}^{(2)} = (\frac{3 - 3}{\sqrt{\frac{8}{3}}}, \ \ \frac{6 - 6}{\sqrt{\frac{32}{3}}}) = (0, \ \ 0) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \</script><script type="math/tex; mode=display">
\hat{x}^{(3)} = (\frac{5 - 3}{\sqrt{\frac{8}{3}}}, \ \ \frac{10 - 6}{\sqrt{\frac{32}{3}}}) = (\sqrt{\frac{3}{2}}, \ \ \sqrt{\frac{3}{2}}) \ \ \ \</script><hr>
<p>如果强行限制输出层的分布是标准化的，可能会导致某些特征模式的丢失，所以在标准化之后，BatchNorm会紧接着对数据做缩放和平移。</p>
<script type="math/tex; mode=display">
y_i \leftarrow \gamma \hat{x_i} + \beta</script><p>其中$\gamma$和$\beta$是可学习的参数，可以赋初始值$\gamma = 1, \beta = 0$，在训练过程中不断学习调整。</p>
<p>上面列出的是BatchNorm方法的计算逻辑，下面针对两种类型的输入数据格式分别进行举例。飞桨支持输入数据的维度大小为2、3、4、5四种情况，这里给出的是维度大小为$2$【表格】和$4$【图像】的示例。</p>
<ul>
<li><strong>示例一：</strong> 当输入数据形状是$[N, K]$【N为批量，K为实际的X的取值】时，一般对应全连接层的输出，示例代码如下所示。 </li>
</ul>
<p>这种情况下会分别对K的每一个分量计算N个样本的均值和方差，数据和参数对应如下：</p>
<ul>
<li>输入 x, [N, K]</li>
<li>输出 y, [N, K]</li>
<li>均值 $\mu_B$，[K, ]</li>
<li>方差 $\sigma_B^2$, [K, ]</li>
<li>缩放参数$\gamma$, [K, ]</li>
<li>平移参数$\beta$, [K, ]</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入数据形状是 [N, K]时的示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> BatchNorm1D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">data = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用BatchNorm1D计算归一化的输出</span></span><br><span class="line"><span class="comment"># 输入数据维度[N, K]，num_features等于K</span></span><br><span class="line">bn = BatchNorm1D(num_features=<span class="number">3</span>)    <span class="comment"># 传入的是特征的个数</span></span><br><span class="line">x = paddle.to_tensor(data)</span><br><span class="line">y = bn(x)	<span class="comment"># 将x放到批量归一化的函数中</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;output of BatchNorm1D Layer: \n &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(y.numpy()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Numpy计算均值、方差和归一化的输出</span></span><br><span class="line"><span class="comment"># 这里对第0个特征进行验证</span></span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">4</span>,<span class="number">7</span>])	<span class="comment">#[2,5,8] [3,6,9]是第2、3个特征</span></span><br><span class="line">a_mean = a.mean()</span><br><span class="line">a_std = a.std()</span><br><span class="line">b = (a - a_mean) / a_std</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;std &#123;&#125;, mean &#123;&#125;, \n output &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a_mean, a_std, b))</span><br><span class="line"><span class="comment"># 可以看到如下结果是一样的</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output of BatchNorm1D Layer: </span></span><br><span class="line"><span class="string"> [[-1.2247438 -1.2247438 -1.2247438]</span></span><br><span class="line"><span class="string"> [ 0.         0.         0.       ]</span></span><br><span class="line"><span class="string"> [ 1.2247438  1.2247438  1.2247438]]</span></span><br><span class="line"><span class="string">std 4.0, mean 2.449489742783178, </span></span><br><span class="line"><span class="string"> output [-1.22474487  0.          1.22474487]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建议读者对第1和第2个特征进行验证，观察numpy计算结果与paddle计算结果是否一致</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>示例二：</strong> 当输入数据形状是$[N, C, H, W]$时， 一般对应卷积层的输出，示例代码如下所示。</li>
</ul>
<p>这种情况下会沿着C这一维度进行展开，分别对每一个通道计算N个样本中总共$N\times H \times W$个像素点的均值和方差，数据和参数对应如下：</p>
<ul>
<li>输入 x, [N, C, H, W]</li>
<li>输出 y, [N, C, H, W]</li>
<li>均值 $\mu_B$，[C, ]</li>
<li>方差 $\sigma_B^2$, [C, ]</li>
<li>缩放参数$\gamma$, [C, ]</li>
<li>平移参数$\beta$, [C, ]</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入数据形状是[N, C, H, W]时的batchnorm示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> BatchNorm2D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机数种子，这样可以保证每次运行结果一致</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">data = np.random.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用BatchNorm2D计算归一化的输出</span></span><br><span class="line"><span class="comment"># 输入数据维度[N, C, H, W]，num_features等于C</span></span><br><span class="line">bn = BatchNorm2D(num_features=<span class="number">3</span>)	<span class="comment"># 传入的是通道的维数</span></span><br><span class="line">x = paddle.to_tensor(data)</span><br><span class="line">y = bn(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;input of BatchNorm2D Layer: \n &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(x.numpy()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;output of BatchNorm2D Layer: \n &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(y.numpy()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取出data中第0通道的数据，</span></span><br><span class="line"><span class="comment"># 使用numpy计算均值、方差及归一化的输出</span></span><br><span class="line">a = data[:, <span class="number">0</span>, :, :]</span><br><span class="line">a_mean = a.mean()</span><br><span class="line">a_std = a.std()</span><br><span class="line">b = (a - a_mean) / a_std</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;channel 0 of input data: \n &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;std &#123;&#125;, mean &#123;&#125;, \n output: \n &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a_mean, a_std, b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提示：这里通过numpy计算出来的输出</span></span><br><span class="line"><span class="comment"># 与BatchNorm2D算子的结果略有差别，</span></span><br><span class="line"><span class="comment"># 因为在BatchNorm2D算子为了保证数值的稳定性，</span></span><br><span class="line"><span class="comment"># 在分母里面加上了一个比较小的浮点数 epsilon=1e-05</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">input of BatchNorm2D Layer: </span></span><br><span class="line"><span class="string"> [[[[0.54340494 0.2783694  0.4245176 ]</span></span><br><span class="line"><span class="string">   [0.84477615 0.00471886 0.12156912]</span></span><br><span class="line"><span class="string">   [0.67074907 0.82585275 0.13670659]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  [[0.5750933  0.89132196 0.20920213]</span></span><br><span class="line"><span class="string">   [0.18532822 0.10837689 0.21969749]</span></span><br><span class="line"><span class="string">   [0.9786238  0.8116832  0.17194101]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  [[0.81622475 0.27407375 0.4317042 ]</span></span><br><span class="line"><span class="string">   [0.9400298  0.81764936 0.33611196]</span></span><br><span class="line"><span class="string">   [0.17541045 0.37283206 0.00568851]]]</span></span><br><span class="line"><span class="string">     [[0.98092085 0.05994199 0.89054596]</span></span><br><span class="line"><span class="string">   [0.5769015  0.7424797  0.63018394]</span></span><br><span class="line"><span class="string">   [0.5818422  0.02043913 0.21002658]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  [[0.5446849  0.76911515 0.25069523]</span></span><br><span class="line"><span class="string">   [0.2858957  0.8523951  0.9750065 ]</span></span><br><span class="line"><span class="string">   [0.8848533  0.35950786 0.59885895]]]]</span></span><br><span class="line"><span class="string">output of BatchNorm2D Layer: </span></span><br><span class="line"><span class="string"> [[[[ 0.4126078  -0.46198368  0.02029109]</span></span><br><span class="line"><span class="string">   [ 1.4071034  -1.3650038  -0.97940934]</span></span><br><span class="line"><span class="string">   [ 0.832831    1.344658   -0.9294571 ]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  [[ 0.2520175   1.2038351  -0.84927964]</span></span><br><span class="line"><span class="string">   [-0.9211378  -1.1527538  -0.8176896 ]</span></span><br><span class="line"><span class="string">   [ 1.4666051   0.96413004 -0.961432  ]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  [[ 0.9541142  -0.9075856  -0.36629617]</span></span><br><span class="line"><span class="string">   [ 1.37925     0.9590063  -0.6945517 ]</span></span><br><span class="line"><span class="string">   [-1.2463869  -0.5684581  -1.8291974 ]]]</span></span><br><span class="line"><span class="string">     [[ 1.473519   -1.2985382   1.2014993 ]</span></span><br><span class="line"><span class="string">   [ 0.25745988  0.7558342   0.41783488]</span></span><br><span class="line"><span class="string">   [ 0.27233088 -1.4174379  -0.8467981 ]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  [[ 0.02166975  0.79234385 -0.98786545]</span></span><br><span class="line"><span class="string">   [-0.86699003  1.0783203   1.4993572 ]</span></span><br><span class="line"><span class="string">   [ 1.1897788  -0.6142123   0.20769882]]]]</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">channel 0 of input data: </span></span><br><span class="line"><span class="string"> [[[0.54340494 0.2783694  0.4245176 ]</span></span><br><span class="line"><span class="string">  [0.84477615 0.00471886 0.12156912]</span></span><br><span class="line"><span class="string">  [0.67074907 0.82585275 0.13670659]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> [[0.25242636 0.7956625  0.01525497]</span></span><br><span class="line"><span class="string">  [0.5988434  0.6038045  0.10514768]</span></span><br><span class="line"><span class="string">  [0.38194343 0.03647606 0.89041156]]]</span></span><br><span class="line"><span class="string">std 0.4183686077594757, mean 0.3030227720737457, </span></span><br><span class="line"><span class="string"> output: </span></span><br><span class="line"><span class="string"> [[[ 0.41263014 -0.46200886  0.02029219]</span></span><br><span class="line"><span class="string">  [ 1.4071798  -1.3650781  -0.9794626 ]</span></span><br><span class="line"><span class="string">  [ 0.8328762   1.3447311  -0.92950773]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> [[-0.54762304  1.2451009  -1.3303081 ]</span></span><br><span class="line"><span class="string">  [ 0.5955816   0.61195374 -1.0336547 ]</span></span><br><span class="line"><span class="string">  [-0.12020606 -1.2602768   1.5577804 ]]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>预测时使用BatchNorm</strong></p>
<p>上面介绍了在训练过程中使用BatchNorm对一批样本进行归一化的方法，但如果使用同样的方法对需要预测的一批样本进行归一化，则预测结果会出现不确定性。</p>
<p>例如样本A、样本B作为一批样本计算均值和方差，与样本A、样本C和样本D作为一批样本计算均值和方差，得到的结果一般来说是不同的。那么样本A的预测结果就会变得不确定，这对预测过程来说是不合理的。解决方法是在训练过程中将大量样本的均值和方差保存下来，预测时直接使用保存好的值而不再重新计算。实际上，在BatchNorm的具体实现中，训练时会计算均值和方差的移动平均值。在飞桨中，默认是采用如下方式计算：</p>
<script type="math/tex; mode=display">
saved\_\mu_B \leftarrow \ saved\_\mu_B \times 0.9 + \mu_B \times (1 - 0.9)</script><script type="math/tex; mode=display">
saved\_\sigma_B^2 \leftarrow \ saved\_\sigma_B^2 \times 0.9 + \sigma_B^2 \times (1 - 0.9)</script><p>在训练过程的最开始将$saved_\mu_B$和$saved_\sigma_B^2$设置为0，每次输入一批新的样本，计算出$\mu_B$和$\sigma_B^2$，然后通过上面的公式更新$saved_\mu_B$和$saved_\sigma_B^2$，在训练的过程中不断的更新它们的值，并作为BatchNorm层的参数保存下来。预测的时候将会加载参数$saved_\mu_B$和$saved_\sigma_B^2$，用他们来代替$\mu_B$和$\sigma_B^2$，增加预测结果的可行性。</p>
<h2 id="七、小结"><a href="#七、小结" class="headerlink" title="七、小结"></a>七、小结</h2><ul>
<li>二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。</li>
<li>当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。</li>
<li>填充可以在输入周围额为增加行和列，由此增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽，填充通常用来控制输出形状的减少。</li>
<li>步幅是每次滑动核窗口时行和列的步长，可以成倍减少输出的形状。</li>
<li>填充和步幅是卷积层的超参数。</li>
<li>输出通道数是卷积层的超参数。</li>
<li>每个输入通道有一个独立的二维卷积核，所有通道结果相加得到一个输出通道结果。每个输出通道有独立的三维卷积核。</li>
<li>当以每像素为基础应用时，$1\times 1$卷积层相当于全连接层。</li>
<li>$1\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。</li>
<li>对于给定输入元素，最大池化层会输出该窗口内的最大值，平均池化层会输出该窗口内的平均值。</li>
<li>池化层的主要优点之一是减轻卷积层对位置的过度敏感。</li>
<li>我们可以指定池化层的填充和步幅。</li>
<li>使用最大池化层以及大于1的步幅，可减少空间维度（如高度和宽度）。</li>
<li>池化层的输出通道数与输入通道数相同。</li>
<li>池化层同样有窗口大小、填充和步幅作为超参数。池化层没有需要学习的参数。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space">小漁头&amp;小戴</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.1-%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF/">http://blog.dai2yutou.space/2023/01/01/深度学习5.1-从全连接层到卷积/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.dai2yutou.space" target="_blank">小漁头|小戴</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/paddle/">paddle</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E5%8D%B7%E7%A7%AF%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/">深度学习基础_卷积基本概念及经典模型复现</a></div><div class="post_share"><div class="social-share" data-image="https://picbed.dai2yutou.space/web_img/19.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css" media="print" onload="this.media='all'"><script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04.2-%E4%BD%BF%E7%94%A8%E6%9E%81%E7%AE%80%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">深度学习4.2-使用极简方法实现手写数字识别任务</div></div></a></div><div class="next-post pull-right"><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.2-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%B8%AD%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%84%E7%BD%91%E6%96%B9%E5%BC%8F/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习5.2-图像分类中经典模型的组网方式</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.2-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%B8%AD%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%84%E7%BD%91%E6%96%B9%E5%BC%8F/" title="深度学习5.2-图像分类中经典模型的组网方式"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">深度学习5.2-图像分类中经典模型的组网方式</div></div></a></div><div><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.3-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" title="深度学习5.3-图像识别模型关键组件之数据处理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">深度学习5.3-图像识别模型关键组件之数据处理</div></div></a></div><div><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.4-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E4%B8%8E%E5%BE%AE%E8%B0%83/" title="深度学习5.4-图像识别模型关键组件之图像增广与迁移学习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">深度学习5.4-图像识别模型关键组件之图像增广与迁移学习</div></div></a></div><div><a href="/2022/12/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="深度学习1.1-深度学习概论"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-18</div><div class="title">深度学习1.1-深度学习概论</div></div></a></div><div><a href="/2022/12/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.1-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98%E7%AD%96%E7%95%A5%EF%BC%88%E4%B8%8A%EF%BC%89/" title="深度学习3.1-模型选择与调优策略（上）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-25</div><div class="title">深度学习3.1-模型选择与调优策略（上）</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/" title="深度学习2.1-线性回归模型的实现"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.1-线性回归模型的实现</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="animate__fadeIn card-info card-widget wow" data-wow-delay="0" data-wow-duration="" data-wow-iteration="" data-wow-offset="" style="visibility: visible; animation-name: fadeIn;"><div class="author-info-top"><div class="card-info-avatar"><a class="avatar-img" data-pjax-state="" href="/about"><img class="entered loaded" alt="avatar" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/apple-touch-icon.jpg" onerror="this.onerror=null,this.src=&quot;/img/friend_404.gif&quot;"/></a><div class="author-status-box"><div class="author-status"><g-emoji class="g-emoji" alias="palm_tree" fallback-src="/img/tree_icon.png">🐟</g-emoji><span>摸鱼中~</span></div></div></div></div><div class="author-info__sayhi" id="author-info__sayhi">晚安😴！我是</div><h1 class="author-info__name">XiaoYutou|XiaoDai</h1><div class="author-info__description">热爱生活点滴，分享时刻精彩。</div><a id="card-info-btn" data-pjax-state="" onclick="pjax.loadUrl(/about/)"><i></i><span style="padding-left:32px;font-weight:600;font-size:large">了解更多<i class="faa-passing animated" style="padding-left:-2px;display:inline-block;vertical-align:middle;"><span style="height:28px;width:28px;fill:currentColor;position:relative;top:-1.5px">💨</span></i></span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xiaoyutoua" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2143191301@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>主域名:<a target="_blank" rel="noopener" href="https://www.dai2yutou.space">小漁头|小戴</a><br><span>技术问题欢迎交流🧐</span><span color="#3eb8be">VX:yuguolong_001</span></center></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF"><span class="toc-text">从全连接层到卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E7%9A%84%E5%B1%80%E9%99%90"><span class="toc-text">一、全连接层的局限</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%8F%98%E6%80%A7"><span class="toc-text">二、空间不变性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89%E5%B9%B3%E7%A7%BB%E4%B8%8D%E5%8F%98%E6%80%A7"><span class="toc-text">1）平移不变性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89%E5%B1%80%E9%83%A8%E6%80%A7"><span class="toc-text">2）局部性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%BC%89%E5%A4%9A%E9%80%9A%E9%81%93"><span class="toc-text">3）多通道</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%8D%B7%E7%A7%AF%EF%BC%88Convolution%EF%BC%89"><span class="toc-text">三、卷积（Convolution）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97"><span class="toc-text">1）卷积计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89%E5%A1%AB%E5%85%85"><span class="toc-text">2）填充</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%BC%89%E6%AD%A5%E5%B9%85"><span class="toc-text">3）步幅</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%EF%BC%89%E6%84%9F%E5%8F%97%E9%87%8E"><span class="toc-text">4）感受野</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%EF%BC%89%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93%E3%80%81%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93"><span class="toc-text">5）多输入通道、多输出通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%EF%BC%891-times-1-%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-text">6）1 $\times$ 1 卷积层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E9%A3%9E%E6%A1%A8%E5%8D%B7%E7%A7%AFAPI%E4%BB%8B%E7%BB%8D"><span class="toc-text">四、飞桨卷积API介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%AE%97%E5%AD%90%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B"><span class="toc-text">卷积算子应用举例</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B1%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E9%BB%91%E7%99%BD%E8%BE%B9%E7%95%8C%E6%A3%80%E6%B5%8B"><span class="toc-text">案例1——简单的黑白边界检测</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B2%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E4%B8%AD%E7%89%A9%E4%BD%93%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="toc-text">案例2——图像中物体边缘检测</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B3%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%9D%87%E5%80%BC%E6%A8%A1%E7%B3%8A"><span class="toc-text">案例3——图像均值模糊</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%B1%A0%E5%8C%96%EF%BC%88Pooling%EF%BC%89"><span class="toc-text">五、池化（Pooling）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%B9%B3%E5%9D%87%E6%B1%A0%E5%8C%96%E4%B8%8E%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96"><span class="toc-text">5.1 平均池化与最大池化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85"><span class="toc-text">5.2 填充和步幅</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%A4%9A%E4%B8%AA%E9%80%9A%E9%81%93"><span class="toc-text">5.3 多个通道</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%88Batch-Normalization%EF%BC%89"><span class="toc-text">六、批归一化（Batch Normalization）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E5%B0%8F%E7%BB%93"><span class="toc-text">七、小结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/08/python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" title="python内置函数使用方法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python内置函数使用方法"/></a><div class="content"><a class="title" href="/2023/05/08/python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" title="python内置函数使用方法">python内置函数使用方法</a><time datetime="2023-05-08T12:06:44.000Z" title="发表于 2023-05-08 20:06:44">2023-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/25/Python%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F%EF%BC%9A%E5%8F%AF%E5%8F%98-%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1/" title="Python传参方式：可变/不可变对象"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python传参方式：可变/不可变对象"/></a><div class="content"><a class="title" href="/2023/04/25/Python%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F%EF%BC%9A%E5%8F%AF%E5%8F%98-%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1/" title="Python传参方式：可变/不可变对象">Python传参方式：可变/不可变对象</a><time datetime="2023-04-25T05:00:23.000Z" title="发表于 2023-04-25 13:00:23">2023-04-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/24/python%E5%AD%A6%E4%B9%A0%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8D%E4%BC%9A%E7%9A%84%E7%9F%A5%E8%AF%86/" title="python学习中遇到的基础不会的知识"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python学习中遇到的基础不会的知识"/></a><div class="content"><a class="title" href="/2023/04/24/python%E5%AD%A6%E4%B9%A0%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8D%E4%BC%9A%E7%9A%84%E7%9F%A5%E8%AF%86/" title="python学习中遇到的基础不会的知识">python学习中遇到的基础不会的知识</a><time datetime="2023-04-24T15:53:05.000Z" title="发表于 2023-04-24 23:53:05">2023-04-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 小漁头&小戴</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.6/translate/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script defer src="/js/light.js"></script><canvas id="universe"></canvas><script defer src="/js/starry_sky.js"></script><script defer src="/js/console.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script async data-pjax src="/js/card_author.js"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JzK9w99AgP1g6fso",ck:"JzK9w99AgP1g6fso"})</script><script type="text/javascript" src ="/js/reward.js" ></script><script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.6.16/dist/sweetalert2.all.min.js"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = 'b16a1fa0e63c46a4b8f28abfb06ae3fe';
  var gaud_map_key = 'e2b04289e870b005374ee030148d64fd&s=rsv3';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/1.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">英文水平不高，咋翻译论文？</a><div class="blog-slider__text">英文水平不高，咋翻译论文？</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/9.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">Butterfly外挂标签</a><div class="blog-slider__text">本文是撰写博客文章时可能会用到的外挂标签汇总，放到一起，便于查阅和使用</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/web_background2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-17</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">🐌博客搭建学习笔记</a><div class="blog-slider__text">这是再搭建博客已经写文章时遇到的bug和对博客的一些必要操作，不定时更新哦~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/07/停车场管理模拟系统/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-07</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/07/停车场管理模拟系统/&quot;);" href="javascript:void(0);" alt="">停车场管理模拟系统</a><div class="blog-slider__text">本文是大二下学期程序设计与数据结构实训课设，模拟的是一个停车场管理系统，用C和C++语言编写，在此记录一下~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/07/停车场管理模拟系统/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/2.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">第一篇文章</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">Hexo发生error：spawn failed错误的解决方法</a><div class="blog-slider__text">Hexo发生error：spawn failed错误的解决方法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-06</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">Hexo博客备份与恢复</a><div class="blog-slider__text">本文旨在解决在不同电脑上都能维护博客或配置、发布的内容丢失可恢复的问题。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">Echarts社区地址</a><div class="blog-slider__text">一些Echarts图标的开源网站。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '2');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__bounceInRight');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/about/'|| '/about/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.dai2yutou.space/api?xiaoyutoua",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xiaoyutoua')
    }
  </script><!-- hexo injector body_end end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>