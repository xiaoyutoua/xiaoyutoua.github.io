<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>深度学习5.4-图像识别模型关键组件之图像增广与迁移学习 | 小漁头|小戴</title><meta name="author" content="小漁头&amp;小戴"><meta name="copyright" content="小漁头&amp;小戴"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="本文是深度学习的第十二篇，本文主要介绍了图像识别模型中的图像增广和迁移学习中的微调技巧。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习5.4-图像识别模型关键组件之图像增广与迁移学习">
<meta property="og:url" content="http://blog.dai2yutou.space/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.4-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E4%B8%8E%E5%BE%AE%E8%B0%83/index.html">
<meta property="og:site_name" content="小漁头|小戴">
<meta property="og:description" content="本文是深度学习的第十二篇，本文主要介绍了图像识别模型中的图像增广和迁移学习中的微调技巧。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picbed.dai2yutou.space/web_img/19.png">
<meta property="article:published_time" content="2023-01-01T13:06:24.000Z">
<meta property="article:modified_time" content="2023-03-30T12:12:57.609Z">
<meta property="article:author" content="小漁头&amp;小戴">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="paddle">
<meta property="article:tag" content="深度学习基础_卷积基本概念及经典模型复现">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picbed.dai2yutou.space/web_img/19.png"><link rel="shortcut icon" href="/img/basketball.png"><link rel="canonical" href="http://blog.dai2yutou.space/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.4-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E4%B8%8E%E5%BE%AE%E8%B0%83/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 小漁头&小戴","link":"链接: ","source":"来源: 小漁头|小戴","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习5.4-图像识别模型关键组件之图像增广与迁移学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-30 20:12:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/css.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/at.alicdn.com/t/c/font_3829236_a49e40pee5.css"><link rel="stylesheet" href="/css/font-awesome.css"><link rel="stylesheet" href="/css/progress_bar.css"><link rel="stylesheet" href="/css/nav_menu.css"><link rel="stylesheet" href="/css/color.css"><link rel="apple-touch-icon" href="/img/apple-touch-icon.jpg"><meta name="apple-mobile-web-app-title" content="小漁头🏀"><link rel="bookmark" href="/img/apple-touch-icon.jpg"><link rel="apple-touch-icon-precomposed" sizes="180x180" href="/img/apple-touch-icon.jpg" ><link rel="stylesheet" href="/css/card_author.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (ture) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picbed.dai2yutou.space/web_img/19.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">小漁头|小戴</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习5.4-图像识别模型关键组件之图像增广与迁移学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-01T13:06:24.000Z" title="发表于 2023-01-01 21:06:24">2023-01-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-30T12:12:57.609Z" title="更新于 2023-03-30 20:12:57">2023-03-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习5.4-图像识别模型关键组件之图像增广与迁移学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>一、图像增广</h1>
<p>🏷️<code>sec_image_augmentation</code></p>
<p>在<code>Alexnet</code>中，我们提到过大型数据集是成功应用深度神经网络的先决条件。图像增广在对训练图像进行一系列的随机变化之后，生成相似但不同的训练样本，从而扩大了训练集的规模。<br>
数据增广是深度学习中常用的技巧之一，主要用于增加训练数据集【增加在当前数据集上，并在项目中直接使用，不会占用本地内存】，让数据集尽可能的多样化，使得训练的模型具有更强的泛化能力。现有的各大深度学习框架都已经自带了数据增广，在实际应用中，并非所有的增广方式都适用当前的训练数据，你需要根据自己的数据集特征来确定应该使用哪几种数据增广方式。</p>
<h2 id="1-1-数据不足的问题">1.1 数据不足的问题</h2>
<p>我们常常会遇到数据不足的情况。我们来思考一个问题：目前现在流行的最先进的神经网络都是成千上万的图片数据，足够大的数据集是效果好的保证。<br>
但是在自己的小数据集上能够使神经网络表现好吗？答案是不确定的。</p>
<p>众所周知，进行模型训练时，数据越多,得到的结果越准确。那么怎么让数据变得多呢？这时，使用合理的数据增强，便解决了数据不足的问题。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/b75a81055f1b423192d8a8dd073d3504c91eb6f2eb8f4390a566cc07a829d9e4" width="500" hegiht="" ></center>
<center><br>图1：扩充数据</br></center>
<p><br></br></p>
<p>就如上图的猫咪，不论是左转多少度，右转多少度，虽然它都是一只猫咪，但是<strong>每一个图片却不是同一个数据</strong>，这就是对数据的增强处理。例如，我们可以以不同的方式裁剪图像，使感兴趣的对象出现在不同的位置，减少模型对于对象出现位置的依赖；我们还可以调整亮度、颜色等因素来降低模型对颜色的敏感度，提高模型的泛化能力。<br>
可以说，图像增广技术对于AlexNet的成功是必不可少的。在本节中，我们将讨论这项广泛应用于计算机视觉的技术。</p>
<p>总结来说，数据增强是指增加一个已有的数据集，使得其拥有更多的多样性，这通常都是在线生成的。我们读入一张原始图片，在之后对它随机做增强，再将处理完的图片放入模型中进行训练。<br>
当然，测试的时候就不需要进行数据增强了，因此这相当于在训练数据中加入了正则项。除了图片上的数据增强，这一技术在语音类数据和文本类数据上同样适用。</p>
<p>我们可以手动对图片进行处理，例如下面的操作：更改图像尺寸和更改模式。</p>
<blockquote>
<p>一般图像都是RGB三个通道，但是有一种图片格式<code>jpg</code>有四个通道，RGBA。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> vision</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;更改原图像&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入一张图片</span></span><br><span class="line"><span class="comment"># 查看数据形状，其形状是[H, W, 通道数]</span></span><br><span class="line">img1 = Image.<span class="built_in">open</span>(<span class="string">&#x27;./work/cat.jpg&#x27;</span>)</span><br><span class="line">img1_shape = np.array(img1)</span><br><span class="line"><span class="built_in">print</span>(img1_shape.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改尺寸</span></span><br><span class="line">img2 = img1.resize((<span class="number">500</span>,<span class="number">400</span>))</span><br><span class="line">img2_shape = np.array(img2) </span><br><span class="line"><span class="built_in">print</span>(img2_shape.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改模式</span></span><br><span class="line"><span class="comment"># RGBA 即红色、绿色、蓝色、透明度(英语:Red, Green, Blue、Alpha)。</span></span><br><span class="line"><span class="built_in">print</span>(img1)</span><br><span class="line">img1 = img1.convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(img1)</span><br><span class="line">img1.save(<span class="string">&quot;cat_RGB.jpg&quot;</span>)	<span class="comment"># 保存图片</span></span><br></pre></td></tr></table></figure>
<p>虽然以上方法完美的实现了我们的需求，但是这种方式太低效了。下面我们会介绍几种常见的图像增广方法，我们可以快速地使用飞桨API来实现这些操作。</p>
<h2 id="1-2-常用的图像增广方法">1.2 常用的图像增广方法</h2>
<p>在对常用图像增广方法的探索时，我们将使用下面这个尺寸为$400\times 500$的图像作为示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;./work/animal.jpg&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;lesser panda&#x27;</span>)</span><br><span class="line">plt.imshow(img)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/53.png" alt="png"></p>
<p>大多数图像增广方法都具有一定的随机性。为了便于观察图像增广的效果，我们下面定义辅助函数<code>apply</code>。此函数在输入图像<code>img</code>上多次运行图像增广方法<code>aug</code>并显示所有结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">apply</span>(<span class="params"></span></span><br><span class="line"><span class="params">    img, </span></span><br><span class="line"><span class="params">    aug,</span></span><br><span class="line"><span class="params">    num_rows=<span class="number">2</span>,	</span></span><br><span class="line"><span class="params">    num_cols=<span class="number">5</span>, </span></span><br><span class="line"><span class="params">    scale=<span class="number">1.5</span>,</span></span><br><span class="line"><span class="params">    titles=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    img, 图片：传入的图片</span></span><br><span class="line"><span class="string">    aug, 规则：对图片进行变换的方式</span></span><br><span class="line"><span class="string">    num_rows=2, 行数</span></span><br><span class="line"><span class="string">    num_cols=5, 列数</span></span><br><span class="line"><span class="string">    scale=1.5, 缩放系数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Y = [aug(img) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_rows * num_cols)]</span><br><span class="line">    figsize = (num_cols * scale, num_rows * scale)</span><br><span class="line">    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)</span><br><span class="line">    axes = axes.flatten()</span><br><span class="line">    <span class="keyword">for</span> i, (ax, img) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(axes, Y)):</span><br><span class="line">        <span class="keyword">if</span> paddle.is_tensor(img):</span><br><span class="line">        <span class="comment"># Tensor Image</span></span><br><span class="line">            ax.imshow(img.numpy())	<span class="comment"># 将张量类型转换为数值类型</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># PIL Image</span></span><br><span class="line">            ax.imshow(img)</span><br><span class="line">        ax.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        ax.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> titles:</span><br><span class="line">            ax.set_title(titles[i])</span><br><span class="line">    <span class="keyword">return</span> axes</span><br></pre></td></tr></table></figure>
<h3 id="1）翻转"><strong>1）翻转</strong></h3>
<p>左右翻转图像通常不会改变对象的类别。这是最早且最广泛使用的图像增广方法之一。接下来，我们使用<code>transforms</code>模块来创建<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/transforms/RandomHorizontalFlip_cn.html#randomhorizontalflip">RandomHorizontalFlip</a>实例，这样就各有50%的几率使图像向左或向右翻转。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RandomHorizontalFlip 基于概率来执行图片的水平翻转。</span></span><br><span class="line"><span class="comment"># prob (float) - 图片执行水平翻转的概率，默认0.5</span></span><br><span class="line">apply(img, vision.transforms.RandomHorizontalFlip())</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/54.png" alt="png"></p>
<p>上下翻转图像不如左右图像翻转那样常用，原因在于很有可能造成误解，例如建筑物翻转之后就完全不同。接下来，我们创建一个<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/transforms/RandomVerticalFlip_cn.html#randomverticalflip">RandomVerticalFlip</a>实例，使图像各有50%的几率向上或向下翻转。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RandomVerticalFlip 基于概率来执行图片的垂直翻转。</span></span><br><span class="line"><span class="comment"># prob (float) - 执行图片垂直翻转的概率，默认0.5</span></span><br><span class="line">apply(img, vision.transforms.RandomVerticalFlip())</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/55.png" alt="png"></p>
<h3 id="2）裁剪切割"><strong>2）裁剪切割</strong></h3>
<p>在我们使用的示例图像中，主角位于图像的中间，但并非所有图像都是这样。在池化层一节中，我们解释了池化层可以降低卷积层对目标位置的敏感性。另外，我们可以通过对图像进行随机裁剪，使物体以不同的比例出现在图像的不同位置，这也可以降低模型对目标位置的敏感性。</p>
<p>在下面的代码中，我们<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/transforms/RandomResizedCrop_cn.html#randomresizedcrop">随机裁剪</a>一个面积为原始面积10%到100%的区域，该区域的宽高比从0.5到2之间随机取值。然后，区域的宽度和高度都被缩放到200像素。在本节中，$a$和$b$之间的随机数指的是在区间$[a, b]$中通过均匀采样获得的连续值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RandomResizedCrop 将输入图像按照随机大小和长宽比进行裁剪。</span></span><br><span class="line">shape_aug = vision.transforms.RandomResizedCrop(</span><br><span class="line">    (<span class="number">200</span>, <span class="number">200</span>), <span class="comment"># 宽度和高度都被缩放到200像素</span></span><br><span class="line">    scale=(<span class="number">0.1</span>, <span class="number">1</span>), <span class="comment"># 面积为原始面积10%到100%的区域, 默认值：0.08至1.0</span></span><br><span class="line">    ratio=(<span class="number">0.5</span>, <span class="number">2</span>) <span class="comment"># 宽高比从0.5到2之间随机取值, 默认值：3./4至4./3</span></span><br><span class="line">)</span><br><span class="line">apply(img, shape_aug)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/56.png" alt="png"></p>
<h3 id="3）改变颜色"><strong>3）改变颜色</strong></h3>
<p>另一种增广方法是<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/transforms/ColorJitter_cn.html#colorjitter">改变颜色</a>。我们可以改变图像颜色的四个方面：亮度（brightness）、对比度（contrast）、饱和度（saturation）和色调（hue）。在下面的示例中，我们随机更改图像的四个数值，随机值为原始图像的50%（$1-0.5$）到150%（$1+0.5$）之间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ColorJitter 随机调整图像的亮度、对比度、饱和度和色调。</span></span><br><span class="line">apply(img, </span><br><span class="line">    vision.transforms.ColorJitter(</span><br><span class="line">        brightness=<span class="number">0.5</span>,</span><br><span class="line">        contrast=<span class="number">0</span>,</span><br><span class="line">        saturation=<span class="number">0</span>,</span><br><span class="line">        hue=<span class="number">0</span></span><br><span class="line">        )</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/57.png" alt="png"></p>
<p>我们还可以创建一个<code>RandomColorJitter</code>实例，并设置同时随机更改图像的亮度（<code>brightness</code>）、对比度（<code>contrast</code>）、饱和度（<code>saturation</code>）和色调（<code>hue</code>）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">color_aug = vision.transforms.ColorJitter(</span><br><span class="line">    brightness=<span class="number">0.5</span>, </span><br><span class="line">    contrast=<span class="number">0.5</span>, </span><br><span class="line">    saturation=<span class="number">0.5</span>, </span><br><span class="line">    hue=<span class="number">0.5</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">apply(img, color_aug)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/58.png" alt="png"></p>
<h3 id="4）结合多种图像增广方法"><strong>4）结合多种图像增广方法</strong></h3>
<p>在实践中，我们将结合多种图像增广方法。比如，我们可以通过使用一个<code>Compose</code>实例来综合上面定义的不同的图像增广方法，并将它们应用到每个图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">augs = vision.transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">    vision.transforms.RandomHorizontalFlip(),</span><br><span class="line">    color_aug,</span><br><span class="line">    shape_aug,</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">apply(img, augs)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/59.png" alt="png"></p>
<h2 id="1-3-应用图像增广">1.3 应用图像增广</h2>
<p>让我们使用图像增广来训练模型。这里，我们使用<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10数据集</a>CIFAR-10数据集中对象的颜色和大小差异更明显。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_images = vision.datasets.Cifar10(mode=<span class="string">&#x27;train&#x27;</span>, data_file=<span class="string">&#x27;data/data149232/cifar-10-python.tar.gz&#x27;</span>, download=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">import</span> ppl</span><br><span class="line">ppl.show_images([all_images[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>)], <span class="number">4</span>, <span class="number">8</span>, scale=<span class="number">0.8</span>);</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/60.png" alt="png"></p>
<p>为了在预测过程中得到确切的结果，我们通常对训练样本只进行图像增广，且在预测过程中不使用随机操作的图像增广，在这里，我们只使用最简单的随机左右翻转。<br>
此外，我们使用<code>ToTensor</code>实例将一批图像转换为深度学习框架所要求的格式，即形状为（批量大小，通道数，高度，宽度）的32位浮点数，取值范围为0到1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vision.transforms.Compose 将用于数据集预处理的接口以列表的方式进行组合</span></span><br><span class="line"><span class="comment"># 应用简单的左右翻转</span></span><br><span class="line"><span class="comment"># ToTensor 生成数据格式为（批量大小，通道数量，高度，宽度）</span></span><br><span class="line"></span><br><span class="line">train_augs = vision.transforms.Compose([</span><br><span class="line">    vision.transforms.RandomHorizontalFlip(),</span><br><span class="line">    vision.transforms.ToTensor()</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">test_augs = vision.transforms.Compose([</span><br><span class="line">    vision.transforms.ToTensor()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_cifar10</span>(<span class="params">is_train, augs, batch_size</span>):</span><br><span class="line">    <span class="keyword">if</span> is_train:</span><br><span class="line">        dataset = vision.datasets.Cifar10(</span><br><span class="line">            mode=<span class="string">&#x27;train&#x27;</span>, data_file=<span class="string">&#x27;data/data149232/cifar-10-python.tar.gz&#x27;</span>, transform=augs, download=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dataset = vision.datasets.Cifar10(</span><br><span class="line">            mode=<span class="string">&#x27;test&#x27;</span>, data_file=<span class="string">&#x27;data/data149232/cifar-10-python.tar.gz&#x27;</span>, transform=augs, download=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">    dataloader = paddle.io.DataLoader(dataset, </span><br><span class="line">                                    batch_size=batch_size,</span><br><span class="line">                                    shuffle=is_train,</span><br><span class="line">                                    num_workers=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> dataloader</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_iter = load_cifar10(<span class="literal">True</span>, train_augs, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="built_in">print</span>(X.shape, y.shape)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<pre><code>[10, 3, 32, 32] [10]
</code></pre>
<p>这样我们就构造好了数据迭代器，我们将使用下面章节讲的内容来将图像增广技术应用到自己的图像识别模型中。</p>
<h1>二、微调</h1>
<p>🏷️<code>sec_fine_tuning</code></p>
<p>在前面的一些章节中，我们介绍了如何在只有6万张图像的MNIST训练数据集上训练模型。我们还描述了学术界当下使用最广泛的大规模图像数据集ImageNet，它有超过1000万的图像和1000类的物体。然而，我们平常接触到的数据集的规模通常在这两者之间。</p>
<p>假如我们想识别图片中不同类型的椅子，然后向用户推荐购买链接。一种可能的方法是首先识别100把普通椅子，为每把椅子拍摄1000张不同角度的图像，然后在收集的图像数据集上训练一个分类模型，尽管这个椅子数据集可能大于Fashion-MNIST数据集，但实例数量仍然不到ImageNet中的十分之一。适合ImageNet的复杂模型可能会在这个椅子数据集上过拟合。此外，由于训练样本数量有限，训练模型的准确性可能无法满足实际要求。</p>
<p>为了解决上述问题，一个显而易见的解决方案是收集更多的数据，但是，收集和标记数据可能需要大量的时间和金钱。例如，为了收集ImageNet数据集，研究人员花费了数百万美元的研究资金。尽管目前的数据收集成本已大幅降低，但这一成本仍不能忽视。</p>
<p>另一种解决方案是应用<strong>迁移学习（transfer learning）</strong> ，将从源数据集学到的知识迁移到目标数据集。例如，尽管ImageNet数据集中的大多数图像与椅子无关，但在此数据集上训练的模型可能会提取更通用的图像特征，这有助于识别边缘、纹理、形状和对象组合，这些类似的特征也可能有效地识别椅子。</p>
<h2 id="2-1-步骤">2.1 步骤</h2>
<p>在本节中，我们将介绍迁移学习中的常见技巧：<strong>微调（fine-tuning）</strong>。微调包括以下四个步骤：</p>
<ol>
<li>在源数据集（例如ImageNet数据集）上预训练神经网络模型，即源模型。</li>
<li>创建一个新的神经网络模型，即目标模型。复制源模型上的所有模型设计及其参数（输出层除外）。</li>
<li>向目标模型添加输出层，其输出数是目标数据集中的类别数。然后随机初始化该层的模型参数。</li>
<li>在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。</li>
</ol>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/e68ea652432448a0b7ecb994cdc3cef3ac2a74eb45f64a43a2c89bfc850f68a9" width="800" hegiht="" ></center>
<center><br>图2：微调模型</br></center>
<p><br></br></p>
<p><strong>当目标数据集比源数据集小得多时，微调有助于提高模型的泛化能力。</strong></p>
<h2 id="2-2-热狗识别">2.2 热狗识别</h2>
<p>通过热狗识别的例子了解Fine-Tuning的用法，我们将在一个小型数据集上微调ResNet模型，该ResNet模型已在ImageNet数据集上进行了预训练。<br>
这个小型数据集包含数千张包含热狗和不包含热狗的图像，我们将使用微调模型来识别图像中是否包含热狗。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> vision</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> ppl</span><br></pre></td></tr></table></figure>
<h3 id="1）获取数据集"><strong>1）获取数据集</strong></h3>
<p>我们使用的热狗数据集来源于网络。该数据集包含1400张热狗的“正类”图像，以及包含尽可能多的其他食物的“负类”图像。含着两个类别的1000张图片用于训练，其余的则用于测试。<br>
解压下载的数据集，我们获得了两个文件夹<code>hotdog/train</code>和<code>hotdog/test</code>。<br>
这两个文件夹都有<code>hotdog</code>（有热狗）和<code>not-hotdog</code>（无热狗）两个子文件夹，<br>
子文件夹内都包含相应类的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line"><span class="comment"># -o 不必先询问用户，unzip执行后覆盖原有文件</span></span><br><span class="line">!unzip -o -q data/data149507/hotdog.<span class="built_in">zip</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_dir = <span class="string">&#x27;hotdog&#x27;</span>		<span class="comment"># 记录图片的路径</span></span><br></pre></td></tr></table></figure>
<p>我们创建两个实例来分别读取训练和测试数据集中的所有图像文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ImageFolder 一种通用的数据加载方式</span></span><br><span class="line">train_imgs = vision.datasets.ImageFolder(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>))</span><br><span class="line">test_imgs = vision.datasets.ImageFolder(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>下面显示了前8个正类样本图片和最后8张负类样本图片。正如你所看到的，图像的大小和纵横比各有不同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hotdogs = [train_imgs[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>)]</span><br><span class="line">not_hotdogs = [train_imgs[-i - <span class="number">1</span>][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>)]</span><br><span class="line">ppl.show_images(hotdogs + not_hotdogs, <span class="number">2</span>, <span class="number">8</span>, scale=<span class="number">1.4</span>); <span class="comment"># 分号用于一条语句的结束标识</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/61.png" alt="png"></p>
<h3 id="2）数据增广"><strong>2）数据增广</strong></h3>
<ul>
<li>在训练期间：我们首先将输入图像按照随机大小和长宽比进行裁剪，然后将该区域缩放为$224 \times 224$输入图像。进行水平翻转。</li>
<li>在测试过程中：由于图像的高宽比都不同，因此我们将图像的高度和宽度都缩放到256像素，然后裁剪中央$224 \times 224$区域作为输入。</li>
</ul>
<p>此外，对于RGB（红、绿和蓝）颜色通道，我们分别标准化每个通道：具体而言，该通道的每个值减去该通道的平均值，然后将结果除以该通道的标准差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">normalize = vision.transforms.Normalize(</span><br><span class="line">    [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"></span><br><span class="line">train_augs = vision.transforms.Compose([</span><br><span class="line">    vision.transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">    vision.transforms.RandomHorizontalFlip(),</span><br><span class="line">    vision.transforms.ToTensor(),</span><br><span class="line">    normalize])</span><br><span class="line"></span><br><span class="line">test_augs = vision.transforms.Compose([</span><br><span class="line">    vision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    vision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    vision.transforms.ToTensor(),</span><br><span class="line">    normalize])</span><br></pre></td></tr></table></figure>
<h3 id="3）定义和初始化模型"><strong>3）定义和初始化模型</strong></h3>
<p>我们使用在ImageNet数据集上预训练的ResNet-18作为源模型。在这里，我们指定<code>pretrained=True</code>以自动下载预训练的模型参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pretrained (bool，可选) - 是否加载在imagenet数据集上的预训练权重。默认值：False。</span></span><br><span class="line">pretrained_net = vision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>预训练的源模型实例包含许多特征层和一个输出层<code>fc</code>，下面给出了源模型的成员变量<code>fc</code>。此划分的主要目的是促进对除输出层以外所有层的模型参数进行微调，在ResNet的全局平均汇聚层后，全连接层转换为ImageNet数据集的1000个类输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pretrained_net)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;#################################################&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;输出层&#x27;</span>, pretrained_net.fc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;#################################################&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>之后，我们构建一个新的神经网络作为目标模型。它的定义方式与预训练源模型的定义方式相同，只是最终层中的输出数量被设置为目标数据集中的类数（而不是1000个）。</p>
<p>在下面的代码中，目标模型<code>finetune_net</code>中成员变量<code>features</code>的参数被初始化为源模型相应层的模型参数。由于模型参数是在ImageNet数据集上预训练的，并且足够好，因此通常只需要较小的学习率即可微调这些参数。</p>
<p>成员变量<code>output</code>的参数是随机初始化的，通常需要更高的学习率才能从头开始训练。假设<code>Trainer</code>实例中的学习率为$\eta$，我们将成员变量<code>output</code>中参数的学习率设置为$10\eta$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">finetune_net = vision.models.resnet18(pretrained=<span class="literal">True</span>) <span class="comment"># 模型参数初始化为源模型相应层的模型参数</span></span><br><span class="line">finetune_net.fc = nn.Linear(finetune_net.fc.weight.shape[<span class="number">0</span>], <span class="number">2</span>) <span class="comment"># 调整输出层（512,2）</span></span><br><span class="line">finetune_net.fc.weight.set_value = nn.initializer.XavierUniform() <span class="comment"># 只对输出层设置初始化参数策略</span></span><br></pre></td></tr></table></figure>
<h3 id="4）训练微调模型"><strong>4）训练微调模型</strong></h3>
<p>首先，我们定义了一个训练函数<code>train_fine_tuning</code>，该函数使用微调，因此可以多次调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_batch</span>(<span class="params">net, X, y, loss, trainer</span>): 	<span class="comment"># 每个批量的训练过程【内层循环】</span></span><br><span class="line">    net.train()		<span class="comment">#开始循环</span></span><br><span class="line">    trainer.clear_grad()	<span class="comment"># 进行梯度</span></span><br><span class="line">    pred = net(X)	<span class="comment"># 计算预测值</span></span><br><span class="line">    l = loss(pred, y)	<span class="comment"># 计算损失</span></span><br><span class="line">    l.<span class="built_in">sum</span>().backward()	<span class="comment"># 反向传播</span></span><br><span class="line">    trainer.step()	<span class="comment"># 更新梯度</span></span><br><span class="line">    train_loss_sum = l.<span class="built_in">sum</span>()	<span class="comment"># 临时存储损失值</span></span><br><span class="line">    train_acc_sum = ppl.accuracy(pred, y)	<span class="comment"># 临时存储精度值</span></span><br><span class="line">    <span class="keyword">return</span> train_loss_sum, train_acc_sum</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, test_iter, loss, trainer, num_epochs</span>):	<span class="comment">#外层循环，训练过程</span></span><br><span class="line">    num_batches = <span class="built_in">len</span>(train_iter)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        metric = ppl.Accumulator(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> i, (features, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">            l, acc = train_batch(net, features, labels, loss, trainer)</span><br><span class="line">            metric.add(l, acc, labels.shape[<span class="number">0</span>])</span><br><span class="line">            <span class="built_in">print</span>(metric[<span class="number">0</span>] / metric[<span class="number">2</span>], metric[<span class="number">1</span>] / metric[<span class="number">2</span>], metric[<span class="number">2</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;#####################################&quot;</span>)</span><br><span class="line">        test_acc = ppl.evaluate_accuracy(net, test_iter)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;loss <span class="subst">&#123;metric[<span class="number">0</span>] / metric[<span class="number">2</span>]:<span class="number">.3</span>f&#125;</span>,  &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;train acc <span class="subst">&#123;metric[<span class="number">1</span>] / metric[<span class="number">2</span>]:<span class="number">.3</span>f&#125;</span>,  &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;test acc <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>,  &#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行微调</span></span><br><span class="line"><span class="comment"># 如果param_group=True，输出层中的模型参数将使用十倍的学习率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_fine_tuning</span>(<span class="params">net, learning_rate, batch_size=<span class="number">128</span>, num_epochs=<span class="number">5</span>, param_group=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># 读取数据</span></span><br><span class="line">    train_iter = paddle.io.DataLoader(</span><br><span class="line">        vision.datasets.DatasetFolder(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>), transform=train_augs),</span><br><span class="line">        batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_iter = paddle.io.DataLoader(</span><br><span class="line">        vision.datasets.DatasetFolder(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>), transform=test_augs),</span><br><span class="line">        batch_size=batch_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 损失</span></span><br><span class="line">    loss = nn.CrossEntropyLoss(reduction=<span class="string">&quot;none&quot;</span>) <span class="comment"># reduction 指定应用于输出结果的计算方式</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 学习率策略</span></span><br><span class="line">    <span class="keyword">if</span> param_group:</span><br><span class="line">        params_1x = [</span><br><span class="line">            param <span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters()</span><br><span class="line">            <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;fc.weight&quot;</span>, <span class="string">&quot;fc.bias&quot;</span>]]</span><br><span class="line">        trainer = paddle.optimizer.SGD(</span><br><span class="line">            parameters=[ <span class="comment"># 参数对应的学习率</span></span><br><span class="line">                &#123;<span class="string">&#x27;params&#x27;</span>: params_1x&#125;, <span class="comment"># params_1x使用正常的learning_rate</span></span><br><span class="line">                &#123;<span class="string">&#x27;params&#x27;</span>: net.fc.parameters(),<span class="string">&#x27;learning_rate&#x27;</span>: learning_rate * <span class="number">10</span>&#125; <span class="comment"># fc.parameters()使用十倍的learning_rate</span></span><br><span class="line">                ],</span><br><span class="line">            learning_rate = learning_rate, weight_decay=<span class="number">0.001</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        trainer = paddle.optimizer.SGD(parameters=net.parameters(), learning_rate=learning_rate,weight_decay=<span class="number">0.001</span>)</span><br><span class="line">        </span><br><span class="line">    train(net, train_iter, test_iter, loss, trainer, num_epochs)</span><br></pre></td></tr></table></figure>
<p>我们使用较小的学习率，通过微调预训练获得的模型参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_fine_tuning(finetune_net, <span class="number">5e-5</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">loss 0.222, train_acc 0.916,test_acc 0.900</span></span><br><span class="line"><span class="string">总体看效果还是不错的</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>为了进行比较，我们定义了一个相同的模型，但是将其所有模型参数初始化为随机值。由于整个模型需要从头开始训练，因此我们需要使用更大的学习率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scratch_net = vision.models.resnet18() <span class="comment"># 不加载在imagenet数据集上的预训练权重</span></span><br><span class="line">scratch_net.fc = nn.Linear(scratch_net.fc.weight.shape[<span class="number">0</span>], <span class="number">2</span>)</span><br><span class="line">train_fine_tuning(scratch_net, <span class="number">5e-4</span>, param_group=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">loss 0.398, train_acc 0.861, test_acc 0.840</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>意料之中，微调模型往往表现更好，因为它的初始参数值更有效。</p>
<h1>三、小结</h1>
<ul>
<li>图像增广基于现有的训练数据生成随机图像，来提高模型的泛化能力。</li>
<li>为了在预测过程中得到确切的结果，我们通常对训练样本只进行图像增广，而在预测过程中不使用带随机操作的图像增广。</li>
<li>深度学习框架提供了许多不同的图像增广方法，这些方法可以被同时应用。</li>
<li>迁移学习将从源数据集中学到的知识“迁移”到目标数据集，微调是迁移学习的常见技巧。</li>
<li>除输出层外，目标模型从源模型中复制所有模型设计及其参数，并根据目标数据集对这些参数进行微调。但是，目标模型的输出层需要从头开始训练。</li>
<li>通常，微调参数使用较小的学习率，而从头开始训练输出层可以使用更大的学习率。</li>
<li>在一个目标数据集上进行训练任务，但是使用了更强的正则化（使用了更小的学习率 使用更少的数据迭代），原因在于源模型已经很好了，保留优势。</li>
<li>微调通过使用在大数据上得到的预训练好的模型来初始化模型权重来提升精度。</li>
<li>微调通常速度更快，精度更高。</li>
<li>微调普遍应用于计算机视觉领域。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space">小漁头&amp;小戴</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.4-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E4%B8%8E%E5%BE%AE%E8%B0%83/">http://blog.dai2yutou.space/2023/01/01/深度学习5.4-图像识别模型关键组件之图像增广与微调/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.dai2yutou.space" target="_blank">小漁头|小戴</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/paddle/">paddle</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E5%8D%B7%E7%A7%AF%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/">深度学习基础_卷积基本概念及经典模型复现</a></div><div class="post_share"><div class="social-share" data-image="https://picbed.dai2yutou.space/web_img/19.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css" media="print" onload="this.media='all'"><script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.3-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">深度学习5.3-图像识别模型关键组件之数据处理</div></div></a></div><div class="next-post pull-right"><a href="/2023/01/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A06.1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习6.1-目标检测基本概念</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.1-%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF/" title="深度学习5.1-从全连接层到卷积"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">深度学习5.1-从全连接层到卷积</div></div></a></div><div><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.3-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" title="深度学习5.3-图像识别模型关键组件之数据处理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">深度学习5.3-图像识别模型关键组件之数据处理</div></div></a></div><div><a href="/2023/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05.2-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%B8%AD%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%84%E7%BD%91%E6%96%B9%E5%BC%8F/" title="深度学习5.2-图像分类中经典模型的组网方式"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">深度学习5.2-图像分类中经典模型的组网方式</div></div></a></div><div><a href="/2022/12/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="深度学习1.1-深度学习概论"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-18</div><div class="title">深度学习1.1-深度学习概论</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/" title="深度学习2.1-线性回归模型的实现"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.1-线性回归模型的实现</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" title="深度学习2.2-神经网络中的分类任务"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.2-神经网络中的分类任务</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="animate__fadeIn card-info card-widget wow" data-wow-delay="0" data-wow-duration="" data-wow-iteration="" data-wow-offset="" style="visibility: visible; animation-name: fadeIn;"><div class="author-info-top"><div class="card-info-avatar"><a class="avatar-img" data-pjax-state="" href="/about"><img class="entered loaded" alt="avatar" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/apple-touch-icon.jpg" onerror="this.onerror=null,this.src=&quot;/img/friend_404.gif&quot;"/></a><div class="author-status-box"><div class="author-status"><g-emoji class="g-emoji" alias="palm_tree" fallback-src="/img/tree_icon.png">🐟</g-emoji><span>摸鱼中~</span></div></div></div></div><div class="author-info__sayhi" id="author-info__sayhi">晚安😴！我是</div><h1 class="author-info__name">XiaoYutou|XiaoDai</h1><div class="author-info__description">热爱生活点滴，分享时刻精彩。</div><a id="card-info-btn" data-pjax-state="" onclick="pjax.loadUrl(/about/)"><i></i><span style="padding-left:32px;font-weight:600;font-size:large">了解更多<i class="faa-passing animated" style="padding-left:-2px;display:inline-block;vertical-align:middle;"><span style="height:28px;width:28px;fill:currentColor;position:relative;top:-1.5px">💨</span></i></span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xiaoyutoua" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2143191301@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>主域名:<a target="_blank" rel="noopener" href="https://www.dai2yutou.space">小漁头|小戴</a><br><span>技术问题欢迎交流🧐</span><span color="#3eb8be">VX:yuguolong_001</span></center></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">一、图像增广</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%B6%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">1.1 数据不足的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E5%B8%B8%E7%94%A8%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E6%96%B9%E6%B3%95"><span class="toc-text">1.2 常用的图像增广方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89%E7%BF%BB%E8%BD%AC"><span class="toc-text">1）翻转</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89%E8%A3%81%E5%89%AA%E5%88%87%E5%89%B2"><span class="toc-text">2）裁剪切割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%BC%89%E6%94%B9%E5%8F%98%E9%A2%9C%E8%89%B2"><span class="toc-text">3）改变颜色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%EF%BC%89%E7%BB%93%E5%90%88%E5%A4%9A%E7%A7%8D%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E6%96%B9%E6%B3%95"><span class="toc-text">4）结合多种图像增广方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E5%BA%94%E7%94%A8%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF"><span class="toc-text">1.3 应用图像增广</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">二、微调</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E6%AD%A5%E9%AA%A4"><span class="toc-text">2.1 步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E7%83%AD%E7%8B%97%E8%AF%86%E5%88%AB"><span class="toc-text">2.2 热狗识别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">1）获取数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF"><span class="toc-text">2）数据增广</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%BC%89%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-text">3）定义和初始化模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%EF%BC%89%E8%AE%AD%E7%BB%83%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="toc-text">4）训练微调模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">三、小结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/09/python%E5%9F%BA%E6%9C%AC%E8%BE%93%E5%87%BA%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/" title="python基本输出方法总结"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python基本输出方法总结"/></a><div class="content"><a class="title" href="/2023/05/09/python%E5%9F%BA%E6%9C%AC%E8%BE%93%E5%87%BA%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/" title="python基本输出方法总结">python基本输出方法总结</a><time datetime="2023-05-09T14:27:42.000Z" title="发表于 2023-05-09 22:27:42">2023-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/08/python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" title="python内置函数使用方法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python内置函数使用方法"/></a><div class="content"><a class="title" href="/2023/05/08/python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" title="python内置函数使用方法">python内置函数使用方法</a><time datetime="2023-05-08T12:06:44.000Z" title="发表于 2023-05-08 20:06:44">2023-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/25/Python%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F%EF%BC%9A%E5%8F%AF%E5%8F%98-%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1/" title="Python传参方式：可变/不可变对象"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python传参方式：可变/不可变对象"/></a><div class="content"><a class="title" href="/2023/04/25/Python%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F%EF%BC%9A%E5%8F%AF%E5%8F%98-%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1/" title="Python传参方式：可变/不可变对象">Python传参方式：可变/不可变对象</a><time datetime="2023-04-25T05:00:23.000Z" title="发表于 2023-04-25 13:00:23">2023-04-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 小漁头&小戴</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.6/translate/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script defer src="/js/light.js"></script><canvas id="universe"></canvas><script defer src="/js/starry_sky.js"></script><script defer src="/js/console.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script async data-pjax src="/js/card_author.js"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JzK9w99AgP1g6fso",ck:"JzK9w99AgP1g6fso"})</script><script type="text/javascript" src ="/js/reward.js" ></script><script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.6.16/dist/sweetalert2.all.min.js"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = 'b16a1fa0e63c46a4b8f28abfb06ae3fe';
  var gaud_map_key = 'e2b04289e870b005374ee030148d64fd&s=rsv3';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/3.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">英文水平不高，咋翻译论文？</a><div class="blog-slider__text">英文水平不高，咋翻译论文？</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/web_background2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-17</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">🐌博客搭建学习笔记</a><div class="blog-slider__text">这是再搭建博客已经写文章时遇到的bug和对博客的一些必要操作，不定时更新哦~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/9.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">Butterfly外挂标签</a><div class="blog-slider__text">本文是撰写博客文章时可能会用到的外挂标签汇总，放到一起，便于查阅和使用</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/07/停车场管理模拟系统/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-07</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/07/停车场管理模拟系统/&quot;);" href="javascript:void(0);" alt="">停车场管理模拟系统</a><div class="blog-slider__text">本文是大二下学期程序设计与数据结构实训课设，模拟的是一个停车场管理系统，用C和C++语言编写，在此记录一下~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/07/停车场管理模拟系统/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/1.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">第一篇文章</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">Hexo发生error：spawn failed错误的解决方法</a><div class="blog-slider__text">Hexo发生error：spawn failed错误的解决方法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-06</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">Hexo博客备份与恢复</a><div class="blog-slider__text">本文旨在解决在不同电脑上都能维护博客或配置、发布的内容丢失可恢复的问题。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">Echarts社区地址</a><div class="blog-slider__text">一些Echarts图标的开源网站。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '2');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__bounceInRight');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/about/'|| '/about/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.dai2yutou.space/api?xiaoyutoua",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xiaoyutoua')
    }
  </script><!-- hexo injector body_end end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>