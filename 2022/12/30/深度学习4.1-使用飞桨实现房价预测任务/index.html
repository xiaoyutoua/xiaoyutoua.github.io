<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>深度学习4.1-使用飞桨实现房价预测任务 | 小漁头|小戴</title><meta name="author" content="小漁头&amp;小戴"><meta name="copyright" content="小漁头&amp;小戴"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="本文是深度学习的第七篇，主要介绍了使用飞桨重写波士顿房价预测任务的五大步骤">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习4.1-使用飞桨实现房价预测任务">
<meta property="og:url" content="http://blog.dai2yutou.space/2022/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04.1-%E4%BD%BF%E7%94%A8%E9%A3%9E%E6%A1%A8%E5%AE%9E%E7%8E%B0%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/index.html">
<meta property="og:site_name" content="小漁头|小戴">
<meta property="og:description" content="本文是深度学习的第七篇，主要介绍了使用飞桨重写波士顿房价预测任务的五大步骤">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picbed.dai2yutou.space/web_img/19.png">
<meta property="article:published_time" content="2022-12-30T10:39:24.000Z">
<meta property="article:modified_time" content="2023-03-30T12:12:44.027Z">
<meta property="article:author" content="小漁头&amp;小戴">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="paddle">
<meta property="article:tag" content="深度学习基础_基础模型实战">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picbed.dai2yutou.space/web_img/19.png"><link rel="shortcut icon" href="/img/basketball.png"><link rel="canonical" href="http://blog.dai2yutou.space/2022/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04.1-%E4%BD%BF%E7%94%A8%E9%A3%9E%E6%A1%A8%E5%AE%9E%E7%8E%B0%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 小漁头&小戴","link":"链接: ","source":"来源: 小漁头|小戴","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习4.1-使用飞桨实现房价预测任务',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-30 20:12:44'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/css.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/at.alicdn.com/t/c/font_3829236_a49e40pee5.css"><link rel="stylesheet" href="/css/font-awesome.css"><link rel="stylesheet" href="/css/progress_bar.css"><link rel="stylesheet" href="/css/nav_menu.css"><link rel="stylesheet" href="/css/color.css"><link rel="apple-touch-icon" href="/img/apple-touch-icon.jpg"><meta name="apple-mobile-web-app-title" content="小漁头🏀"><link rel="bookmark" href="/img/apple-touch-icon.jpg"><link rel="apple-touch-icon-precomposed" sizes="180x180" href="/img/apple-touch-icon.jpg" ><link rel="stylesheet" href="/css/card_author.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (ture) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">61</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">36</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picbed.dai2yutou.space/web_img/19.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">小漁头|小戴</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dai2yutou.space/"><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><span> 📦归档</span></a></li><li><a class="site-page child" href="/tags/"><span> 🔖标签</span></a></li><li><a class="site-page child" href="/categories/"><span> 📂分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 万花筒</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E5%94%A0%E5%97%91/"><span> 💭唠嗑</span></a></li><li><a class="site-page child" href="/HTML/%E6%96%B0%E5%B9%B4%E5%80%92%E8%AE%A1%E6%97%B6/index.html"><span> 🔐项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/love/"><span> 恋爱小屋</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E8%A3%85%E4%BF%AE%E6%97%A5%E5%BF%97/"><span> ⏰装修日志</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习4.1-使用飞桨实现房价预测任务</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-12-30T10:39:24.000Z" title="发表于 2022-12-30 18:39:24">2022-12-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-30T12:12:44.027Z" title="更新于 2023-03-30 20:12:44">2023-03-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习4.1-使用飞桨实现房价预测任务"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="🏡使用飞桨重写波士顿房价预测任务"><a href="#🏡使用飞桨重写波士顿房价预测任务" class="headerlink" title="🏡使用飞桨重写波士顿房价预测任务"></a><strong>🏡使用飞桨重写波士顿房价预测任务</strong></h1><p>学习本节，希望你能够掌握以下知识点：</p>
<ul>
<li>了解辨别基础模型的方法；</li>
<li>熟悉进行预测任务与搭建基础模型的流程；</li>
<li>掌握层与块的基本概念，掌握自定义层的方法。</li>
</ul>
<hr>
<p>波士顿房价预测是一个经典的机器学习任务，类似于程序员世界的 “Hello World”。和大家对房价的普遍认知相同，波士顿地区的房价受诸多因素影响。该数据集统计了13种可能影响房价的因素和该类型房屋的均价，期望构建一个基于13个因素进行房价预测的模型。</p>
<p>如<strong>图1</strong>所示，对于预测问题，可以根据预测输出的类型是连续的实数值，还是离散的标签，区分为回归任务和分类任务。因为房价是一个连续值，所以房价预测显然是一个回归任务。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/abce0cb2a92f4e679c6855cfa520491597171533a0b0447e8d51d904446e213e" width="550" hegiht="" ></center>
<center><br>图1：波士顿房价影响因素示意图</br></center>

<p>深度学习不仅实现了模型的端到端学习，还推动了人工智能进入工业大生产阶段，产生了标准化、自动化和模块化的通用框架。不同场景的深度学习模型具备一定的通用性，五个步骤即可完成模型的构建和训练，如 <strong>图2</strong> 所示。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/17a932875f5f4f28a62bf060f96678618094841fbfb54f098eac798bf0e44ca6" width="700" hegiht="" ></center>
<center><br>图2：使用飞桨框架构建神经网络过程</br></center>

<p>正是由于深度学习的建模和训练的过程存在通用性，在构建不同的模型时，只有<strong>模型三要素</strong>【模型、损失、优化器】不同，其它步骤基本一致，深度学习框架才有用武之地。在数据处理之前，需要先加载飞桨框架的相关类库。</p>
<hr>
<p><strong>扩展：</strong> 端到端的学习</p>
<p>**端到端学习 (End-to-End Learning)**，也称端到端训练，是指在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标。通俗来讲，其实就是不做其他额外处理，从原始数据输入到任务结果输出，整个训练和预测过程都是在模型里完成的。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载飞桨、NumPy和相关类库</span></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Linear</span><br><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br></pre></td></tr></table></figure>

<p>代码中参数含义如下：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Overview_cn.html">paddle</a>：飞桨的主库，paddle 根目录下保留了常用API的别名，当前包括：paddle.tensor、paddle.framework、paddle.device目录下的所有API；</li>
<li><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Linear_cn.html#linear">Linear</a>：神经网络的全连接层函数，包含所有输入权重相加的基本神经元结构。在房价预测任务中，使用只有一层的神经网络（全连接层）实现线性回归模型。</li>
<li><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#paddle-nn">paddle.nn</a>：组网相关的API，包括 Linear、卷积 Conv2D、循环神经网络LSTM、损失函数CrossEntropyLoss、激活函数ReLU等；</li>
<li>paddle.nn.functional：与paddle.nn一样，包含组网相关的API，如：Linear、激活函数ReLU等，二者包含的同名模块功能相同，运行性能也基本一致。 差别在于paddle.nn目录下的模块均是类，每个类自带模块参数；<strong>paddle.nn.functional目录下的模块均是函数，需要手动传入函数计算所需要的参数。</strong> 在实际使用时，卷积、全连接层等本身具有可学习的参数，建议使用paddle.nn；而激活函数、池化等操作没有可学习参数，可以考虑使用paddle.nn.functional。</li>
</ul>
<hr>
<p><strong>说明：</strong></p>
<p>飞桨支持两种深度学习建模编写方式，更方便调试的动态图模式和性能更好并便于部署的静态图模式。</p>
<ul>
<li>动态图模式（命令式编程范式，类比Python）：解析式的执行方式。用户无需预先定义完整的网络结构，每写一行网络代码，即可同时获得计算结果；</li>
<li>静态图模式（声明式编程范式，类比C++）：先编译后执行的方式。用户需预先定义完整的网络结构，再对网络结构进行编译优化后，才能执行获得计算结果。</li>
</ul>
<p>飞桨框架2.0及之后的版本，默认使用动态图模式进行编码，同时提供了完备的动转静支持，开发者仅需添加一个装饰器（ <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/jit/to_static_cn.html#to-static">to_static</a> ），飞桨会自动将动态图的程序转换为静态图的program，并使用该program训练并可保存静态模型以实现推理部署。</p>
<hr>
<h2 id="1-数据处理"><a href="#1-数据处理" class="headerlink" title="1 数据处理"></a><strong>1 数据处理</strong></h2><p>数据处理包含五个部分：数据导入、数据形状变换、数据集划分、数据归一化处理和封装<code>load data</code>函数。数据预处理后，才能被模型调用。</p>
<h3 id="1-1-读入数据"><a href="#1-1-读入数据" class="headerlink" title="1.1 读入数据"></a><strong>1.1 读入数据</strong></h3><p>通过如下代码读入数据，了解下波士顿房价的数据集结构，数据存放在本地目录下<code>work/housing.data</code>文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入需要用到的package</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment"># 读入训练数据</span></span><br><span class="line">datafile = <span class="string">&#x27;work/housing.data&#x27;</span></span><br><span class="line">data = np.fromfile(datafile, sep=<span class="string">&#x27; &#x27;</span>, dtype=np.float32)</span><br><span class="line"><span class="built_in">print</span>(data, data.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[6.320e-03 1.800e+01 2.310e+00 ... 3.969e+02 7.880e+00 1.190e+01] (7084,)</span><br><span class="line">读入的数据是不标准的，是全堆在一列，</span><br><span class="line">这里可以看到读到了7084行，所以需要对数据进行形状变换</span><br></pre></td></tr></table></figure>


<h3 id="1-2-数据形状变换"><a href="#1-2-数据形状变换" class="headerlink" title="1.2 数据形状变换"></a><strong>1.2 数据形状变换</strong></h3><p>由于读入的原始数据是1维的，所有数据都连在一起。因此需要我们将数据的形状进行变换，形成一个2维的矩阵，每行为一个数据样本（14个值），每个数据样本包含13个$X$（影响房价的特征）和一个$Y$（该类型房屋的均价）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读入之后的数据被转化成1维array，其中array的第0-13项是第一条数据，第14-27项是第二条数据，以此类推.... </span></span><br><span class="line"><span class="comment"># 这里对原始数据做reshape，变成N x 14的形式</span></span><br><span class="line">feature_names = [ <span class="string">&#x27;CRIM&#x27;</span>, <span class="string">&#x27;ZN&#x27;</span>, <span class="string">&#x27;INDUS&#x27;</span>, <span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;NOX&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;AGE&#x27;</span>,<span class="string">&#x27;DIS&#x27;</span>, </span><br><span class="line">                 <span class="string">&#x27;RAD&#x27;</span>, <span class="string">&#x27;TAX&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;MEDV&#x27;</span> ]</span><br><span class="line">feature_num = <span class="built_in">len</span>(feature_names)</span><br><span class="line">data = data.reshape([data.shape[<span class="number">0</span>] // feature_num, feature_num])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">x = data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(14,)
[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01
 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00 2.400e+01]
(506, 14)
</code></pre>
<h3 id="1-3-数据集划分"><a href="#1-3-数据集划分" class="headerlink" title="1.3 数据集划分"></a><strong>1.3 数据集划分</strong></h3><p>将数据集划分成训练集和测试集，其中训练集用于确定模型的参数，测试集用于评判模型的效果。为什么要对数据集进行拆分，而不能直接应用于模型训练呢？这与学生时代的授课和考试关系比较类似，如 <strong>图3</strong> 所示。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/a1c845a50e28474d9aa72028edfea33f1a3deca1d54d40ec94ba366d3a18c408" width="600" hegiht="" ></center>
<center><br>图3：训练集和测试集拆分的意义</br></center>

<p>上学时总有一些自作聪明的同学，平时不认真学习，考试前临阵抱佛脚，将习题死记硬背下来，但是成绩往往并不好。因为学校期望学生掌握的是知识，而不仅仅是习题本身。另出新的考题，才能鼓励学生努力去掌握习题背后的原理。同样我们期望模型学习的是任务的本质规律，而不是训练数据本身，模型训练未使用的数据，才能更真实的评估模型的效果。</p>
<p>在本案例中，我们将80%的数据用作训练集，20%用作测试集，实现代码如下。通过打印训练集的形状，可以发现共有404个样本，每个样本含有13个特征和1个预测值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ratio = <span class="number">0.8</span></span><br><span class="line">offset = <span class="built_in">int</span>(data.shape[<span class="number">0</span>] * ratio)</span><br><span class="line">training_data = data[:offset]</span><br><span class="line">test_data = data[offset:]</span><br><span class="line">training_data.shape</span><br><span class="line">text_data.shape</span><br></pre></td></tr></table></figure>


<pre><code>(404, 14)
(102, 14)
</code></pre>
<h3 id="1-4-数据归一化处理"><a href="#1-4-数据归一化处理" class="headerlink" title="1.4 数据归一化处理"></a><strong>1.4 数据归一化处理</strong></h3><p>对每个特征进行归一化处理，使得每个特征的取值缩放到0~1之间。这样做有两个好处：<strong>一是模型训练更高效；二是特征前的权重大小可以代表该变量对预测结果的贡献度</strong>（因为每个特征值本身的范围相同）。归一化公式如下：</p>
<p>$$<br>x’ &#x3D; \frac{x-x_{min}}{x_{max}-x_{min}}<br>$$</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/2eb06823355c4aa9bf25a95c4e259ae54f02b15e00fb4a119d5ed13a3adc0b67" width="650" hegiht="" ></center>
<center><br>图4：数据归一化的优势</br></center>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算train数据集的最大值，最小值，平均值</span></span><br><span class="line">maximums, minimums, avgs = training_data.<span class="built_in">max</span>(axis=<span class="number">0</span>), \</span><br><span class="line">                            training_data.<span class="built_in">min</span>(axis=<span class="number">0</span>),\</span><br><span class="line">                            training_data.<span class="built_in">sum</span>(axis=<span class="number">0</span>) / training_data.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据进行归一化处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">    data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])</span><br></pre></td></tr></table></figure>

<h3 id="1-5-封装成load-data函数"><a href="#1-5-封装成load-data函数" class="headerlink" title="1.5 封装成load data函数"></a><strong>1.5 封装成load data函数</strong></h3><p>将上述几个数据处理操作封装成<code>load data</code>函数，以便下一步模型的调用，实现方法如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="comment"># 从文件导入数据</span></span><br><span class="line">    datafile = <span class="string">&#x27;./work/housing.data&#x27;</span></span><br><span class="line">    data = np.fromfile(datafile, sep=<span class="string">&#x27; &#x27;</span>, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数</span></span><br><span class="line">    feature_names = [ <span class="string">&#x27;CRIM&#x27;</span>, <span class="string">&#x27;ZN&#x27;</span>, <span class="string">&#x27;INDUS&#x27;</span>, <span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;NOX&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;AGE&#x27;</span>, \</span><br><span class="line">                      <span class="string">&#x27;DIS&#x27;</span>, <span class="string">&#x27;RAD&#x27;</span>, <span class="string">&#x27;TAX&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;MEDV&#x27;</span> ]</span><br><span class="line">    feature_num = <span class="built_in">len</span>(feature_names)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原始数据进行Reshape，变成[N, 14]这样的形状</span></span><br><span class="line">    data = data.reshape([data.shape[<span class="number">0</span>] // feature_num, feature_num])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原数据集拆分成训练集和测试集</span></span><br><span class="line">    <span class="comment"># 这里使用80%的数据做训练，20%的数据做测试</span></span><br><span class="line">    <span class="comment"># 测试集和训练集必须是没有交集的</span></span><br><span class="line">    ratio = <span class="number">0.8</span></span><br><span class="line">    offset = <span class="built_in">int</span>(data.shape[<span class="number">0</span>] * ratio)</span><br><span class="line">    training_data = data[:offset]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算train数据集的最大值，最小值</span></span><br><span class="line">    maximums, minimums = training_data.<span class="built_in">max</span>(axis=<span class="number">0</span>), training_data.<span class="built_in">min</span>(axis=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 记录数据的归一化参数，在预测时对数据做归一化[方便后续的反归一化的使用]</span></span><br><span class="line">    <span class="keyword">global</span> max_values</span><br><span class="line">    <span class="keyword">global</span> min_values</span><br><span class="line">   </span><br><span class="line">    max_values = maximums</span><br><span class="line">    min_values = minimums</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对数据进行归一化处理</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">        data[:, i] = (data[:, i] - min_values[i]) / (maximums[i] - minimums[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练集和测试集的划分比例</span></span><br><span class="line">    training_data = data[:offset]</span><br><span class="line">    test_data = data[offset:]</span><br><span class="line">    <span class="keyword">return</span> training_data, test_data</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">training_data, test_data = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line"><span class="built_in">print</span>(training_data.shape, test_data.shape)</span><br><span class="line"><span class="built_in">print</span>(training_data[<span class="number">1</span>,:])	<span class="comment">#第一条样本</span></span><br></pre></td></tr></table></figure>

<pre><code>(404, 14) (102, 14)
[2.35922547e-04 0.00000000e+00 2.62405723e-01 0.00000000e+00
 1.72839552e-01 5.47997713e-01 7.82698274e-01 3.48961979e-01
 4.34782617e-02 1.14822544e-01 5.53191364e-01 1.00000000e+00
 2.04470202e-01 3.68888885e-01]
</code></pre>
<h2 id="2-模型设计"><a href="#2-模型设计" class="headerlink" title="2 模型设计"></a><strong>2 模型设计</strong></h2><h3 id="【层与块】"><a href="#【层与块】" class="headerlink" title="【层与块】"></a><strong>【层与块】</strong></h3><p>前几篇讨论的模型复杂度有限，最复杂的是含一个隐藏层的多层感知机模型，然而实际情况中，这种模型过于简单，表达效果不够好，因此需要研究较为复杂的模型。然而较为复杂的模型也是由简单模型组成，因此有必要研究简单模型如何组成复杂模型。事实证明可以通过 “堆叠” 简单模型实现，为了描述如何堆叠，引入<strong>块（block）</strong> 的概念。块可以描述单层、多层组成的组件或者整个模型。使用块的一个好处是可以将一些块组合成更大的组件，这一过程通常是递归的，因此可以通过定义代码来生成任意复杂度的块，可以通过简洁的代码实现复杂的神经网络。</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/ef8b24068e894be8ab3fede36a6ad7ab4b275bbd21ba409b893f3ad8b58ffb20" width="700" hegiht="" ></center>

<center><br>图5：“堆叠”的块</br></center>

<p>事实证明，研究讨论“比单个层大”但“比整个模型小”的组件更有价值。对于多层感知机而言，整个模型及其组成层都是这种架构。 整个模型接受原始输入（特征），生成输出（预测）， 并包含一些参数（所有组成层的参数集合）。 同样，每个单独的层接收输入（由前一层提供）， 生成输出（到下一层的输入），并且具有一组可调参数， 这些参数根据从下一层反向传播的信号进行更新。</p>
<p>在构造自定义块之前，我们先回顾一下多层感知机的代码。下面的代码生成一个网络，其中包含一个具有256个单元和ReLU激活函数的全连接隐藏层，然后是一个具有10个隐藏单元且不带激活函数的全连接输出层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F <span class="comment"># nn下的实用功能组件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义具有一个隐藏层的多层感知机，如上图5的第一个图</span></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2是批量大小，20是X的维度值，所以这里是传进来了两条20维的样本</span></span><br><span class="line"><span class="comment"># 这里必须是20，因为上面定义网络时接受的数据就是20维</span></span><br><span class="line">X = paddle.rand((<span class="number">2</span>, <span class="number">20</span>))</span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line">net(X)	<span class="comment"># 把x放进网络中查看输出结果</span></span><br></pre></td></tr></table></figure>

<pre><code>Tensor(shape=[2, 20], dtype=float32, place=Place(cpu), stop_gradient=True,
       [[0.10209441, 0.16913104, 0.44511813, 0.28342801, 0.65742350, 0.44651571,
         0.36694321, 0.03608739, 0.25556597, 0.75385630, 0.59597689, 0.00202843,
         0.81059551, 0.68003124, 0.18284233, 0.79699272, 0.73747963, 0.67146826,
         0.55906087, 0.61247164],
        [0.69550031, 0.46067774, 0.51894343, 0.93576533, 0.81870192, 0.48760650,
         0.13647318, 0.78110564, 0.49254259, 0.61881417, 0.73745596, 0.97040987,
         0.49153054, 0.17309034, 0.07548618, 0.78019077, 0.56080866, 0.51286954,
         0.66860092, 0.46016651]])

Tensor(shape=[2, 10], dtype=float32, place=Place(cpu), stop_gradient=False,
       [[ 0.02718867,  0.33097127, -0.22596562, -0.10938051,  0.30752018,
          0.09025095, -0.10254925,  0.09890905, -0.44127771,  0.13845670],
        [-0.18452074,  0.47807249, -0.28389767, -0.22750369,  0.37274802,
          0.17845176, -0.08270003, -0.07816530, -0.30161276,  0.00834796]])
</code></pre>
<p>在这个例子中，我们通过实例化<code>nn.Sequential</code>来构建我们的模型， <code>nn.Sequential</code>定义了一种特殊的<code>Module</code>（块）， 它维护了一个由<code>Module</code>组成的有序列表。</p>
<h3 id="【自定义块】"><a href="#【自定义块】" class="headerlink" title="【自定义块】"></a><strong>【自定义块】</strong></h3><p>模型定义的实质是定义线性回归的网络结构，飞桨建议通过创建Python类的方式完成模型网络的定义，该类需要继承paddle.nn.Layer父类，并且在类中定义<code>init</code>函数和<code>forward</code>函数。<code>forward</code>函数是框架指定实现前向计算逻辑的函数，程序在调用模型实例时会自动执行，<code>forward</code>函数中使用的网络层需要在<code>init</code>函数中声明。</p>
<ul>
<li><strong>定义<code>init</code>函数</strong>：在类的初始化函数中声明每一层网络的实现函数。</li>
<li><strong>定义<code>forward</code>函数</strong>：构建神经网络结构，实现前向计算过程，并返回预测结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 自定义块	Sequential</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Layer):</span><br><span class="line">    <span class="comment"># 用模型参数声明层。这里，我们声明两个全连接的层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()<span class="comment"># 调用MLP的父类Module的构造函数来执行必要的函数初始化。</span></span><br><span class="line">        <span class="comment"># 这样，在类实例化时也可以指定其他函数参数。</span></span><br><span class="line">        self.hidden = nn.Linear(in_features=<span class="number">20</span>, out_features=<span class="number">256</span>) <span class="comment"># 隐藏层</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">256</span>, <span class="number">10</span>) <span class="comment"># 输出层</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。</span></span><br><span class="line">        <span class="keyword">return</span> self.out(F.relu(self.hidden(X)))	<span class="comment">#函数调用方式：调用ReLu激活函数</span></span><br><span class="line"></span><br><span class="line">X = paddle.rand((<span class="number">2</span>, <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">net = MLP()	<span class="comment">#将MLP封装起来，封装成一个net网络</span></span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure>


<pre><code>Tensor(shape=[2, 10], dtype=float32, place=Place(cpu), stop_gradient=False,
       [[-0.12201045, -0.15452111,  0.06742557, -0.00087534,  0.01926781,
         -0.25647265, -0.11357559,  0.21616164,  0.00257475, -0.01310621],
        [ 0.02261407, -0.16433953,  0.07217564, -0.11244217,  0.14721063,
         -0.20428163, -0.14929581,  0.06752300,  0.04719778,  0.1380767	7]])
</code></pre>
<p><strong>扩展：</strong> Module 类</p>
<p>Module 是一个基类，每次我们要搭建自己的神经网络的时候都要继承这个类，继承这个类会使得我们搭建网络的过程变得异常简单。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Module</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *<span class="built_in">input</span></span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">add_module</span>(<span class="params">self,name,module</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">cuda</span>(<span class="params">self,device=<span class="literal">None</span></span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">cpu</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *<span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">parameters</span>(<span class="params">self, recurse=<span class="literal">True</span></span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">named_parameters</span>(<span class="params">self, prefix=<span class="string">&#x27;&#x27;</span>, recurse=<span class="literal">True</span></span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">children</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">named_children</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">modules</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">named_modules</span>(<span class="params">self,memo=<span class="literal">None</span>,prefix=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self,mode=<span class="literal">True</span></span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">zero_grad</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__dir__</span>(<span class="params">self</span>):</span><br></pre></td></tr></table></figure>

<p>我们可以使用这种方法来任意搭建神经网络。下面是一个<code>输入维度为20、输出维度为5，两个隐藏层、使用ReLU激活函数</code>的神经网络模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">myMLP</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()	<span class="comment">#先调用一下父类，进行函数的初始化</span></span><br><span class="line">        self.hidden1 = nn.Linear(<span class="number">20</span>, <span class="number">32</span>)	<span class="comment">#定义一个20输入32输出的隐藏层</span></span><br><span class="line">        self.hidden2 = nn.Linear(<span class="number">32</span>, <span class="number">64</span>)	<span class="comment">#定义一个32输入64输出的隐藏层</span></span><br><span class="line">        self.act = nn.ReLU()	<span class="comment">#层搭建方式：定义一个人ReLu激活函数</span></span><br><span class="line">        self.output = nn.Linear(<span class="number">64</span>, <span class="number">5</span>)	<span class="comment">#定义一个64输入5输出的输出层</span></span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):	<span class="comment">#前向传播函数</span></span><br><span class="line">        y = self.hidden1(X)</span><br><span class="line">        y = self.act(y)</span><br><span class="line">        y = self.hidden2(y)</span><br><span class="line">        y = self.act(y)</span><br><span class="line">        y = self.output(y)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">X = paddle.rand((<span class="number">2</span>, <span class="number">20</span>))	<span class="comment">#传入的X在这里必须是20的样本</span></span><br><span class="line"></span><br><span class="line">net = myMLP()	<span class="comment">#定义好的MLP类封装起来</span></span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure>


<pre><code>Tensor(shape=[2, 5], dtype=float32, place=Place(cpu), stop_gradient=False,
       [[ 0.33403778,  0.10073330, -0.62100554, -0.13195495,  0.38762105],
        [ 0.50147879,  0.08661372, -0.59700704, -0.05069904,  0.40827096]])
</code></pre>
<h3 id="【搭建房价预测模型】"><a href="#【搭建房价预测模型】" class="headerlink" title="【搭建房价预测模型】"></a><strong>【搭建房价预测模型】</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Regressor</span>(nn.Layer):	<span class="comment">#这里定义了一个简单的单层网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fc = Linear(<span class="number">13</span>, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        x = self.fc(inputs)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h2 id="3-训练配置"><a href="#3-训练配置" class="headerlink" title="3 训练配置"></a><strong>3 训练配置</strong></h2><p>训练配置过程如下图所示：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/96075d4df5ae4e01ac1491ebf176fa557bd122b646ba49238f65c9b38a98cab4" width="700" hegiht="" ></center>
<center><br>图6：训练配置流程示意图</br></center>

<ul>
<li>本教程默认使用AI Studio训练模型，因此无需指定机器资源；</li>
<li>声明定义好的回归模型实例为Regressor，并将模型的状态设置为<code>train</code>；</li>
<li>使用<code>load_data</code>函数加载训练数据和测试数据；</li>
<li>设置优化算法和学习率，优化算法采用随机梯度下降SGD，学习率设置为0.01。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 声明定义好的线性回归模型</span></span><br><span class="line">model = Regressor()</span><br><span class="line"><span class="comment"># 开启模型训练模式</span></span><br><span class="line">model.train()</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">training_data, test_data = load_data()</span><br><span class="line"><span class="comment"># 定义优化算法，使用随机梯度下降SGD</span></span><br><span class="line"><span class="comment"># 学习率设置为0.01</span></span><br><span class="line">opt = paddle.optimizer.SGD(learning_rate=<span class="number">0.01</span>, parameters=model.parameters())</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>说明：</strong></p>
<p>模型实例有两种状态：训练状态<code>.train()</code>和预测状态<code>.eval()</code>。训练时要执行正向计算和反向传播梯度两个过程，而预测时只需要执行正向计算。</p>
<hr>
<h2 id="4-训练过程"><a href="#4-训练过程" class="headerlink" title="4 训练过程"></a><strong>4 训练过程</strong></h2><p>训练过程采用二层循环嵌套方式：</p>
<ul>
<li><p><strong>内层循环：</strong> 负责整个数据集的一次遍历，采用分批次方式（batch）。假设数据集样本数量为1000，一个批次有10个样本，则遍历一次数据集的批次数量是1000&#x2F;10&#x3D;100，即内层循环需要执行100次。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> iter_id, mini_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(mini_batches):</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>外层循环：</strong> 定义遍历数据集的次数，通过参数EPOCH_NUM设置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<p><strong>说明</strong>:</p>
<p>batch的取值会影响模型训练效果，batch过大，会增大内存消耗和计算时间，且训练效果并不会明显提升（每次参数只向梯度反方向移动一小步，因此方向没必要特别精确）；batch过小，每个batch的样本数据没有统计意义，计算的梯度方向可能偏差较大。由于房价预测模型的训练数据集较小，因此将batch设置为10。</p>
<hr>
<p>每次内层循环都需要执行如 <strong>图7</strong> 所示的步骤：</p>
<center><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/8154cf612a024a3f9144b4e31f59568ef9ad59c155b344919221d63bb9ccfcc8" width="700" hegiht="" ></center>
<center><br>图7：内循环计算过程</br></center>

<ul>
<li>数据准备：将一个批次的数据先转换成 nparray 格式，再转换成<code>Tensor</code>格式；</li>
<li>前向计算：将一个批次的样本数据灌入网络中，计算输出结果；</li>
<li>计算损失函数：以前向计算结果和真实房价作为输入，通过损失函数 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/2.4rc/api/paddle/nn/functional/square_error_cost_cn.html#square-error-cost">square_error_cost</a> API计算出损失函数值（Loss）；</li>
<li>反向传播：执行梯度反向传播<code>backward</code>函数，即从后到前逐层计算每一层的梯度，并根据设置的优化算法更新参数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">EPOCH_NUM = <span class="number">10</span>   <span class="comment"># 设置外层循环次数</span></span><br><span class="line">BATCH_SIZE = <span class="number">10</span>  <span class="comment"># 设置batch大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义外层循环</span></span><br><span class="line"><span class="keyword">for</span> epoch_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">    <span class="comment"># 在每轮迭代开始之前，将训练数据的顺序随机的打乱</span></span><br><span class="line">    np.random.shuffle(training_data)</span><br><span class="line">    <span class="comment"># 将训练数据进行拆分，得到小批量的数据，每个batch包含10条数据</span></span><br><span class="line">    mini_batches = [training_data[k:k+BATCH_SIZE] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(training_data), BATCH_SIZE)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义内层循环</span></span><br><span class="line">    <span class="keyword">for</span> iter_id, mini_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(mini_batches):</span><br><span class="line">        x = np.array(mini_batch[:, :-<span class="number">1</span>]) <span class="comment"># 获得当前批次训练数据</span></span><br><span class="line">        y = np.array(mini_batch[:, -<span class="number">1</span>:]) <span class="comment"># 获得当前批次训练标签（真实房价）</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将numpy数据转为飞桨动态图tensor的格式,方便数据在整个paddle框架中通用</span></span><br><span class="line">        house_features = paddle.to_tensor(x)</span><br><span class="line">        prices = paddle.to_tensor(y)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 前向计算，得到预测的y</span></span><br><span class="line">        predicts = model(house_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = F.square_error_cost(predicts, label=prices)</span><br><span class="line">        avg_loss = paddle.mean(loss)	<span class="comment">#平均损失</span></span><br><span class="line">        <span class="keyword">if</span> iter_id%<span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;epoch: &#123;&#125;, iter: &#123;&#125;, loss is: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch_id, iter_id, avg_loss.numpy()))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播损失，计算每层参数的梯度值</span></span><br><span class="line">        avg_loss.backward()</span><br><span class="line">        <span class="comment"># 优化器更新参数，根据设置好的学习率迭代一步</span></span><br><span class="line">        opt.step()</span><br><span class="line">        <span class="comment"># 清空梯度变量，以备下一轮计算</span></span><br><span class="line">        opt.clear_grad()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 下面是训练结果，再执行一遍程序，会继续向下训练，而不是从头开始</span></span><br></pre></td></tr></table></figure>

<pre><code>epoch: 0, iter: 0, loss is: [0.02828562]
epoch: 1, iter: 0, loss is: [0.01003132]
epoch: 2, iter: 0, loss is: [0.02788146]
epoch: 3, iter: 0, loss is: [0.01141991]
epoch: 4, iter: 0, loss is: [0.04065816]
epoch: 5, iter: 0, loss is: [0.0243281]
epoch: 6, iter: 0, loss is: [0.03753167]
epoch: 7, iter: 0, loss is: [0.02115335]
epoch: 8, iter: 0, loss is: [0.0295791]
epoch: 9, iter: 0, loss is: [0.01928121]
</code></pre>
<h2 id="5-保存并测试模型"><a href="#5-保存并测试模型" class="headerlink" title="5 保存并测试模型"></a><strong>5 保存并测试模型</strong></h2><h3 id="5-1-保存模型"><a href="#5-1-保存模型" class="headerlink" title="5.1 保存模型"></a><strong>5.1 保存模型</strong></h3><p>使用 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/save_cn.html#save">paddle.save API</a> 将模型当前的参数数据 <code>model.state_dict()</code> 保存到文件中，用于模型预测或校验的程序调用。</p>
<blockquote>
<p>data目录每次启动项目会清空，永久保存需要放到work目录下</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型的整个参数，文件名为 xxx.pdparams</span></span><br><span class="line">paddle.save(model.state_dict(), <span class="string">&#x27;data/LR_model.pdparams&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型保存成功，模型参数保存在data/LR_model.pdparams中&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>说明：</strong></p>
<p>理论而言，直接使用模型实例即可完成预测，但是在实际应用中，训练模型和使用模型往往是不同的场景。模型训练通常使用大量的线下服务器（不对外向企业的客户&#x2F;用户提供在线服务）；模型预测则通常使用线上提供预测服务的服务器实现或者将已经完成的预测模型嵌入手机或其他终端设备中使用。因此“先保存模型，再加载模型”更贴合真实场景的使用方法。</p>
<hr>
<h3 id="5-2-测试模型"><a href="#5-2-测试模型" class="headerlink" title="5.2 测试模型"></a><strong>5.2 测试模型</strong></h3><p>下面选择一条数据样本，测试下模型的预测效果。测试过程和在应用场景中使用模型的过程一致，主要可分成如下三个步骤：</p>
<ol>
<li>配置模型预测的机器资源。本案例默认使用本机，因此无需写代码指定。</li>
<li>将训练好的模型参数加载到模型实例中。由两个语句完成，第一句是从文件中读取模型参数；第二句是将参数内容加载到模型。加载完毕后，需要将模型的状态调整为<code>eval()</code>（校验）。上文中提到，训练状态的模型需要同时支持前向计算和反向传导梯度，模型的实现较为臃肿，而校验和预测状态的模型只需要支持前向计算，模型的实现更加简单，性能更好。</li>
<li>将待预测的样本特征输入到模型中，打印输出的预测结果。</li>
</ol>
<p>通过<code>load_one_example</code>函数实现从数据集中抽一条样本作为测试样本，具体实现代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_one_example</span>():</span><br><span class="line">    <span class="comment"># 从上边已加载的测试集中，随机选择一条作为测试数据</span></span><br><span class="line">    idx = np.random.randint(<span class="number">0</span>, test_data.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;抽取的是第&#x27;</span>, idx, <span class="string">&#x27;条样本&#x27;</span>)</span><br><span class="line">    one_data, label = test_data[idx, :-<span class="number">1</span>], test_data[idx, -<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;特征是：&#x27;</span>, one_data, one_data.shape)	<span class="comment"># 即x</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;标签是：&#x27;</span>, label, label.shape)	<span class="comment"># 即y</span></span><br><span class="line">    <span class="comment"># 修改该条数据shape为[1,13]</span></span><br><span class="line">    one_data =  one_data.reshape([<span class="number">1</span>,-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> one_data, label</span><br></pre></td></tr></table></figure>

<p>将训练好的模型参数加载到模型实例中。同时抽取一条样本：<code>特征+标签</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数为保存模型参数的文件地址</span></span><br><span class="line">model_dict = paddle.load(<span class="string">&#x27;data/LR_model.pdparams&#x27;</span>)</span><br><span class="line">model.load_dict(model_dict)	<span class="comment"># 将参数铺到模型当中</span></span><br><span class="line">model.<span class="built_in">eval</span>()	<span class="comment"># 开启评估模式	</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数为数据集的文件地址</span></span><br><span class="line">one_data, label = load_one_example()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转为动态图的variable格式 </span></span><br><span class="line">one_data = paddle.to_tensor(one_data)</span><br><span class="line">predict = model(one_data)	<span class="comment"># 放入数据得到预测结果</span></span><br></pre></td></tr></table></figure>

<pre><code>抽取的是第 76 条样本
特征是： [0.06538943 0.         0.7002779  0.         0.30246916 0.51369995
 0.6364572  0.2086588  1.         1.         0.8085107  1.
 0.2486203 ] (13,)
标签是： 0.4 ()
</code></pre>
<p>因为我们在正式开始训练之前对数据进行了归一化处理，实际取出的特征与标签值并不符合实际数据，因此在这里我们需要对预测结果进行反归一化处理。</p>
<p>$$<br>x’ &#x3D; \frac{x-x_{min}}{x_{max}-x_{min}}<br>$$<br>反归一化公式如下：</p>
<p>$$<br>x &#x3D; x’·({x_{max}-x_{min}}) + x_{min}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对结果做反归一化处理</span></span><br><span class="line">predict = predict * (max_values[-<span class="number">1</span>] - min_values[-<span class="number">1</span>]) + min_values[-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 对label数据做反归一化处理</span></span><br><span class="line">label = label * (max_values[-<span class="number">1</span>] - min_values[-<span class="number">1</span>]) + min_values[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Inference result is &#123;&#125;, the corresponding label is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(predict.numpy(), label))</span><br></pre></td></tr></table></figure>

<pre><code>Inference result is [[23.333654]], the corresponding label is 23.0
</code></pre>
<p>通过比较“模型预测值”和“真实房价”可见，模型的预测效果与真实房价接近。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space">小漁头&amp;小戴</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://blog.dai2yutou.space/2022/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04.1-%E4%BD%BF%E7%94%A8%E9%A3%9E%E6%A1%A8%E5%AE%9E%E7%8E%B0%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/">http://blog.dai2yutou.space/2022/12/30/深度学习4.1-使用飞桨实现房价预测任务/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.dai2yutou.space" target="_blank">小漁头|小戴</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/paddle/">paddle</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%98/">深度学习基础_基础模型实战</a></div><div class="post_share"><div class="social-share" data-image="https://picbed.dai2yutou.space/web_img/19.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css" media="print" onload="this.media='all'"><script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.2-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98%E7%AD%96%E7%95%A5%EF%BC%88%E4%B8%8B%EF%BC%89/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">深度学习3.2-模型选择与调优策略（下）</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04.2-%E4%BD%BF%E7%94%A8%E6%9E%81%E7%AE%80%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习4.2-使用极简方法实现手写数字识别任务</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04.2-%E4%BD%BF%E7%94%A8%E6%9E%81%E7%AE%80%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1/" title="深度学习4.2-使用极简方法实现手写数字识别任务"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-30</div><div class="title">深度学习4.2-使用极简方法实现手写数字识别任务</div></div></a></div><div><a href="/2022/12/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="深度学习1.1-深度学习概论"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-18</div><div class="title">深度学习1.1-深度学习概论</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/" title="深度学习2.1-线性回归模型的实现"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.1-线性回归模型的实现</div></div></a></div><div><a href="/2022/12/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" title="深度学习2.2-神经网络中的分类任务"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-20</div><div class="title">深度学习2.2-神经网络中的分类任务</div></div></a></div><div><a href="/2022/12/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="深度学习2.3-多层感知机的搭建与实现"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-23</div><div class="title">深度学习2.3-多层感知机的搭建与实现</div></div></a></div><div><a href="/2022/12/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.1-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98%E7%AD%96%E7%95%A5%EF%BC%88%E4%B8%8A%EF%BC%89/" title="深度学习3.1-模型选择与调优策略（上）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/19.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-25</div><div class="title">深度学习3.1-模型选择与调优策略（上）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="animate__fadeIn card-info card-widget wow" data-wow-delay="0" data-wow-duration="" data-wow-iteration="" data-wow-offset="" style="visibility: visible; animation-name: fadeIn;"><div class="author-info-top"><div class="card-info-avatar"><a class="avatar-img" data-pjax-state="" href="/about"><img class="entered loaded" alt="avatar" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/apple-touch-icon.jpg" onerror="this.onerror=null,this.src=&quot;/img/friend_404.gif&quot;"/></a><div class="author-status-box"><div class="author-status"><g-emoji class="g-emoji" alias="palm_tree" fallback-src="/img/tree_icon.png">🐟</g-emoji><span>摸鱼中~</span></div></div></div></div><div class="author-info__sayhi" id="author-info__sayhi">晚安😴！我是</div><h1 class="author-info__name">XiaoYutou|XiaoDai</h1><div class="author-info__description">热爱生活点滴，分享时刻精彩。</div><a id="card-info-btn" data-pjax-state="" onclick="pjax.loadUrl(/about/)"><i></i><span style="padding-left:32px;font-weight:600;font-size:large">了解更多<i class="faa-passing animated" style="padding-left:-2px;display:inline-block;vertical-align:middle;"><span style="height:28px;width:28px;fill:currentColor;position:relative;top:-1.5px">💨</span></i></span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xiaoyutoua" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2143191301@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>主域名:<a target="_blank" rel="noopener" href="https://www.dai2yutou.space">小漁头|小戴</a><br><span>技术问题欢迎交流🧐</span><span color="#3eb8be">VX:yuguolong_001</span></center></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%8F%A1%E4%BD%BF%E7%94%A8%E9%A3%9E%E6%A1%A8%E9%87%8D%E5%86%99%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1"><span class="toc-text">🏡使用飞桨重写波士顿房价预测任务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-text">1 数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-text">1.1 读入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%95%B0%E6%8D%AE%E5%BD%A2%E7%8A%B6%E5%8F%98%E6%8D%A2"><span class="toc-text">1.2 数据形状变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-text">1.3 数据集划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="toc-text">1.4 数据归一化处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-%E5%B0%81%E8%A3%85%E6%88%90load-data%E5%87%BD%E6%95%B0"><span class="toc-text">1.5 封装成load data函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1"><span class="toc-text">2 模型设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E3%80%90%E5%B1%82%E4%B8%8E%E5%9D%97%E3%80%91"><span class="toc-text">【层与块】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E3%80%90%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%97%E3%80%91"><span class="toc-text">【自定义块】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E3%80%90%E6%90%AD%E5%BB%BA%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%E3%80%91"><span class="toc-text">【搭建房价预测模型】</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%AE%AD%E7%BB%83%E9%85%8D%E7%BD%AE"><span class="toc-text">3 训练配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-text">4 训练过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%BF%9D%E5%AD%98%E5%B9%B6%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="toc-text">5 保存并测试模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">5.1 保存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="toc-text">5.2 测试模型</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/06/07/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%9F%EF%BC%9F%EF%BC%9F/" title="如何学习动态规划？？？"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/28.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何学习动态规划？？？"/></a><div class="content"><a class="title" href="/2023/06/07/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%9F%EF%BC%9F%EF%BC%9F/" title="如何学习动态规划？？？">如何学习动态规划？？？</a><time datetime="2023-06-07T15:58:25.000Z" title="发表于 2023-06-07 23:58:25">2023-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/30/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E7%9A%84%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="基于时间片轮转的进程管理系统的设计与实现"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/27.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于时间片轮转的进程管理系统的设计与实现"/></a><div class="content"><a class="title" href="/2023/05/30/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E7%9A%84%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="基于时间片轮转的进程管理系统的设计与实现">基于时间片轮转的进程管理系统的设计与实现</a><time datetime="2023-05-30T15:25:36.000Z" title="发表于 2023-05-30 23:25:36">2023-05-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/29/Python%E5%9B%9B%E5%A4%A7%E6%B3%95%E5%AE%9D/" title="Python四大法宝"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/article_img/Python/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python四大法宝"/></a><div class="content"><a class="title" href="/2023/05/29/Python%E5%9B%9B%E5%A4%A7%E6%B3%95%E5%AE%9D/" title="Python四大法宝">Python四大法宝</a><time datetime="2023-05-29T05:19:20.000Z" title="发表于 2023-05-29 13:19:20">2023-05-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 小漁头&小戴</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.6/translate/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/node-snackbar/0.1.16/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script defer src="/js/light.js"></script><canvas id="universe"></canvas><script defer src="/js/starry_sky.js"></script><script defer src="/js/console.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script async data-pjax src="/js/card_author.js"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JzK9w99AgP1g6fso",ck:"JzK9w99AgP1g6fso"})</script><script type="text/javascript" src ="/js/reward.js" ></script><script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.6.16/dist/sweetalert2.all.min.js"></script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = 'b16a1fa0e63c46a4b8f28abfb06ae3fe';
  var gaud_map_key = 'e2b04289e870b005374ee030148d64fd&s=rsv3';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/4.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-02</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">英文水平不高，咋翻译论文？</a><div class="blog-slider__text">英文水平不高，咋翻译论文？</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/02/02/论文翻译/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/web_background2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-17</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">🐌博客搭建学习笔记</a><div class="blog-slider__text">这是再搭建博客已经写文章时遇到的bug和对博客的一些必要操作，不定时更新哦~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/17/博客搭建学习笔记/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/9.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">Butterfly外挂标签</a><div class="blog-slider__text">本文是撰写博客文章时可能会用到的外挂标签汇总，放到一起，便于查阅和使用</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/Butterfly外挂标签/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/3.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">第一篇文章</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/09/hello-world/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-20</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">Hexo发生error：spawn failed错误的解决方法</a><div class="blog-slider__text">Hexo发生error：spawn failed错误的解决方法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/20/erro_spawn_failed/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-06</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">Hexo博客备份与恢复</a><div class="blog-slider__text">本文旨在解决在不同电脑上都能维护博客或配置、发布的内容丢失可恢复的问题。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/06/Hexo博客备份与恢复/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbed.dai2yutou.space/web_img/10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">Echarts社区地址</a><div class="blog-slider__text">一些Echarts图标的开源网站。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/01/24/Echarts社区地址/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '2');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__bounceInRight');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/about/'|| '/about/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.dai2yutou.space/api?xiaoyutoua",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'xiaoyutoua')
    }
  </script><!-- hexo injector body_end end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>